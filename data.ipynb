{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2204bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfbd\n",
    "import requests\n",
    "import json\n",
    "from itertools import islice\n",
    "import time\n",
    "from cfbd.rest import ApiException\n",
    "from pprint import pprint\n",
    "import sys, subprocess\n",
    "import networkx as nx\n",
    "import datetime\n",
    "from config import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7d977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access api\n",
    "\n",
    "configuration = cfbd.Configuration(\n",
    "    access_token = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting team data to cross ref\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "\n",
    "# This is the only dictionary you need to create here.\n",
    "node_attributes_by_year = {}\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Fetching all team data for attributes for {year}...\")\n",
    "    teams_api = cfbd.TeamsApi(cfbd.ApiClient(configuration))\n",
    "    all_teams = teams_api.get_teams(year=year)\n",
    "    print(f\"Found {len(all_teams)} teams.\")\n",
    "    \n",
    "    current_year_attrs = {}\n",
    "    for team in all_teams:\n",
    "        current_year_attrs[team.school] = {\n",
    "            # Use 'Unknown' as a default string if data is None\n",
    "            'classification': str(team.classification) if team.classification else 'Unknown',\n",
    "            'conference': str(team.conference) if team.conference else 'Unknown',\n",
    "            # Use 0.0 as a default float if data is None\n",
    "            'latitude': float(team.location.latitude) if team.location and team.location.latitude else 0.0,\n",
    "            'longitude': float(team.location.longitude) if team.location and team.location.longitude else 0.0\n",
    "        }\n",
    "    node_attributes_by_year[year] = current_year_attrs\n",
    "\n",
    "print(\"Node attribute maps created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting transfer portal data\n",
    "\n",
    "with cfbd.ApiClient(configuration) as api_client:\n",
    "    api_instance = cfbd.PlayersApi(api_client)\n",
    "\n",
    "api_response_2025 = api_instance.get_transfer_portal(year=2025)\n",
    "api_response_2024 = api_instance.get_transfer_portal(year=2024)\n",
    "api_response_2023 = api_instance.get_transfer_portal(year=2023)\n",
    "api_response_2022 = api_instance.get_transfer_portal(year=2022)\n",
    "api_response_2021 = api_instance.get_transfer_portal(year=2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to graphml\n",
    "\n",
    "data_by_year = {\n",
    "    2025: api_response_2025,\n",
    "    2024: api_response_2024,\n",
    "    2023: api_response_2023,\n",
    "    2022: api_response_2022,\n",
    "    2021: api_response_2021\n",
    "}\n",
    "\n",
    "node_attr_map = node_attributes_by_year\n",
    "\n",
    "default_attrs = {\n",
    "    'classification': 'Unknown',\n",
    "    'conference': 'Unknown',\n",
    "    'latitude': 0.0,\n",
    "    'longitude': 0.0\n",
    "}\n",
    "\n",
    "# Add nodes and edges to the graph G based on data\n",
    "# Nodes: school names (origin and destination)\n",
    "# Edges: a directed edge origin -> destination per player; edge attributes aggregate players\n",
    "for year, data in data_by_year.items():\n",
    "    G = nx.DiGraph()\n",
    "    print(f\"Processing data for {year}...\")\n",
    "    for t in data:\n",
    "        origin = t.origin.strip() if getattr(t, 'origin', None) else None\n",
    "        dest = t.destination.strip() if getattr(t, 'destination', None) else None\n",
    "\n",
    "        # add nodes if present\n",
    "        if origin:\n",
    "            G.add_node(origin)\n",
    "        if dest:\n",
    "            G.add_node(dest)\n",
    "\n",
    "        # only create edges when both origin and destination exist\n",
    "        if origin and dest:\n",
    "            player = f\"{getattr(t, 'first_name', '')} {getattr(t, 'last_name', '')}\".strip()\n",
    "            pos = getattr(t, 'position', None)\n",
    "            date = getattr(t, 'transfer_date', None)\n",
    "            date_iso = date.isoformat() if date is not None else None\n",
    "            rating = getattr(t, 'rating', None)\n",
    "            stars = getattr(t, 'stars', None)\n",
    "            eligibility = getattr(t, 'eligibility', None)\n",
    "\n",
    "            if G.has_edge(origin, dest):\n",
    "                edge = G[origin][dest]\n",
    "                edge.setdefault('players', []).append(player)\n",
    "                edge.setdefault('positions', []).append(pos)\n",
    "                edge.setdefault('dates', []).append(date_iso)\n",
    "                edge.setdefault('ratings', []).append(rating)\n",
    "                edge.setdefault('stars', []).append(stars)\n",
    "                edge.setdefault('eligibility', []).append(str(eligibility))\n",
    "                edge['weight'] = edge.get('weight', 1) + 1\n",
    "            else:\n",
    "                G.add_edge(origin, dest, players=[player], positions=[pos], dates=[date_iso], ratings=[rating], stars=[stars], eligibility=[str(eligibility)], weight=1)\n",
    "\n",
    "\n",
    "    # Serialize any list-valued (or None) edge attributes to strings for GraphML compatibility\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        for k in list(attrs.keys()):\n",
    "            val = attrs[k]\n",
    "            if isinstance(val, list):\n",
    "                # join list elements into a single string; convert None -> empty string\n",
    "                attrs[k] = ' | '.join(['' if x is None else str(x) for x in val])\n",
    "            elif val is None:\n",
    "                attrs[k] = ''\n",
    "\n",
    "    #Get the map of attributes for the specific year\n",
    "    current_year_node_attrs = node_attr_map.get(year, {})\n",
    "\n",
    "    # Create the final mapping, applying defaults to any node not in the map\n",
    "    final_attrs_for_graph = {\n",
    "        node: current_year_node_attrs.get(node, default_attrs) for node in G.nodes()\n",
    "    }\n",
    "\n",
    "    # Set all attributes at once. \n",
    "    # NetworkX unpacks the inner dictionaries automatically.\n",
    "    nx.set_node_attributes(G, final_attrs_for_graph)\n",
    "\n",
    "    filename = f\"transfer_portal_{year}.graphml\"\n",
    "\n",
    "    # write graphml\n",
    "    nx.write_graphml(G, filename)\n",
    "    print(f\"Wrote {len(G.nodes())} nodes and {len(G.edges())} edges to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77080f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PART 1: RECRUITING GRAPHS WITH SCHOOL ATTRIBUTES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: COLLECTING RECRUITING DATA\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# First, collect school attributes for all years\n",
    "print(\"Collecting school attributes for all years...\")\n",
    "school_attrs_by_year = {}\n",
    "\n",
    "# assigns year as the key and year_attrs as the value, which is itself a dict with a value that is also another dict\n",
    "for year in range(2000, 2027):\n",
    "    print(f\"  Fetching school data for {year}...\")\n",
    "    try:\n",
    "        teams_api = cfbd.TeamsApi(cfbd.ApiClient(configuration))\n",
    "        teams = teams_api.get_teams(year=year)\n",
    "        \n",
    "        year_attrs = {}\n",
    "        for team in teams:\n",
    "            year_attrs[team.school] = {\n",
    "                'classification': str(team.classification) if team.classification else 'Unknown',\n",
    "                'conference': str(team.conference) if team.conference else 'Unknown',\n",
    "                'latitude': float(team.location.latitude) if (team.location and team.location.latitude) else 0.0,\n",
    "                'longitude': float(team.location.longitude) if (team.location and team.location.longitude) else 0.0\n",
    "            }\n",
    "        school_attrs_by_year[year] = year_attrs\n",
    "        time.sleep(1)  # Rate limit protection\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error fetching teams for {year}: {e}\")\n",
    "        school_attrs_by_year[year] = {}\n",
    "\n",
    "# Now build recruiting graphs\n",
    "print(\"\\nBuilding recruiting graphs...\")\n",
    "\n",
    "for year in range(2000, 2027):\n",
    "    print(f\"\\n  Processing recruiting class {year}...\")\n",
    "    \n",
    "    try:\n",
    "        recruit_api = cfbd.RecruitingApi(cfbd.ApiClient(configuration))\n",
    "        recruits = recruit_api.get_recruits(year=year)\n",
    "        \n",
    "        G = nx.MultiGraph()\n",
    "        \n",
    "        # Track node attributes\n",
    "        hometown_node_attrs = {}\n",
    "        school_node_attrs = {}\n",
    "        \n",
    "        for recruit in recruits:\n",
    "            school = getattr(recruit, 'committed_to', None)\n",
    "            city = getattr(recruit, 'city', None)\n",
    "            state = getattr(recruit, 'state_province', None)\n",
    "            hometown_info = getattr(recruit, 'hometown_info', None)\n",
    "            \n",
    "            # Build hometown key\n",
    "            hometown_key = None\n",
    "            if city and state:\n",
    "                hometown_key = f\"{city}, {state}\"\n",
    "            \n",
    "            if not school or not hometown_key:\n",
    "                continue\n",
    "            \n",
    "            # Add school node\n",
    "            if school not in G:\n",
    "                G.add_node(school, bipartite=0, type='School')\n",
    "                # Get school attributes from our pre-fetched data\n",
    "                school_node_attrs[school] = school_attrs_by_year.get(year, {}).get(\n",
    "                    school,\n",
    "                    {'classification': 'Unknown', 'conference': 'Unknown', 'latitude': 0.0, 'longitude': 0.0}\n",
    "                )\n",
    "            \n",
    "            # Add hometown node\n",
    "            if hometown_key not in G:\n",
    "                G.add_node(hometown_key, bipartite=1, type='Hometown')\n",
    "                hometown_node_attrs[hometown_key] = {\n",
    "                    'latitude': float(hometown_info.latitude) if (hometown_info and hometown_info.latitude) else 0.0,\n",
    "                    'longitude': float(hometown_info.longitude) if (hometown_info and hometown_info.longitude) else 0.0,\n",
    "                    'fips': int(hometown_info.fips_code) if (hometown_info and hometown_info.fips_code) else 0,\n",
    "                    'city': city,\n",
    "                    'state': state\n",
    "                }\n",
    "            \n",
    "            id = getattr(recruit, 'id', 'Unknown')\n",
    "            athlete_id = getattr(recruit, 'athlete_id', 'Unknown')\n",
    "            name = getattr(recruit, 'name', 'Unknown')\n",
    "            position = getattr(recruit, 'position', 'N/A')\n",
    "            rating = getattr(recruit, 'rating', 0.0)\n",
    "            stars = getattr(recruit, 'stars', 0)\n",
    "            type = str(getattr(recruit, 'recruit_type', 'N/A')) if getattr(recruit, 'recruit_type', None) else 'N/A'\n",
    "            \n",
    "            G.add_edge(\n",
    "                hometown_key,\n",
    "                school,\n",
    "                id=str(id),\n",
    "                athlete_id=str(athlete_id),\n",
    "                player=name,\n",
    "                position=position,\n",
    "                rating=rating,\n",
    "                stars=stars,\n",
    "                recruit_type=type,\n",
    "                weight=1\n",
    "            )\n",
    "        \n",
    "        # Set node attributes\n",
    "        nx.set_node_attributes(G, school_node_attrs)\n",
    "        nx.set_node_attributes(G, hometown_node_attrs)\n",
    "        \n",
    "        # Serialize attributes for GraphML\n",
    "        # We need keys=True to handle MultiGraph edges correctly\n",
    "        for u, v, key, attrs in G.edges(data=True, keys=True):\n",
    "            for k, val in attrs.items():\n",
    "                # We no longer have lists, so we just check for None\n",
    "                if val is None:\n",
    "                    attrs[k] = ''\n",
    "        \n",
    "        # Save graph\n",
    "        filename = RECRUITING_DIR / f\"recruiting_network_{year}.graphml\"\n",
    "        nx.write_graphml(G, filename)\n",
    "        print(f\"    ✓ Saved {len(G.nodes())} nodes, {len(G.edges())} edges\")\n",
    "        \n",
    "        time.sleep(1)  # Rate limit protection\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error processing {year}: {e}\")\n",
    "\n",
    "print(\"\\n✓ Recruiting graphs complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f9cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CFB DATA COLLECTION PIPELINE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PART 2: COLLECTING PLAYER PERFORMANCE DATA\n",
      "======================================================================\n",
      "\n",
      "  Fetching performance data for 2013...\n",
      "    ✓ Collected 2984 player records\n",
      "  Fetching performance data for 2014...\n",
      "    ✓ Collected 3052 player records\n",
      "  Fetching performance data for 2015...\n",
      "    ✓ Collected 3109 player records\n",
      "  Fetching performance data for 2016...\n",
      "    ✓ Collected 3252 player records\n",
      "  Fetching performance data for 2017...\n",
      "    ✓ Collected 3229 player records\n",
      "  Fetching performance data for 2018...\n",
      "    ✓ Collected 3490 player records\n",
      "  Fetching performance data for 2019...\n",
      "    ✓ Collected 3506 player records\n",
      "  Fetching performance data for 2020...\n",
      "    ✓ Collected 2381 player records\n",
      "  Fetching performance data for 2021...\n",
      "    ✓ Collected 3303 player records\n",
      "  Fetching performance data for 2022...\n",
      "    ✓ Collected 4992 player records\n",
      "  Fetching performance data for 2023...\n",
      "    ✓ Collected 4585 player records\n",
      "  Fetching performance data for 2024...\n",
      "    ✓ Collected 4129 player records\n",
      "\n",
      "✓ Saved 42012 performance records to data\\supplemental\\player_performance.csv\n",
      "\n",
      "======================================================================\n",
      "PART 3: COLLECTING TEAM ROSTERS\n",
      "======================================================================\n",
      "\n",
      "  Fetching roster data for 2000...\n",
      "    ✓ Collected 0 roster records\n",
      "  Fetching roster data for 2001...\n",
      "    ✓ Collected 0 roster records\n",
      "  Fetching roster data for 2002...\n",
      "    ✓ Collected 0 roster records\n",
      "  Fetching roster data for 2003...\n",
      "    ✓ Collected 0 roster records\n",
      "  Fetching roster data for 2004...\n",
      "    ✓ Collected 3620 roster records\n",
      "  Fetching roster data for 2005...\n",
      "    ✓ Collected 4146 roster records\n",
      "  Fetching roster data for 2006...\n",
      "    ✓ Collected 4367 roster records\n",
      "  Fetching roster data for 2007...\n",
      "    ✓ Collected 4698 roster records\n",
      "  Fetching roster data for 2008...\n",
      "    ✓ Collected 4798 roster records\n",
      "  Fetching roster data for 2009...\n",
      "    ✓ Collected 13747 roster records\n",
      "  Fetching roster data for 2010...\n",
      "    ✓ Collected 14253 roster records\n",
      "  Fetching roster data for 2011...\n",
      "    ✓ Collected 14508 roster records\n",
      "  Fetching roster data for 2012...\n",
      "    ✓ Collected 14966 roster records\n",
      "  Fetching roster data for 2013...\n",
      "    ✓ Collected 15566 roster records\n",
      "  Fetching roster data for 2014...\n",
      "    ✓ Collected 16178 roster records\n",
      "  Fetching roster data for 2015...\n",
      "    ✓ Collected 16426 roster records\n",
      "  Fetching roster data for 2016...\n",
      "    ✓ Collected 18068 roster records\n",
      "  Fetching roster data for 2017...\n",
      "    ✓ Collected 17907 roster records\n",
      "  Fetching roster data for 2018...\n",
      "    ✓ Collected 17940 roster records\n",
      "  Fetching roster data for 2019...\n",
      "    ✓ Collected 18794 roster records\n",
      "  Fetching roster data for 2020...\n",
      "    ✓ Collected 16458 roster records\n",
      "  Fetching roster data for 2021...\n",
      "    ✓ Collected 18698 roster records\n",
      "  Fetching roster data for 2022...\n",
      "    ✓ Collected 30401 roster records\n",
      "  Fetching roster data for 2023...\n",
      "    ✓ Collected 22465 roster records\n",
      "  Fetching roster data for 2024...\n",
      "    ✓ Collected 22843 roster records\n",
      "\n",
      "✓ Saved 310847 roster records to data\\supplemental\\rosters.csv\n",
      "\n",
      "======================================================================\n",
      "PART 4: COLLECTING TEAM RATINGS\n",
      "======================================================================\n",
      "\n",
      "  Fetching ratings for 2000...\n",
      "    ✓ Collected FPI for 0 teams\n",
      "    ✓ Collected SRS for 116 teams\n",
      "  Fetching ratings for 2001...\n",
      "    ✓ Collected FPI for 0 teams\n",
      "    ✓ Collected SRS for 117 teams\n",
      "  Fetching ratings for 2002...\n",
      "    ✓ Collected FPI for 0 teams\n",
      "    ✓ Collected SRS for 117 teams\n",
      "  Fetching ratings for 2003...\n",
      "    ✓ Collected FPI for 0 teams\n",
      "    ✓ Collected SRS for 117 teams\n",
      "  Fetching ratings for 2004...\n",
      "    ✓ Collected FPI for 0 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2005...\n",
      "    ✓ Collected FPI for 119 teams\n",
      "    ✓ Collected SRS for 119 teams\n",
      "  Fetching ratings for 2006...\n",
      "    ✓ Collected FPI for 119 teams\n",
      "    ✓ Collected SRS for 119 teams\n",
      "  Fetching ratings for 2007...\n",
      "    ✓ Collected FPI for 119 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2008...\n",
      "    ✓ Collected FPI for 120 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2009...\n",
      "    ✓ Collected FPI for 120 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2010...\n",
      "    ✓ Collected FPI for 120 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2011...\n",
      "    ✓ Collected FPI for 120 teams\n",
      "    ✓ Collected SRS for 120 teams\n",
      "  Fetching ratings for 2012...\n",
      "    ✓ Collected FPI for 124 teams\n",
      "    ✓ Collected SRS for 124 teams\n",
      "  Fetching ratings for 2013...\n",
      "    ✓ Collected FPI for 126 teams\n",
      "    ✓ Collected SRS for 125 teams\n",
      "  Fetching ratings for 2014...\n",
      "    ✓ Collected FPI for 128 teams\n",
      "    ✓ Collected SRS for 128 teams\n",
      "  Fetching ratings for 2015...\n",
      "    ✓ Collected FPI for 128 teams\n",
      "    ✓ Collected SRS for 128 teams\n",
      "  Fetching ratings for 2016...\n",
      "    ✓ Collected FPI for 128 teams\n",
      "    ✓ Collected SRS for 128 teams\n",
      "  Fetching ratings for 2017...\n",
      "    ✓ Collected FPI for 130 teams\n",
      "    ✓ Collected SRS for 130 teams\n",
      "  Fetching ratings for 2018...\n",
      "    ✓ Collected FPI for 130 teams\n",
      "    ✓ Collected SRS for 130 teams\n",
      "  Fetching ratings for 2019...\n",
      "    ✓ Collected FPI for 130 teams\n",
      "    ✓ Collected SRS for 130 teams\n",
      "  Fetching ratings for 2020...\n",
      "    ✓ Collected FPI for 127 teams\n",
      "    ✓ Collected SRS for 77 teams\n",
      "  Fetching ratings for 2021...\n",
      "    ✓ Collected FPI for 130 teams\n",
      "    ✓ Collected SRS for 130 teams\n",
      "  Fetching ratings for 2022...\n",
      "    ✓ Collected FPI for 131 teams\n",
      "    ✓ Collected SRS for 261 teams\n",
      "  Fetching ratings for 2023...\n",
      "    ✓ Collected FPI for 133 teams\n",
      "    ✓ Collected SRS for 261 teams\n",
      "  Fetching ratings for 2024...\n",
      "    ✓ Collected FPI for 134 teams\n",
      "    ✓ Collected SRS for 264 teams\n",
      "\n",
      "✓ Saved 3492 rating records to data\\supplemental\\team_performance.csv\n",
      "\n",
      "======================================================================\n",
      "DATA COLLECTION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Recruiting graphs: data\\recruiting\n",
      "Performance data: data\\supplemental\n",
      "\n",
      "Files created:\n",
      "  - player_performance.csv\n",
      "  - rosters.csv\n",
      "  - team_performance.csv\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# redoing recruit data\n",
    "\n",
    "import cfbd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "from cfbd.rest import ApiException\n",
    "from config import API_KEY\n",
    "\n",
    "# Initialize API configuration\n",
    "configuration = cfbd.Configuration(access_token=API_KEY)\n",
    "\n",
    "# Create output directories\n",
    "OUTPUT_DIR = Path(\"./data\")\n",
    "RECRUITING_DIR = OUTPUT_DIR / \"recruiting\"\n",
    "PERFORMANCE_DIR = OUTPUT_DIR / \"supplemental\"\n",
    "RECRUITING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PERFORMANCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CFB DATA COLLECTION PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# PART 2: PLAYER PERFORMANCE DATA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: COLLECTING PLAYER PERFORMANCE DATA\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "all_performance_data = []\n",
    "\n",
    "for year in range(2013, 2025):\n",
    "    print(f\"  Fetching performance data for {year}...\")\n",
    "    \n",
    "    try:\n",
    "        performance_api = cfbd.MetricsApi(cfbd.ApiClient(configuration))\n",
    "        performance_data = performance_api.get_predicted_points_added_by_player_season(year=year)\n",
    "        \n",
    "        for player in performance_data:\n",
    "            avg_obj = getattr(player, 'average_ppa', None)\n",
    "            tot_obj = getattr(player, 'total_ppa', None)\n",
    "            all_performance_data.append({\n",
    "                'player_id': getattr(player, 'id', None),\n",
    "                'season': getattr(player, 'season', year),\n",
    "                'name': getattr(player, 'name', None),\n",
    "                'team': getattr(player, 'team', None),\n",
    "                'position': getattr(player, 'position', None),\n",
    "                'conference': getattr(player, 'conference', None),\n",
    "                'averagePPA_all': getattr(avg_obj, 'all', None) if avg_obj else None,\n",
    "                'totalPPA_all': getattr(tot_obj, 'all', None) if tot_obj else None,\n",
    "            })\n",
    "        \n",
    "        print(f\"    ✓ Collected {len(performance_data)} player records\")\n",
    "        time.sleep(1)  # Rate limit protection\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error fetching performance for {year}: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "if all_performance_data:\n",
    "    df_performance = pd.DataFrame(all_performance_data)\n",
    "    output_file = PERFORMANCE_DIR / f\"player_performance.csv\"\n",
    "    df_performance.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Saved {len(df_performance)} performance records to {output_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No performance data collected\")\n",
    "\n",
    "# ============================================\n",
    "# PART 3: TEAM ROSTERS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: COLLECTING TEAM ROSTERS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "all_roster_data = []\n",
    "\n",
    "for year in range(2000, 2025):\n",
    "    print(f\"  Fetching roster data for {year}...\")\n",
    "    \n",
    "    try:\n",
    "        teams_api = cfbd.TeamsApi(cfbd.ApiClient(configuration))\n",
    "        roster_data = teams_api.get_roster(year=year)\n",
    "        \n",
    "        for player in roster_data:\n",
    "            fname = getattr(player, 'first_name', None)\n",
    "            lname = getattr(player, 'last_name', None)\n",
    "            if fname and lname:\n",
    "                name = f\"{fname} {lname}\"\n",
    "            else:\n",
    "                name = fname or lname or None\n",
    "            all_roster_data.append({\n",
    "                'player_id': getattr(player, 'id', None),\n",
    "                'name': name,\n",
    "                'team': getattr(player, 'team', None),\n",
    "                'position': getattr(player, 'position', None),\n",
    "                'year': year,\n",
    "                'recruit_ids': ','.join(getattr(player, 'recruit_ids', [])) if getattr(player, 'recruit_ids', None) else None,\n",
    "            })\n",
    "\n",
    "        print(f\"    ✓ Collected {len(roster_data)} roster records\")\n",
    "        time.sleep(1)  # Rate limit protection\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error fetching rosters for {year}: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "if all_roster_data:\n",
    "    df_rosters = pd.DataFrame(all_roster_data)\n",
    "    output_file = PERFORMANCE_DIR / f\"rosters.csv\"\n",
    "    df_rosters.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Saved {len(df_rosters)} roster records to {output_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No roster data collected\")\n",
    "\n",
    "# ============================================\n",
    "# PART 4: TEAM RATINGS (FPI + SRS)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 4: COLLECTING TEAM RATINGS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "all_ratings_data = []\n",
    "\n",
    "for year in range(2000, 2025):\n",
    "    print(f\"  Fetching ratings for {year}...\")\n",
    "    \n",
    "    # Fetch FPI\n",
    "    fpi_data = {}\n",
    "    try:\n",
    "        ratings_api = cfbd.RatingsApi(cfbd.ApiClient(configuration))\n",
    "        fpi_ratings = ratings_api.get_fpi(year=year)\n",
    "\n",
    "        for rating in fpi_ratings:\n",
    "            team = getattr(rating, 'team', None)\n",
    "            fpi_value = getattr(rating, 'fpi', None)\n",
    "            conference = getattr(rating, 'conference', None)\n",
    "            if team:\n",
    "                fpi_data[team] = {'fpi': fpi_value, 'conference': conference}\n",
    "        \n",
    "        print(f\"    ✓ Collected FPI for {len(fpi_data)} teams\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error fetching FPI for {year}: {e}\")\n",
    "    \n",
    "    # Fetch SRS\n",
    "    srs_data = {}\n",
    "    try:\n",
    "        srs_ratings = ratings_api.get_srs(year=year)\n",
    "        \n",
    "        for rating in srs_ratings:\n",
    "            team = getattr(rating, 'team', None)\n",
    "            srs_value = getattr(rating, 'rating', None)\n",
    "            if team:\n",
    "                srs_data[team] = srs_value\n",
    "        \n",
    "        print(f\"    ✓ Collected SRS for {len(srs_data)} teams\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except ApiException as e:\n",
    "        print(f\"    Error fetching SRS for {year}: {e}\")\n",
    "    \n",
    "    # Merge FPI and SRS\n",
    "    all_teams = set(list(fpi_data.keys()) + list(srs_data.keys()))\n",
    "    for team in all_teams:\n",
    "        all_ratings_data.append({\n",
    "            'school': team,\n",
    "            'year': year,\n",
    "            'fpi': fpi_data.get(team, {}).get('fpi', None),\n",
    "            'srs': srs_data.get(team, None),\n",
    "            'conference': fpi_data.get(team, {}).get('conference', None)\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "if all_ratings_data:\n",
    "    df_ratings = pd.DataFrame(all_ratings_data)\n",
    "    output_file = PERFORMANCE_DIR / f\"team_performance.csv\"\n",
    "    df_ratings.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Saved {len(df_ratings)} rating records to {output_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No ratings data collected\")\n",
    "\n",
    "# ============================================\n",
    "# SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA COLLECTION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nRecruiting graphs: {RECRUITING_DIR}\")\n",
    "print(f\"Performance data: {PERFORMANCE_DIR}\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  - player_performance.csv\")\n",
    "print(f\"  - rosters.csv\")\n",
    "print(f\"  - team_performance.csv\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e2d482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserInfo(patron_level=0, remaining_calls=770)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cfbd.ApiClient(configuration) as api_client:\n",
    "    info = cfbd.InfoApi(api_client)\n",
    "\n",
    "info.get_user_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
