{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2204bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfbd\n",
    "import requests\n",
    "import json\n",
    "from itertools import islice\n",
    "import time\n",
    "from cfbd.rest import ApiException\n",
    "from pprint import pprint\n",
    "import sys, subprocess\n",
    "import networkx as nx\n",
    "from config import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7d977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access api\n",
    "\n",
    "configuration = cfbd.Configuration(\n",
    "    access_token = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting team data to cross ref\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "\n",
    "# This is the only dictionary you need to create here.\n",
    "node_attributes_by_year = {}\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Fetching all team data for attributes for {year}...\")\n",
    "    teams_api = cfbd.TeamsApi(cfbd.ApiClient(configuration))\n",
    "    all_teams = teams_api.get_teams(year=year)\n",
    "    print(f\"Found {len(all_teams)} teams.\")\n",
    "    \n",
    "    current_year_attrs = {}\n",
    "    for team in all_teams:\n",
    "        current_year_attrs[team.school] = {\n",
    "            # Use 'Unknown' as a default string if data is None\n",
    "            'classification': str(team.classification) if team.classification else 'Unknown',\n",
    "            'conference': str(team.conference) if team.conference else 'Unknown',\n",
    "            # Use 0.0 as a default float if data is None\n",
    "            'latitude': float(team.location.latitude) if team.location and team.location.latitude else 0.0,\n",
    "            'longitude': float(team.location.longitude) if team.location and team.location.longitude else 0.0\n",
    "        }\n",
    "    node_attributes_by_year[year] = current_year_attrs\n",
    "\n",
    "print(\"Node attribute maps created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd9d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting transfer portal data\n",
    "\n",
    "# Enter a context with an instance of the API client\n",
    "with cfbd.ApiClient(configuration) as api_client:\n",
    "    # Create an instance of the API class\n",
    "    api_instance = cfbd.PlayersApi(api_client)\n",
    "\n",
    "api_response_2025 = api_instance.get_transfer_portal(year=2025)\n",
    "api_response_2024 = api_instance.get_transfer_portal(year=2024)\n",
    "api_response_2023 = api_instance.get_transfer_portal(year=2023)\n",
    "api_response_2022 = api_instance.get_transfer_portal(year=2022)\n",
    "api_response_2021 = api_instance.get_transfer_portal(year=2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to graphml\n",
    "\n",
    "data_by_year = {\n",
    "    2025: api_response_2025,\n",
    "    2024: api_response_2024,\n",
    "    2023: api_response_2023,\n",
    "    2022: api_response_2022,\n",
    "    2021: api_response_2021\n",
    "}\n",
    "\n",
    "node_attr_map = node_attributes_by_year\n",
    "\n",
    "default_attrs = {\n",
    "    'classification': 'Unknown',\n",
    "    'conference': 'Unknown',\n",
    "    'latitude': 0.0,\n",
    "    'longitude': 0.0\n",
    "}\n",
    "\n",
    "# Add nodes and edges to the graph G based on data\n",
    "# Nodes: school names (origin and destination)\n",
    "# Edges: a directed edge origin -> destination per player; edge attributes aggregate players\n",
    "for year, data in data_by_year.items():\n",
    "    G = nx.DiGraph()\n",
    "    print(f\"Processing data for {year}...\")\n",
    "    for t in data:\n",
    "        origin = t.origin.strip() if getattr(t, 'origin', None) else None\n",
    "        dest = t.destination.strip() if getattr(t, 'destination', None) else None\n",
    "\n",
    "        # add nodes if present\n",
    "        if origin:\n",
    "            G.add_node(origin)\n",
    "        if dest:\n",
    "            G.add_node(dest)\n",
    "\n",
    "        # only create edges when both origin and destination exist\n",
    "        if origin and dest:\n",
    "            player = f\"{getattr(t, 'first_name', '')} {getattr(t, 'last_name', '')}\".strip()\n",
    "            pos = getattr(t, 'position', None)\n",
    "            date = getattr(t, 'transfer_date', None)\n",
    "            date_iso = date.isoformat() if date is not None else None\n",
    "            rating = getattr(t, 'rating', None)\n",
    "            stars = getattr(t, 'stars', None)\n",
    "            eligibility = getattr(t, 'eligibility', None)\n",
    "\n",
    "            if G.has_edge(origin, dest):\n",
    "                edge = G[origin][dest]\n",
    "                edge.setdefault('players', []).append(player)\n",
    "                edge.setdefault('positions', []).append(pos)\n",
    "                edge.setdefault('dates', []).append(date_iso)\n",
    "                edge.setdefault('ratings', []).append(rating)\n",
    "                edge.setdefault('stars', []).append(stars)\n",
    "                edge.setdefault('eligibility', []).append(str(eligibility))\n",
    "                edge['weight'] = edge.get('weight', 1) + 1\n",
    "            else:\n",
    "                G.add_edge(origin, dest, players=[player], positions=[pos], dates=[date_iso], ratings=[rating], stars=[stars], eligibility=[str(eligibility)], weight=1)\n",
    "\n",
    "\n",
    "    # Serialize any list-valued (or None) edge attributes to strings for GraphML compatibility\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        for k in list(attrs.keys()):\n",
    "            val = attrs[k]\n",
    "            if isinstance(val, list):\n",
    "                # join list elements into a single string; convert None -> empty string\n",
    "                attrs[k] = ' | '.join(['' if x is None else str(x) for x in val])\n",
    "            elif val is None:\n",
    "                attrs[k] = ''\n",
    "\n",
    "    #Get the map of attributes for the specific year\n",
    "    current_year_node_attrs = node_attr_map.get(year, {}) # Get the map, or an empty dict\n",
    "\n",
    "    # Create the final mapping, applying defaults to any node not in the map\n",
    "    final_attrs_for_graph = {\n",
    "        node: current_year_node_attrs.get(node, default_attrs) for node in G.nodes()\n",
    "    }\n",
    "\n",
    "    # Set all attributes at once. \n",
    "    # NetworkX unpacks the inner dictionaries automatically.\n",
    "    nx.set_node_attributes(G, final_attrs_for_graph)\n",
    "\n",
    "    # --- 4. VERIFY AND SAVE ---\n",
    "    print(\"\\n--- Verification ---\")\n",
    "    # Check the attributes for a few schools\n",
    "    for school in ['Alabama', 'North Dakota State', 'Ohio State']:\n",
    "        if school in G:\n",
    "            print(f\"School: {school}, Attributes: {G.nodes[school]}\")\n",
    "\n",
    "    filename = f\"transfer_portal_{year}.graphml\"\n",
    "\n",
    "    # write graphml\n",
    "    nx.write_graphml(G, filename)\n",
    "    print(f\"Wrote {len(G.nodes())} nodes and {len(G.edges())} edges to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f35e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Recruiting Data for 27 seasons (2000 to 2026) ---\n",
      "Fetching recruits for 2000...\n",
      "Successfully fetched 119 recruits for 2000.\n",
      "Fetching recruits for 2001...\n",
      "Successfully fetched 129 recruits for 2001.\n",
      "Fetching recruits for 2002...\n",
      "Successfully fetched 1542 recruits for 2002.\n",
      "Fetching recruits for 2003...\n",
      "Successfully fetched 1839 recruits for 2003.\n",
      "Fetching recruits for 2004...\n",
      "Successfully fetched 1896 recruits for 2004.\n",
      "Fetching recruits for 2005...\n",
      "Successfully fetched 1936 recruits for 2005.\n",
      "Fetching recruits for 2006...\n",
      "Successfully fetched 2116 recruits for 2006.\n",
      "Fetching recruits for 2007...\n",
      "Successfully fetched 2165 recruits for 2007.\n",
      "Fetching recruits for 2008...\n",
      "Successfully fetched 2169 recruits for 2008.\n",
      "Fetching recruits for 2009...\n",
      "Successfully fetched 2214 recruits for 2009.\n",
      "Fetching recruits for 2010...\n",
      "Successfully fetched 2445 recruits for 2010.\n",
      "Fetching recruits for 2011...\n",
      "Successfully fetched 2682 recruits for 2011.\n",
      "Fetching recruits for 2012...\n",
      "Successfully fetched 3086 recruits for 2012.\n",
      "Fetching recruits for 2013...\n",
      "Successfully fetched 3430 recruits for 2013.\n",
      "Fetching recruits for 2014...\n",
      "Successfully fetched 3772 recruits for 2014.\n",
      "Fetching recruits for 2015...\n",
      "Successfully fetched 3516 recruits for 2015.\n",
      "Fetching recruits for 2016...\n",
      "Successfully fetched 3937 recruits for 2016.\n",
      "Fetching recruits for 2017...\n",
      "Successfully fetched 4222 recruits for 2017.\n",
      "Fetching recruits for 2018...\n",
      "Successfully fetched 3886 recruits for 2018.\n",
      "Fetching recruits for 2019...\n",
      "Successfully fetched 3992 recruits for 2019.\n",
      "Fetching recruits for 2020...\n",
      "Successfully fetched 3870 recruits for 2020.\n",
      "Fetching recruits for 2021...\n",
      "Successfully fetched 2666 recruits for 2021.\n",
      "Fetching recruits for 2022...\n",
      "Successfully fetched 2198 recruits for 2022.\n",
      "Fetching recruits for 2023...\n",
      "Successfully fetched 2297 recruits for 2023.\n",
      "Fetching recruits for 2024...\n",
      "Successfully fetched 2548 recruits for 2024.\n",
      "Fetching recruits for 2025...\n",
      "Successfully fetched 2507 recruits for 2025.\n",
      "Fetching recruits for 2026...\n",
      "Successfully fetched 2384 recruits for 2026.\n",
      "\n",
      "--- All recruiting data fetched successfully! ---\n",
      "Data is stored in the 'recruits_by_year' dictionary.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "recruit_api = cfbd.RecruitingApi(cfbd.ApiClient(configuration))\n",
    "recruits_by_year = {}\n",
    "\n",
    "start_year = 2000 # First year of available recruiting data\n",
    "current_year = datetime.datetime.now().year\n",
    "end_year = current_year + 1 # Add 1 to get the *next* recruiting class\n",
    "\n",
    "# Create the full list of years to fetch\n",
    "years_to_fetch = list(range(start_year, end_year + 1)) # +1 because range() is exclusive\n",
    "\n",
    "print(f\"--- Fetching Recruiting Data for {len(years_to_fetch)} seasons ({start_year} to {end_year}) ---\")\n",
    "\n",
    "# --- 3. Iterate and Fetch Data ---\n",
    "try:\n",
    "    for year in years_to_fetch:\n",
    "        print(f\"Fetching recruits for {year}...\")\n",
    "        api_response = recruit_api.get_recruits(year=year)\n",
    "        \n",
    "        recruits_by_year[year] = api_response\n",
    "        print(f\"Successfully fetched {len(api_response)} recruits for {year}.\")\n",
    "        \n",
    "    print(\"\\n--- All recruiting data fetched successfully! ---\")\n",
    "    print(\"Data is stored in the 'recruits_by_year' dictionary.\")\n",
    "\n",
    "except ApiException as e:\n",
    "    print(f\"Error calling RecruitsApi->get_recruits: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355dfc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Bipartite Recruiting Graphs ---\n",
      "\n",
      "Processing recruiting data for 2000...\n",
      "Wrote 151 nodes (40 schools, 111 hometowns) and 117 edges to recruiting_network_2000.graphml\n",
      "\n",
      "Processing recruiting data for 2001...\n",
      "Wrote 169 nodes (50 schools, 119 hometowns) and 125 edges to recruiting_network_2001.graphml\n",
      "\n",
      "Processing recruiting data for 2002...\n",
      "Wrote 812 nodes (108 schools, 704 hometowns) and 1039 edges to recruiting_network_2002.graphml\n",
      "\n",
      "Processing recruiting data for 2003...\n",
      "Wrote 901 nodes (118 schools, 783 hometowns) and 1190 edges to recruiting_network_2003.graphml\n",
      "\n",
      "Processing recruiting data for 2004...\n",
      "Wrote 923 nodes (119 schools, 804 hometowns) and 1242 edges to recruiting_network_2004.graphml\n",
      "\n",
      "Processing recruiting data for 2005...\n",
      "Wrote 929 nodes (118 schools, 811 hometowns) and 1287 edges to recruiting_network_2005.graphml\n",
      "\n",
      "Processing recruiting data for 2006...\n",
      "Wrote 1013 nodes (120 schools, 893 hometowns) and 1553 edges to recruiting_network_2006.graphml\n",
      "\n",
      "Processing recruiting data for 2007...\n",
      "Wrote 1033 nodes (116 schools, 917 hometowns) and 1551 edges to recruiting_network_2007.graphml\n",
      "\n",
      "Processing recruiting data for 2008...\n",
      "Wrote 1094 nodes (118 schools, 976 hometowns) and 1647 edges to recruiting_network_2008.graphml\n",
      "\n",
      "Processing recruiting data for 2009...\n",
      "Wrote 1074 nodes (117 schools, 957 hometowns) and 1607 edges to recruiting_network_2009.graphml\n",
      "\n",
      "Processing recruiting data for 2010...\n",
      "Wrote 1120 nodes (124 schools, 996 hometowns) and 1832 edges to recruiting_network_2010.graphml\n",
      "\n",
      "Processing recruiting data for 2011...\n",
      "Wrote 1133 nodes (139 schools, 994 hometowns) and 1833 edges to recruiting_network_2011.graphml\n",
      "\n",
      "Processing recruiting data for 2012...\n",
      "Wrote 1305 nodes (184 schools, 1121 hometowns) and 2148 edges to recruiting_network_2012.graphml\n",
      "\n",
      "Processing recruiting data for 2013...\n",
      "Wrote 1278 nodes (207 schools, 1071 hometowns) and 2124 edges to recruiting_network_2013.graphml\n",
      "\n",
      "Processing recruiting data for 2014...\n",
      "Wrote 1380 nodes (230 schools, 1150 hometowns) and 2204 edges to recruiting_network_2014.graphml\n",
      "\n",
      "Processing recruiting data for 2015...\n",
      "Wrote 1379 nodes (228 schools, 1151 hometowns) and 2132 edges to recruiting_network_2015.graphml\n",
      "\n",
      "Processing recruiting data for 2016...\n",
      "Wrote 1427 nodes (235 schools, 1192 hometowns) and 2440 edges to recruiting_network_2016.graphml\n",
      "\n",
      "Processing recruiting data for 2017...\n",
      "Wrote 1454 nodes (235 schools, 1219 hometowns) and 2525 edges to recruiting_network_2017.graphml\n",
      "\n",
      "Processing recruiting data for 2018...\n",
      "Wrote 1488 nodes (228 schools, 1260 hometowns) and 2770 edges to recruiting_network_2018.graphml\n",
      "\n",
      "Processing recruiting data for 2019...\n",
      "Wrote 1286 nodes (226 schools, 1060 hometowns) and 2095 edges to recruiting_network_2019.graphml\n",
      "\n",
      "Processing recruiting data for 2020...\n",
      "Wrote 1358 nodes (232 schools, 1126 hometowns) and 2222 edges to recruiting_network_2020.graphml\n",
      "\n",
      "Processing recruiting data for 2021...\n",
      "Wrote 1136 nodes (200 schools, 936 hometowns) and 1679 edges to recruiting_network_2021.graphml\n",
      "\n",
      "Processing recruiting data for 2022...\n",
      "Wrote 1005 nodes (183 schools, 822 hometowns) and 1479 edges to recruiting_network_2022.graphml\n",
      "\n",
      "Processing recruiting data for 2023...\n",
      "Wrote 1043 nodes (176 schools, 867 hometowns) and 1647 edges to recruiting_network_2023.graphml\n",
      "\n",
      "Processing recruiting data for 2024...\n",
      "Wrote 1136 nodes (189 schools, 947 hometowns) and 1797 edges to recruiting_network_2024.graphml\n",
      "\n",
      "Processing recruiting data for 2025...\n",
      "Wrote 1133 nodes (187 schools, 946 hometowns) and 1838 edges to recruiting_network_2025.graphml\n",
      "\n",
      "Processing recruiting data for 2026...\n",
      "Wrote 982 nodes (160 schools, 822 hometowns) and 1590 edges to recruiting_network_2026.graphml\n",
      "\n",
      "--- All recruiting graphs saved successfully! ---\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "print(\"--- Building Bipartite Recruiting Graphs ---\")\n",
    "\n",
    "# Get the school attribute map from the previous cell\n",
    "school_attr_map = node_attributes_by_year \n",
    "\n",
    "# Define default school attributes\n",
    "default_school_attrs = {\n",
    "    'classification': 'Unknown',\n",
    "    'conference': 'Unknown',\n",
    "    'latitude': 0.0,\n",
    "    'longitude': 0.0\n",
    "}\n",
    "\n",
    "# Loop over the raw data we just fetched\n",
    "for year, data in recruits_by_year.items():\n",
    "    G = nx.Graph() # Bipartite graphs are typically undirected\n",
    "    print(f\"\\nProcessing recruiting data for {year}...\")\n",
    "\n",
    "    hometown_node_attrs = {} # Dict to store attributes for hometown nodes\n",
    "    school_node_attrs = {}   # Dict to store attributes for school nodes\n",
    "\n",
    "    for t in data:\n",
    "        # --- 1. Get School Node (Set 0) ---\n",
    "        school = getattr(t, 'committed_to', None)\n",
    "        \n",
    "        # --- 2. Get Hometown Node (Set 1) ---\n",
    "        \n",
    "        # Get city and state from the TOP-LEVEL recruit object\n",
    "        city = getattr(t, 'city', None)\n",
    "        state = getattr(t, 'state_province', None)\n",
    "        \n",
    "        # Get the hometown_info object ONLY for coordinates\n",
    "        hometown_info = getattr(t, 'hometown_info', None)\n",
    "        \n",
    "        hometown_key = None\n",
    "        # We need city and state to create a unique hometown key\n",
    "        if city and state:\n",
    "            hometown_key = f\"{city}, {state}\"\n",
    "        \n",
    "        # --- 3. We need BOTH nodes to create an edge ---\n",
    "        if not school or not hometown_key:\n",
    "            continue # Skip this recruit if they aren't committed or have no hometown\n",
    "\n",
    "        # --- 4. Add Nodes and Gather Attributes ---\n",
    "        \n",
    "        # Add School Node (if it's not already in the graph)\n",
    "        if school not in G:\n",
    "            G.add_node(school, bipartite=0, type='School')\n",
    "            # Get its attributes from the map we built earlier\n",
    "            school_node_attrs[school] = school_attr_map.get(year, {}).get(school, default_school_attrs)\n",
    "        \n",
    "        # Add Hometown Node (if it's not already in the graph)\n",
    "        if hometown_key not in G:\n",
    "            G.add_node(hometown_key, bipartite=1, type='Hometown')\n",
    "            # Store its attributes\n",
    "            hometown_node_attrs[hometown_key] = {\n",
    "                # Get lat/long from the hometown_info object\n",
    "                'latitude': float(hometown_info.latitude) if hometown_info and hometown_info.latitude else 0.0,\n",
    "                'longitude': float(hometown_info.longitude) if hometown_info and hometown_info.longitude else 0.0,\n",
    "                # Get city/state from the top-level variables\n",
    "                'city': city,\n",
    "                'state': state\n",
    "            }\n",
    "\n",
    "        # --- 5. Get Edge Attributes ---\n",
    "        # These are all the attributes you requested\n",
    "        player = getattr(t, 'name', 'Unknown')\n",
    "        pos = getattr(t, 'position', 'N/A')\n",
    "        rating = getattr(t, 'rating', 0.0) # Use 0.0 for None\n",
    "        recruit_type = getattr(t, 'recruit_type', 'N/A')\n",
    "        stars = getattr(t, 'stars', 0) # Use 0 for None\n",
    "\n",
    "        # --- 6. Add/Update the Edge ---\n",
    "        if G.has_edge(hometown_key, school):\n",
    "            edge = G[hometown_key][school]\n",
    "            edge['players'].append(player)\n",
    "            edge['positions'].append(pos)\n",
    "            edge['ratings'].append(rating)\n",
    "            edge['stars'].append(stars)\n",
    "            edge['recruit_types'].append(recruit_type)\n",
    "            edge['weight'] = edge.get('weight', 0) + 1\n",
    "        else:\n",
    "            G.add_edge(hometown_key, school, \n",
    "                       players=[player], \n",
    "                       positions=[pos], \n",
    "                       ratings=[rating],\n",
    "                       stars=[stars],\n",
    "                       recruit_types=[recruit_type], \n",
    "                       weight=1)\n",
    "    \n",
    "    # --- 7. Apply All Node Attributes ---\n",
    "    nx.set_node_attributes(G, school_node_attrs)\n",
    "    nx.set_node_attributes(G, hometown_node_attrs)\n",
    "    \n",
    "    # --- 8. Serialize Edge Lists for GraphML ---\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        for k in list(attrs.keys()):\n",
    "            val = attrs[k]\n",
    "            if isinstance(val, list):\n",
    "                attrs[k] = ' | '.join(['' if x is None else str(x) for x in val])\n",
    "            elif val is None:\n",
    "                attrs[k] = ''\n",
    "\n",
    "    # --- 9. Save the GraphML File ---\n",
    "    filename = f\"recruiting_network_{year}.graphml\"\n",
    "    nx.write_graphml(G, filename)\n",
    "    print(f\"Wrote {len(G.nodes())} nodes ({len(school_node_attrs)} schools, {len(hometown_node_attrs)} hometowns) and {len(G.edges())} edges to {filename}\")\n",
    "\n",
    "print(\"\\n--- All recruiting graphs saved successfully! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
