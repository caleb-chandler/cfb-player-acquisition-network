{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cc2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f3e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 5 files from xfer and 27 files from rec.\n"
     ]
    }
   ],
   "source": [
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\raw\")\n",
    "recpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\recruiting\\original\")\n",
    "xferfiles = {}\n",
    "recfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "for file_path in recpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_r = nx.read_graphml(file_path)\n",
    "    recfiles[name] = G_r\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(xferfiles)} files from xfer and {len(recfiles)} files from rec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cffa2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 transfer portal files\n",
      "\n",
      "============================================================\n",
      "ANALYZING CURRENT DATA STATE\n",
      "============================================================\n",
      "\n",
      "transfer_portal_2021:\n",
      "  Edges: 958\n",
      "  Players: 1053\n",
      "  Multi-player edges: 77\n",
      "\n",
      "transfer_portal_2022:\n",
      "  Edges: 1225\n",
      "  Players: 1367\n",
      "  Multi-player edges: 113\n",
      "\n",
      "transfer_portal_2023:\n",
      "  Edges: 1413\n",
      "  Players: 1607\n",
      "  Multi-player edges: 140\n",
      "\n",
      "transfer_portal_2024:\n",
      "  Edges: 2340\n",
      "  Players: 2654\n",
      "  Multi-player edges: 224\n",
      "\n",
      "transfer_portal_2025:\n",
      "  Edges: 3296\n",
      "  Players: 3765\n",
      "  Multi-player edges: 337\n",
      "\n",
      "============================================================\n",
      "BUILDING STAR-TO-RATING MAPPING FROM EXISTING DATA\n",
      "============================================================\n",
      "\n",
      "Rating statistics by star level:\n",
      "------------------------------------------------------------\n",
      "1 Stars: No data available\n",
      "\n",
      "2 Stars:\n",
      "  Count: 108\n",
      "  Mean:   0.7850\n",
      "  Median: 0.7900\n",
      "  Std:    0.0109\n",
      "  Range:  0.7300 - 0.7900\n",
      "\n",
      "3 Stars:\n",
      "  Count: 5476\n",
      "  Mean:   0.8496\n",
      "  Median: 0.8500\n",
      "  Std:    0.0236\n",
      "  Range:  0.8000 - 0.8900\n",
      "\n",
      "4 Stars:\n",
      "  Count: 655\n",
      "  Mean:   0.9125\n",
      "  Median: 0.9100\n",
      "  Std:    0.0146\n",
      "  Range:  0.9000 - 0.9700\n",
      "\n",
      "5 Stars:\n",
      "  Count: 16\n",
      "  Mean:   0.9850\n",
      "  Median: 0.9800\n",
      "  Std:    0.0071\n",
      "  Range:  0.9800 - 1.0000\n",
      "\n",
      "============================================================\n",
      "SPLITTING MULTI-PLAYER EDGES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Edges: 958 → 1051 (+93)\n",
      "  Players processed: 1053\n",
      "  Duplicates merged: 2\n",
      "\n",
      "Processing transfer_portal_2022...\n",
      "  Edges: 1225 → 1364 (+139)\n",
      "  Players processed: 1367\n",
      "  Duplicates merged: 3\n",
      "\n",
      "Processing transfer_portal_2023...\n",
      "  Edges: 1413 → 1603 (+190)\n",
      "  Players processed: 1607\n",
      "  Duplicates merged: 4\n",
      "\n",
      "Processing transfer_portal_2024...\n",
      "  Edges: 2340 → 2646 (+306)\n",
      "  Players processed: 2654\n",
      "  Duplicates merged: 8\n",
      "\n",
      "Processing transfer_portal_2025...\n",
      "  Edges: 3296 → 3751 (+455)\n",
      "  Players processed: 3765\n",
      "  Duplicates merged: 14\n",
      "\n",
      "\n",
      "============================================================\n",
      "IMPUTING MISSING RATINGS WITH STAR-TO-RATING VALUES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Imputed 639 out of 1051 player ratings\n",
      "Processing transfer_portal_2022...\n",
      "  Imputed 410 out of 1364 player ratings\n",
      "Processing transfer_portal_2023...\n",
      "  Imputed 698 out of 1603 player ratings\n",
      "Processing transfer_portal_2024...\n",
      "  Imputed 641 out of 2646 player ratings\n",
      "Processing transfer_portal_2025...\n",
      "  Imputed 834 out of 3751 player ratings\n",
      "\n",
      "============================================================\n",
      "SAVING CLEANED GRAPHS\n",
      "============================================================\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2021_cleaned.graphml\n",
      "  Nodes: 264\n",
      "  Edges: 1051\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2022_cleaned.graphml\n",
      "  Nodes: 282\n",
      "  Edges: 1364\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2023_cleaned.graphml\n",
      "  Nodes: 283\n",
      "  Edges: 1603\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2024_cleaned.graphml\n",
      "  Nodes: 352\n",
      "  Edges: 2646\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2025_cleaned.graphml\n",
      "  Nodes: 410\n",
      "  Edges: 3751\n",
      "\n",
      "✓ All graphs cleaned and saved!\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "               Graph  Original Edges  Cleaned Edges  Change  Percent Increase\n",
      "transfer_portal_2021             958           1051      93          9.707724\n",
      "transfer_portal_2022            1225           1364     139         11.346939\n",
      "transfer_portal_2023            1413           1603     190         13.446568\n",
      "transfer_portal_2024            2340           2646     306         13.076923\n",
      "transfer_portal_2025            3296           3751     455         13.804612\n",
      "\n",
      "============================================================\n",
      "STAR-TO-RATING MAPPING TABLE\n",
      "============================================================\n",
      "\n",
      "           mean  median       std   min   max   count\n",
      "Stars                                                \n",
      "1           NaN     NaN       NaN   NaN   NaN     NaN\n",
      "2      0.785000    0.79  0.010929  0.73  0.79   108.0\n",
      "3      0.849648    0.85  0.023627  0.80  0.89  5476.0\n",
      "4      0.912504    0.91  0.014614  0.90  0.97   655.0\n",
      "5      0.985000    0.98  0.007071  0.98  1.00    16.0\n",
      "\n",
      "✓ Mapping table saved to: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\star_rating_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load your transfer portal graphs\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\raw\")\n",
    "xferfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "print(f\"Loaded {len(xferfiles)} transfer portal files\\n\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: ANALYZE CURRENT STATE\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYZING CURRENT DATA STATE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    total_edges = len(graph.edges())\n",
    "    total_players = 0\n",
    "    multi_player_edges = 0\n",
    "    \n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        players_str = data.get('players', '')\n",
    "        if players_str:\n",
    "            player_list = [p.strip() for p in players_str.split('|')]\n",
    "            total_players += len(player_list)\n",
    "            if len(player_list) > 1:\n",
    "                multi_player_edges += 1\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Edges: {total_edges}\")\n",
    "    print(f\"  Players: {total_players}\")\n",
    "    print(f\"  Multi-player edges: {multi_player_edges}\")\n",
    "    print()\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: BUILD STAR-TO-RATING MAPPING\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING STAR-TO-RATING MAPPING FROM EXISTING DATA\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "all_ratings_by_star = {1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        ratings_str = data.get('ratings', '')\n",
    "        stars_str = data.get('stars', '')\n",
    "        \n",
    "        if not ratings_str or not stars_str:\n",
    "            continue\n",
    "        \n",
    "        # Split by pipe and clean\n",
    "        ratings_list = [r.strip() for r in ratings_str.split('|')]\n",
    "        stars_list = [st.strip() for st in stars_str.split('|')]\n",
    "        \n",
    "        # Match up ratings with stars\n",
    "        for rating, star in zip(ratings_list, stars_list):\n",
    "            try:\n",
    "                rating_val = float(rating) if rating and rating != '' and rating != 'None' else None\n",
    "                star_val = int(float(star)) if star and star != '' and star != 'None' else None\n",
    "                \n",
    "                if rating_val is not None and star_val is not None and 1 <= star_val <= 5:\n",
    "                    all_ratings_by_star[star_val].append(rating_val)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "# Calculate statistics for each star level\n",
    "print(\"Rating statistics by star level:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "star_rating_map = {}\n",
    "for star in sorted(all_ratings_by_star.keys()):\n",
    "    ratings = all_ratings_by_star[star]\n",
    "    if ratings:\n",
    "        mean_rating = np.mean(ratings)\n",
    "        median_rating = np.median(ratings)\n",
    "        std_rating = np.std(ratings)\n",
    "        min_rating = np.min(ratings)\n",
    "        max_rating = np.max(ratings)\n",
    "        \n",
    "        star_rating_map[star] = {\n",
    "            'mean': mean_rating,\n",
    "            'median': median_rating,\n",
    "            'std': std_rating,\n",
    "            'min': min_rating,\n",
    "            'max': max_rating,\n",
    "            'count': len(ratings)\n",
    "        }\n",
    "        \n",
    "        print(f\"{star} Stars:\")\n",
    "        print(f\"  Count: {len(ratings)}\")\n",
    "        print(f\"  Mean:   {mean_rating:.4f}\")\n",
    "        print(f\"  Median: {median_rating:.4f}\")\n",
    "        print(f\"  Std:    {std_rating:.4f}\")\n",
    "        print(f\"  Range:  {min_rating:.4f} - {max_rating:.4f}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{star} Stars: No data available\\n\")\n",
    "        star_rating_map[star] = {'mean': None, 'median': None}\n",
    "\n",
    "# Define fallback function\n",
    "def get_fallback_rating(star_value, method='median'):\n",
    "    \"\"\"Returns a fallback rating based on star value.\"\"\"\n",
    "    try:\n",
    "        star = int(float(star_value))\n",
    "        if star in star_rating_map and star_rating_map[star][method] is not None:\n",
    "            return star_rating_map[star][method]\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    return 0.0\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: SPLIT EDGES BY PLAYER\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPLITTING MULTI-PLAYER EDGES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def are_same_person(name1, name2):\n",
    "    \"\"\"\n",
    "    Returns True if two players share the same last name, \n",
    "    ignoring suffixes like Jr, Sr, III.\n",
    "    \"\"\"\n",
    "    if not name1 or not name2:\n",
    "        return False\n",
    "\n",
    "    def get_cleaned_last_name(full_name):\n",
    "        parts = full_name.strip().lower().split()\n",
    "        \n",
    "        if not parts:\n",
    "            return \"\"\n",
    "\n",
    "        suffixes = {'jr', 'jr.', 'sr', 'sr.', 'ii', 'iii', 'iv', 'v'}\n",
    "\n",
    "        while len(parts) > 1 and parts[-1] in suffixes:\n",
    "            parts.pop()\n",
    "            \n",
    "        return parts[-1]\n",
    "\n",
    "    return get_cleaned_last_name(name1) == get_cleaned_last_name(name2)\n",
    "\n",
    "cleaned_graphs = {}\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    # Create new MULTI-graph to support multiple edges between same nodes\n",
    "    G_new = nx.MultiDiGraph()\n",
    "    \n",
    "    # Copy node attributes\n",
    "    for node, attrs in graph.nodes(data=True):\n",
    "        G_new.add_node(node, **attrs)\n",
    "    \n",
    "    edges_before = len(graph.edges())\n",
    "    edges_after = 0\n",
    "    players_processed = 0\n",
    "    duplicates_merged = 0\n",
    "    \n",
    "    # Process each edge\n",
    "    for source, target, data in graph.edges(data=True):\n",
    "        # Extract all the pipe-separated attributes\n",
    "        players_str = data.get('players', '')\n",
    "        positions_str = data.get('positions', '')\n",
    "        dates_str = data.get('dates', '')\n",
    "        ratings_str = data.get('ratings', '')\n",
    "        stars_str = data.get('stars', '')\n",
    "        eligibility_str = data.get('eligibility', '')\n",
    "        \n",
    "        if not players_str:\n",
    "            continue\n",
    "        \n",
    "        # Split all attributes by pipe\n",
    "        players = [p.strip() for p in players_str.split('|')]\n",
    "        positions = [p.strip() for p in positions_str.split('|')] if positions_str else [''] * len(players)\n",
    "        dates = [d.strip() for d in dates_str.split('|')] if dates_str else [''] * len(players)\n",
    "        ratings = [r.strip() for r in ratings_str.split('|')] if ratings_str else [''] * len(players)\n",
    "        stars = [s.strip() for s in stars_str.split('|')] if stars_str else [''] * len(players)\n",
    "        eligibility = [e.strip() for e in eligibility_str.split('|')] if eligibility_str else [''] * len(players)\n",
    "        \n",
    "        # Pad shorter lists to match players list length\n",
    "        max_len = len(players)\n",
    "        positions += [''] * (max_len - len(positions))\n",
    "        dates += [''] * (max_len - len(dates))\n",
    "        ratings += [''] * (max_len - len(ratings))\n",
    "        stars += [''] * (max_len - len(stars))\n",
    "        eligibility += [''] * (max_len - len(eligibility))\n",
    "        \n",
    "        # Group players by unique identity\n",
    "        player_groups = defaultdict(list)\n",
    "        \n",
    "        for i, player in enumerate(players):\n",
    "            players_processed += 1\n",
    "            \n",
    "            # Check if this player is already in our groups\n",
    "            merged = False\n",
    "            for existing_player in list(player_groups.keys()):\n",
    "                if are_same_person(player, existing_player):\n",
    "                    # Merge with existing entry\n",
    "                    player_groups[existing_player].append({\n",
    "                        'player': player,\n",
    "                        'position': positions[i],\n",
    "                        'date': dates[i],\n",
    "                        'rating': ratings[i],\n",
    "                        'stars': stars[i],\n",
    "                        'eligibility': eligibility[i]\n",
    "                    })\n",
    "                    duplicates_merged += 1\n",
    "                    merged = True\n",
    "                    break\n",
    "            \n",
    "            if not merged:\n",
    "                # Create new entry\n",
    "                player_groups[player].append({\n",
    "                    'player': player,\n",
    "                    'position': positions[i],\n",
    "                    'date': dates[i],\n",
    "                    'rating': ratings[i],\n",
    "                    'stars': stars[i],\n",
    "                    'eligibility': eligibility[i]\n",
    "                })\n",
    "        \n",
    "        # Create one edge per unique player\n",
    "        # KEY FIX: Use MultiDiGraph or unique edge keys\n",
    "        for player_name, player_data_list in player_groups.items():\n",
    "            # For duplicate entries, take the first non-empty value for each attribute\n",
    "            def get_best_value(attr_name):\n",
    "                values = [pd[attr_name] for pd in player_data_list]\n",
    "                for v in values:\n",
    "                    if v and v != '' and v != 'None':\n",
    "                        return v\n",
    "                return ''\n",
    "            \n",
    "            final_data = {\n",
    "                'players': player_name,\n",
    "                'positions': get_best_value('position'),\n",
    "                'dates': get_best_value('date'),\n",
    "                'ratings': get_best_value('rating'),\n",
    "                'stars': get_best_value('stars'),\n",
    "                'eligibility': get_best_value('eligibility'),\n",
    "                'weight': 1\n",
    "            }\n",
    "            \n",
    "            # Add edge (MultiDiGraph automatically handles multiple edges)\n",
    "            G_new.add_edge(source, target, **final_data)\n",
    "            edges_after += 1\n",
    "    \n",
    "    print(f\"  Edges: {edges_before} → {edges_after} (+{edges_after - edges_before})\")\n",
    "    print(f\"  Players processed: {players_processed}\")\n",
    "    print(f\"  Duplicates merged: {duplicates_merged}\") \n",
    "    print()\n",
    "    \n",
    "    cleaned_graphs[name] = G_new\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: IMPUTE MISSING RATINGS WITH STAR VALUES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPUTING MISSING RATINGS WITH STAR-TO-RATING VALUES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in cleaned_graphs.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    imputed_count = 0\n",
    "    total_players = 0\n",
    "    \n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        rating_str = data.get('ratings', '')\n",
    "        star_str = data.get('stars', '')\n",
    "        \n",
    "        total_players += 1\n",
    "        \n",
    "        # If rating is missing but star exists, use fallback\n",
    "        if (not rating_str or rating_str == '' or rating_str == 'None') and star_str and star_str != '' and star_str != 'None':\n",
    "            fallback = get_fallback_rating(star_str, method='median')\n",
    "            data['ratings'] = str(fallback)\n",
    "            imputed_count += 1\n",
    "    \n",
    "    print(f\"  Imputed {imputed_count} out of {total_players} player ratings\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: SAVE CLEANED GRAPHS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING CLEANED GRAPHS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, graph in cleaned_graphs.items():\n",
    "    output_file = output_path / f\"{name}_cleaned.graphml\"\n",
    "    nx.write_graphml(graph, output_file)\n",
    "    print(f\"Saved: {output_file}\")\n",
    "    print(f\"  Nodes: {len(graph.nodes())}\")\n",
    "    print(f\"  Edges: {len(graph.edges())}\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ All graphs cleaned and saved!\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 6: SUMMARY STATISTICS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_data = []\n",
    "for name in xferfiles.keys():\n",
    "    original = xferfiles[name]\n",
    "    cleaned = cleaned_graphs[name]\n",
    "    \n",
    "    orig_edges = len(original.edges())\n",
    "    clean_edges = len(cleaned.edges())\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Graph': name,\n",
    "        'Original Edges': orig_edges,\n",
    "        'Cleaned Edges': clean_edges,\n",
    "        'Change': clean_edges - orig_edges,\n",
    "        'Percent Increase': ((clean_edges - orig_edges) / orig_edges * 100) if orig_edges > 0 else 0\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# STEP 7: EXPORT MAPPING TABLE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAR-TO-RATING MAPPING TABLE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "mapping_df = pd.DataFrame.from_dict(star_rating_map, orient='index')\n",
    "mapping_df.index.name = 'Stars'\n",
    "print(mapping_df.to_string())\n",
    "\n",
    "# Save mapping to CSV\n",
    "mapping_csv = output_path / \"star_rating_mapping.csv\"\n",
    "mapping_df.to_csv(mapping_csv)\n",
    "print(f\"\\n✓ Mapping table saved to: {mapping_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e380ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRANSFER PORTAL GRAPHS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2021_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 19/264 nodes (7.2%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.', 'Texas-Permian Basin']\n",
      "  conference:\n",
      "    Missing in 19/264 nodes (7.2%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.', 'Texas-Permian Basin']\n",
      "  latitude:\n",
      "    Missing in 23/264 nodes (8.7%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'Northwestern', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.']\n",
      "  longitude:\n",
      "    Missing in 23/264 nodes (8.7%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'Northwestern', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 104/1051 edges (9.9%)\n",
      "    Sample edges: [('Missouri Western State', 'Kansas'), ('Kansas', 'Butler C.C.'), ('Kansas', 'Kansas State'), ('Kansas', 'UTSA'), ('Florida State', 'Troy')]\n",
      "  stars:\n",
      "    Missing in 104/1051 edges (9.9%)\n",
      "    Sample edges: [('Missouri Western State', 'Kansas'), ('Kansas', 'Butler C.C.'), ('Kansas', 'Kansas State'), ('Kansas', 'UTSA'), ('Florida State', 'Troy')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2022_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 23/282 nodes (8.2%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Trinity Valley C.C.']\n",
      "  conference:\n",
      "    Missing in 23/282 nodes (8.2%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Trinity Valley C.C.']\n",
      "  latitude:\n",
      "    Missing in 27/282 nodes (9.6%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Florida International']\n",
      "  longitude:\n",
      "    Missing in 27/282 nodes (9.6%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Florida International']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 123/1364 edges (9.0%)\n",
      "    Sample edges: [('East Carolina', 'Winston-Salem State'), ('East Carolina', 'Alabama A&M'), ('Tennessee State', 'Troy'), ('Dartmouth', 'New Mexico State'), ('Simon Fraser', 'Washington State')]\n",
      "  stars:\n",
      "    Missing in 123/1364 edges (9.0%)\n",
      "    Sample edges: [('East Carolina', 'Winston-Salem State'), ('East Carolina', 'Alabama A&M'), ('Tennessee State', 'Troy'), ('Dartmouth', 'New Mexico State'), ('Simon Fraser', 'Washington State')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2023_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 23/283 nodes (8.1%)\n",
      "    Sample nodes: ['Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Coffeyville C.C.', 'Laney College']\n",
      "  conference:\n",
      "    Missing in 23/283 nodes (8.1%)\n",
      "    Sample nodes: ['Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Coffeyville C.C.', 'Laney College']\n",
      "  latitude:\n",
      "    Missing in 25/283 nodes (8.8%)\n",
      "    Sample nodes: ['Florida International', 'Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Northwestern']\n",
      "  longitude:\n",
      "    Missing in 25/283 nodes (8.8%)\n",
      "    Sample nodes: ['Florida International', 'Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Northwestern']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 39/1603 edges (2.4%)\n",
      "    Sample edges: [('Air Force', 'Palomar College'), ('UNLV', 'Cerritos College'), ('California', 'Nevada'), ('California', 'Arizona State'), ('Houston', 'Southern Miss')]\n",
      "  stars:\n",
      "    Missing in 39/1603 edges (2.4%)\n",
      "    Sample edges: [('Air Force', 'Palomar College'), ('UNLV', 'Cerritos College'), ('California', 'Nevada'), ('California', 'Arizona State'), ('Houston', 'Southern Miss')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2024_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 47/352 nodes (13.4%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'CSU-Pueblo', 'Missouri Western State']\n",
      "  conference:\n",
      "    Missing in 47/352 nodes (13.4%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'CSU-Pueblo', 'Missouri Western State']\n",
      "  latitude:\n",
      "    Missing in 51/352 nodes (14.5%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'Florida International', 'West Florida']\n",
      "  longitude:\n",
      "    Missing in 51/352 nodes (14.5%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'Florida International', 'West Florida']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 213/2646 edges (8.0%)\n",
      "    Sample edges: [('Georgia', 'Jacksonville State'), ('Washington State', 'Nevada'), ('Arkansas', 'Missouri State'), ('Arkansas', 'North Texas'), ('Arkansas', 'McNeese')]\n",
      "  stars:\n",
      "    Missing in 213/2646 edges (8.0%)\n",
      "    Sample edges: [('Georgia', 'Jacksonville State'), ('Washington State', 'Nevada'), ('Arkansas', 'Missouri State'), ('Arkansas', 'North Texas'), ('Arkansas', 'McNeese')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2025_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 66/410 nodes (16.1%)\n",
      "    Sample nodes: [\"King's College\", 'Albany', 'American River C.C.', 'UNC-Pembroke', 'Hinds C.C.']\n",
      "  conference:\n",
      "    Missing in 66/410 nodes (16.1%)\n",
      "    Sample nodes: [\"King's College\", 'Albany', 'American River C.C.', 'UNC-Pembroke', 'Hinds C.C.']\n",
      "  latitude:\n",
      "    Missing in 71/410 nodes (17.3%)\n",
      "    Sample nodes: [\"King's College\", 'Florida International', 'Albany', 'American River C.C.', 'UNC-Pembroke']\n",
      "  longitude:\n",
      "    Missing in 71/410 nodes (17.3%)\n",
      "    Sample nodes: [\"King's College\", 'Florida International', 'Albany', 'American River C.C.', 'UNC-Pembroke']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 480/3751 edges (12.8%)\n",
      "    Sample edges: [('Richmond', 'East Carolina'), ('Richmond', 'James Madison'), ('East Carolina', 'Chattanooga'), ('East Carolina', 'Harding University'), ('East Carolina', 'App State')]\n",
      "  stars:\n",
      "    Missing in 480/3751 edges (12.8%)\n",
      "    Sample edges: [('Richmond', 'East Carolina'), ('Richmond', 'James Madison'), ('East Carolina', 'Chattanooga'), ('East Carolina', 'Harding University'), ('East Carolina', 'App State')]\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "OVERALL SUMMARY\n",
      "============================================================\n",
      "\n",
      "                       Graph  Node Attrs  Edge Attrs  Missing Node Attrs  Missing Edge Attrs\n",
      "transfer_portal_2021_cleaned           4           7                   4                   2\n",
      "transfer_portal_2022_cleaned           4           7                   4                   2\n",
      "transfer_portal_2023_cleaned           4           7                   4                   2\n",
      "transfer_portal_2024_cleaned           4           7                   4                   2\n",
      "transfer_portal_2025_cleaned           4           7                   4                   2\n"
     ]
    }
   ],
   "source": [
    "# checking missing attributes\n",
    "\n",
    "xferpathclean = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "xferfilesclean = {}\n",
    "\n",
    "for file_path in xferpathclean.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfilesclean[name] = G_x\n",
    "\n",
    "# ============================================\n",
    "# FUNCTION TO ANALYZE MISSING ATTRIBUTES\n",
    "# ============================================\n",
    "\n",
    "def analyze_missing_attributes(graph, graph_name):\n",
    "    \"\"\"\n",
    "    Analyzes a graph for missing node and edge attributes\n",
    "    Returns dictionaries with missing attribute information\n",
    "    \"\"\"\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Analyzing: {graph_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # --- NODE ATTRIBUTES ---\n",
    "    print(\"NODE ATTRIBUTES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all possible node attributes\n",
    "    all_node_attrs = set()\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        all_node_attrs.update(data.keys())\n",
    "    \n",
    "    print(f\"Total unique node attributes found: {len(all_node_attrs)}\")\n",
    "    print(f\"Attributes: {sorted(all_node_attrs)}\\n\")\n",
    "    \n",
    "    # Check which nodes are missing which attributes\n",
    "    node_missing_summary = {}\n",
    "    for attr in all_node_attrs:\n",
    "        missing_nodes = []\n",
    "        for node, data in graph.nodes(data=True):\n",
    "            if attr not in data or data[attr] is None or data[attr] == '' or data[attr] == 0.0 or data[attr] == 'Unknown':\n",
    "                missing_nodes.append(node)\n",
    "        \n",
    "        if missing_nodes:\n",
    "            node_missing_summary[attr] = {\n",
    "                'count': len(missing_nodes),\n",
    "                'percentage': (len(missing_nodes) / len(graph.nodes())) * 100,\n",
    "                'sample_nodes': missing_nodes[:5]  # First 5 examples\n",
    "            }\n",
    "    \n",
    "    if node_missing_summary:\n",
    "        print(\"Missing Node Attributes Summary:\")\n",
    "        for attr, info in sorted(node_missing_summary.items()):\n",
    "            print(f\"  {attr}:\")\n",
    "            print(f\"    Missing in {info['count']}/{len(graph.nodes())} nodes ({info['percentage']:.1f}%)\")\n",
    "            print(f\"    Sample nodes: {info['sample_nodes']}\")\n",
    "    else:\n",
    "        print(\"✓ All nodes have all attributes!\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # --- EDGE ATTRIBUTES ---\n",
    "    print(\"EDGE ATTRIBUTES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all possible edge attributes\n",
    "    all_edge_attrs = set()\n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        all_edge_attrs.update(data.keys())\n",
    "    \n",
    "    print(f\"Total unique edge attributes found: {len(all_edge_attrs)}\")\n",
    "    print(f\"Attributes: {sorted(all_edge_attrs)}\\n\")\n",
    "    \n",
    "    # Check which edges are missing which attributes\n",
    "    edge_missing_summary = {}\n",
    "    for attr in all_edge_attrs:\n",
    "        missing_edges = []\n",
    "        for s, t, data in graph.edges(data=True):\n",
    "            if attr not in data or data[attr] is None or data[attr] == '' or data[attr] == 0.0 or data[attr] == 'Unknown':\n",
    "                missing_edges.append((s, t))\n",
    "        \n",
    "        if missing_edges:\n",
    "            edge_missing_summary[attr] = {\n",
    "                'count': len(missing_edges),\n",
    "                'percentage': (len(missing_edges) / len(graph.edges())) * 100,\n",
    "                'sample_edges': missing_edges[:5]  # First 5 examples\n",
    "            }\n",
    "    \n",
    "    if edge_missing_summary:\n",
    "        print(\"Missing Edge Attributes Summary:\")\n",
    "        for attr, info in sorted(edge_missing_summary.items()):\n",
    "            print(f\"  {attr}:\")\n",
    "            print(f\"    Missing in {info['count']}/{len(graph.edges())} edges ({info['percentage']:.1f}%)\")\n",
    "            print(f\"    Sample edges: {info['sample_edges']}\")\n",
    "    else:\n",
    "        print(\"✓ All edges have all attributes!\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'node_attrs': all_node_attrs,\n",
    "        'edge_attrs': all_edge_attrs,\n",
    "        'node_missing': node_missing_summary,\n",
    "        'edge_missing': edge_missing_summary\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ANALYZE ALL GRAPHS\n",
    "# ============================================\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# Analyze transfer portal graphs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFER PORTAL GRAPHS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in xferfilesclean.items():\n",
    "    results = analyze_missing_attributes(graph, name)\n",
    "    all_results[name] = results\n",
    "\n",
    "# Analyze recruiting graphs\n",
    "#print(\"\\n\" + \"=\"*60)\n",
    "#print(\"RECRUITING GRAPHS\")\n",
    "#print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "#for name, graph in recfiles.items():\n",
    " #   results = analyze_missing_attributes(graph, name)\n",
    "  #  all_results[name] = results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CREATE SUMMARY DATAFRAME\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_data = []\n",
    "for graph_name, results in all_results.items():\n",
    "    summary_data.append({\n",
    "        'Graph': graph_name,\n",
    "        'Node Attrs': len(results['node_attrs']),\n",
    "        'Edge Attrs': len(results['edge_attrs']),\n",
    "        'Missing Node Attrs': len(results['node_missing']),\n",
    "        'Missing Edge Attrs': len(results['edge_missing'])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5779f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 transfer portal files\n",
      "\n",
      "======================================================================\n",
      "MISSING DATA ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "2021:\n",
      "  Total transfers: 1051\n",
      "  Missing ratings: 105 (10.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 104\n",
      "\n",
      "2022:\n",
      "  Total transfers: 1364\n",
      "  Missing ratings: 123 (9.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 123\n",
      "\n",
      "2023:\n",
      "  Total transfers: 1603\n",
      "  Missing ratings: 39 (2.4%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 39\n",
      "\n",
      "2024:\n",
      "  Total transfers: 2646\n",
      "  Missing ratings: 213 (8.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 213\n",
      "\n",
      "2025:\n",
      "  Total transfers: 3751\n",
      "  Missing ratings: 480 (12.8%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 480\n",
      "\n",
      "\n",
      "Summary Table:\n",
      " Year  Total Edges  Missing Ratings  Missing %  Missing 2-star  Missing 3-star  Missing 4-star  Missing 5-star  Missing Unknown  Present 2-star  Present 3-star  Present 4-star  Present 5-star\n",
      " 2021         1051              105   9.990485               0               0               0               0              104             109             748              88               1\n",
      " 2022         1364              123   9.017595               0               0               0               0              123              97             998             140               6\n",
      " 2023         1603               39   2.432938               0               0               0               0               39             168            1120             270               6\n",
      " 2024         2646              213   8.049887               0               0               0               0              213             136            2079             212               6\n",
      " 2025         3751              480  12.796588               0               0               0               0              480             174            2886             209               2\n",
      "\n",
      "======================================================================\n",
      "NPV CALCULATION WITH CONFIDENCE INTERVALS\n",
      "======================================================================\n",
      "\n",
      "Top 20 Schools by NPV (2025) with Uncertainty:\n",
      "======================================================================\n",
      "              school   npv  net_degree  in_count  out_count  total_missing  uncertainty  best_case  worst_case\n",
      "    Sacramento State 17.07          20        31         11             10          1.0      23.17       21.17\n",
      "       Southern Miss 15.95          19        48         29              3          0.3      18.80       18.20\n",
      "              Kansas 15.36          18        26          8              9          0.9      10.31        8.51\n",
      "            Virginia 13.91          16        30         14              4          0.4      12.61       11.81\n",
      "         Austin Peay 12.65          15        21          6              3          0.3      13.80       13.20\n",
      "    Prairie View A&M 12.58          15        18          3              3          0.3      15.43       14.83\n",
      "      Kennesaw State 11.39          14        24         10             10          1.0       8.99        6.99\n",
      "    Western Kentucky  9.89          12        37         25              8          0.8      10.69        9.09\n",
      "      Oklahoma State  9.72          11        36         25              7          0.7      11.27        9.87\n",
      "East Tennessee State  9.55          11        20          9              7          0.7      16.20       14.80\n",
      "                UNLV  9.34          11        37         26              6          0.6       9.94        8.74\n",
      "    Florida Atlantic  8.22          10        33         23              8          0.8       9.02        7.42\n",
      "          New Mexico  8.14          10        30         20             10          1.0       9.14        7.14\n",
      "      Arkansas State  8.11          10        28         18             10          1.0       7.41        5.41\n",
      "             Memphis  7.85           9        35         26              1          0.1       8.80        8.60\n",
      "         Florida A&M  7.83           9        13          4              5          0.5      10.88        9.88\n",
      "              Baylor  7.65           9        22         13              4          0.4       6.35        5.55\n",
      "               UConn  7.55           9        22         13              4          0.4       6.25        5.45\n",
      "              Toledo  7.39           9        19         10              3          0.3       6.84        6.24\n",
      "            Colorado  7.17           8        32         24              2          0.2       7.37        6.97\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "======================================================================\n",
      "\n",
      "1. Average uncertainty across all schools: ±0.23\n",
      "2. Max uncertainty: ±1.70 (Marshall)\n",
      "3. Schools with >5 missing transfers: 43\n",
      "\n",
      "4. Ranking Stability Analysis:\n",
      "   Average rank change in best-case scenario: 35.4 positions\n",
      "   Max rank change: 210 positions\n",
      "   Schools with rank change >5: 332\n",
      "\n",
      "5. Most Affected Schools (highest uncertainty):\n",
      "          school   npv  total_missing  uncertainty  rank_change\n",
      "        Marshall  2.11             17          1.7           37\n",
      "Coastal Carolina -0.09             16          1.6          158\n",
      "   James Madison  4.14             15          1.5           31\n",
      "   Massachusetts  2.92             15          1.5           58\n",
      "     North Texas -1.29             12          1.2           43\n",
      "============================================================\n",
      "ANALYZING CURRENT DATA STATE\n",
      "============================================================\n",
      "\n",
      "transfer_portal_2021:\n",
      "  Edges: 1051\n",
      "  Players: 1051\n",
      "  Multi-player edges: 0\n",
      "\n",
      "transfer_portal_2022:\n",
      "  Edges: 1364\n",
      "  Players: 1364\n",
      "  Multi-player edges: 0\n",
      "\n",
      "transfer_portal_2023:\n",
      "  Edges: 1603\n",
      "  Players: 1603\n",
      "  Multi-player edges: 0\n",
      "\n",
      "transfer_portal_2024:\n",
      "  Edges: 2646\n",
      "  Players: 2646\n",
      "  Multi-player edges: 0\n",
      "\n",
      "transfer_portal_2025:\n",
      "  Edges: 3751\n",
      "  Players: 3751\n",
      "  Multi-player edges: 0\n",
      "\n",
      "============================================================\n",
      "SPLITTING MULTI-PLAYER EDGES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Edges: 1051 → 1051 (+0)\n",
      "  Players processed: 1051\n",
      "  Duplicates merged: 0\n",
      "\n",
      "Processing transfer_portal_2022...\n",
      "  Edges: 1364 → 1364 (+0)\n",
      "  Players processed: 1364\n",
      "  Duplicates merged: 0\n",
      "\n",
      "Processing transfer_portal_2023...\n",
      "  Edges: 1603 → 1603 (+0)\n",
      "  Players processed: 1603\n",
      "  Duplicates merged: 0\n",
      "\n",
      "Processing transfer_portal_2024...\n",
      "  Edges: 2646 → 2646 (+0)\n",
      "  Players processed: 2646\n",
      "  Duplicates merged: 0\n",
      "\n",
      "Processing transfer_portal_2025...\n",
      "  Edges: 3751 → 3751 (+0)\n",
      "  Players processed: 3751\n",
      "  Duplicates merged: 0\n",
      "\n",
      "============================================================\n",
      "REPLACING MISSING RATINGS WITH STAR-TO-RATING VALUES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Imputed 0 out of 858 player ratings\n",
      "Processing transfer_portal_2022...\n",
      "  Imputed 0 out of 1109 player ratings\n",
      "Processing transfer_portal_2023...\n",
      "  Imputed 0 out of 1379 player ratings\n",
      "Processing transfer_portal_2024...\n",
      "  Imputed 0 out of 2143 player ratings\n",
      "Processing transfer_portal_2025...\n",
      "  Imputed 0 out of 2852 player ratings\n",
      "============================================================\n",
      "NORMALIZING RATINGS\n",
      "============================================================\n",
      "\n",
      "Original rating range: 0.0000 to 1.0000\n",
      "transfer_portal_2021: Normalized 858 ratings\n",
      "transfer_portal_2022: Normalized 1109 ratings\n",
      "transfer_portal_2023: Normalized 1379 ratings\n",
      "transfer_portal_2024: Normalized 2143 ratings\n",
      "transfer_portal_2025: Normalized 2852 ratings\n",
      "\n",
      "New rating range: 0.0000 to 1.0000\n",
      "\n",
      "============================================================\n",
      "SAVING CLEANED GRAPHS\n",
      "============================================================\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2021_cleaned.graphml\n",
      "  Nodes: 264\n",
      "  Edges: 958\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2022_cleaned.graphml\n",
      "  Nodes: 282\n",
      "  Edges: 1225\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2023_cleaned.graphml\n",
      "  Nodes: 283\n",
      "  Edges: 1413\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2024_cleaned.graphml\n",
      "  Nodes: 352\n",
      "  Edges: 2340\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2025_cleaned.graphml\n",
      "  Nodes: 410\n",
      "  Edges: 3296\n",
      "\n",
      "✓ All graphs cleaned and saved!\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "               Graph  Original Edges  Cleaned Edges  Change  Percent Increase\n",
      "transfer_portal_2021            1051            958     -93         -8.848716\n",
      "transfer_portal_2022            1364           1225    -139        -10.190616\n",
      "transfer_portal_2023            1603           1413    -190        -11.852776\n",
      "transfer_portal_2024            2646           2340    -306        -11.564626\n",
      "transfer_portal_2025            3751           3296    -455        -12.130099\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load cleaned transfer portal data\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "xferfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*_cleaned.graphml'):\n",
    "    name = file_path.stem.replace('_cleaned', '')\n",
    "    G = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G\n",
    "\n",
    "print(f\"Loaded {len(xferfiles)} transfer portal files\\n\")\n",
    "\n",
    "# ============================================\n",
    "# ANALYZE MISSING DATA PATTERNS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "missing_analysis = []\n",
    "\n",
    "for name, G in xferfiles.items():\n",
    "    year = int(name.split('_')[-1])\n",
    "    \n",
    "    total_edges = G.number_of_edges()\n",
    "    missing_rating = 0\n",
    "    missing_stars = 0\n",
    "    has_rating = 0\n",
    "    has_stars = 0\n",
    "    \n",
    "    # Track ratings by star level for missing data\n",
    "    missing_by_star = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 'unknown': 0}\n",
    "    present_by_star = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    \n",
    "    for u, v, data in G.edges(data=True):\n",
    "        rating = data.get('ratings', '')\n",
    "        stars = data.get('stars', '')\n",
    "        \n",
    "        # Check rating presence\n",
    "        if not rating or rating in ['', '0.0', 'None']:\n",
    "            missing_rating += 1\n",
    "            \n",
    "            # What star level is this missing rating?\n",
    "            if stars and stars not in ['', 'None']:\n",
    "                try:\n",
    "                    star_val = int(float(stars))\n",
    "                    if 1 <= star_val <= 5:\n",
    "                        missing_by_star[star_val] += 1\n",
    "                    else:\n",
    "                        missing_by_star['unknown'] += 1\n",
    "                except:\n",
    "                    missing_by_star['unknown'] += 1\n",
    "            else:\n",
    "                missing_by_star['unknown'] += 1\n",
    "        else:\n",
    "            has_rating += 1\n",
    "            \n",
    "            # Track star distribution of present ratings\n",
    "            if stars and stars not in ['', 'None']:\n",
    "                try:\n",
    "                    star_val = int(float(stars))\n",
    "                    if 1 <= star_val <= 5:\n",
    "                        present_by_star[star_val] += 1\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Check stars presence\n",
    "        if not stars or stars in ['', 'None']:\n",
    "            missing_stars += 1\n",
    "        else:\n",
    "            has_stars += 1\n",
    "    \n",
    "    missing_pct = (missing_rating / total_edges * 100) if total_edges > 0 else 0\n",
    "    \n",
    "    missing_analysis.append({\n",
    "        'Year': year,\n",
    "        'Total Edges': total_edges,\n",
    "        'Missing Ratings': missing_rating,\n",
    "        'Missing %': missing_pct,\n",
    "        'Missing 2-star': missing_by_star[2],\n",
    "        'Missing 3-star': missing_by_star[3],\n",
    "        'Missing 4-star': missing_by_star[4],\n",
    "        'Missing 5-star': missing_by_star[5],\n",
    "        'Missing Unknown': missing_by_star['unknown'],\n",
    "        'Present 2-star': present_by_star[2],\n",
    "        'Present 3-star': present_by_star[3],\n",
    "        'Present 4-star': present_by_star[4],\n",
    "        'Present 5-star': present_by_star[5]\n",
    "    })\n",
    "    \n",
    "    print(f\"{year}:\")\n",
    "    print(f\"  Total transfers: {total_edges}\")\n",
    "    print(f\"  Missing ratings: {missing_rating} ({missing_pct:.1f}%)\")\n",
    "    print(f\"  Missing by star level:\")\n",
    "    print(f\"    2-star: {missing_by_star[2]}\")\n",
    "    print(f\"    3-star: {missing_by_star[3]}\")\n",
    "    print(f\"    4-star: {missing_by_star[4]}\")\n",
    "    print(f\"    5-star: {missing_by_star[5]}\")\n",
    "    print(f\"    Unknown: {missing_by_star['unknown']}\")\n",
    "    print()\n",
    "\n",
    "missing_df = pd.DataFrame(missing_analysis)\n",
    "print(\"\\nSummary Table:\")\n",
    "print(missing_df.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# CALCULATE NPV WITH UNCERTAINTY BOUNDS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NPV CALCULATION WITH CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def calculate_npv_with_bounds(G, year):\n",
    "    \"\"\"\n",
    "    Calculate NPV for each school with uncertainty bounds\n",
    "    based on missing data.\n",
    "    \"\"\"\n",
    "    school_stats = {}\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        in_transfers = []\n",
    "        out_transfers = []\n",
    "        in_missing = 0\n",
    "        out_missing = 0\n",
    "        \n",
    "        # Incoming transfers\n",
    "        for pred in G.predecessors(node):\n",
    "            for key, data in G[pred][node].items() if isinstance(G, nx.MultiDiGraph) else [(0, G[pred][node])]:\n",
    "                rating = data.get('ratings', '')\n",
    "                if rating and rating not in ['', '0.0', 'None']:\n",
    "                    in_transfers.append(float(rating))\n",
    "                else:\n",
    "                    in_missing += 1\n",
    "        \n",
    "        # Outgoing transfers\n",
    "        for succ in G.successors(node):\n",
    "            for key, data in G[node][succ].items() if isinstance(G, nx.MultiDiGraph) else [(0, G[node][succ])]:\n",
    "                rating = data.get('ratings', '')\n",
    "                if rating and rating not in ['', '0.0', 'None']:\n",
    "                    out_transfers.append(float(rating))\n",
    "                else:\n",
    "                    out_missing += 1\n",
    "        \n",
    "        # Calculate NPV components\n",
    "        in_sum = sum(in_transfers)\n",
    "        out_sum = sum(out_transfers)\n",
    "        npv = in_sum - out_sum\n",
    "        \n",
    "        # Calculate uncertainty bounds (assume missing values could be ±0.1)\n",
    "        # Best case: missing incoming are high (0.95), missing outgoing are low (0.75)\n",
    "        # Worst case: missing incoming are low (0.75), missing outgoing are high (0.95)\n",
    "        best_case_npv = (in_sum + in_missing * 0.95) - (out_sum + out_missing * 0.75)\n",
    "        worst_case_npv = (in_sum + in_missing * 0.75) - (out_sum + out_missing * 0.95)\n",
    "        \n",
    "        uncertainty = (best_case_npv - worst_case_npv) / 2\n",
    "        \n",
    "        school_stats[node] = {\n",
    "            'npv': npv,\n",
    "            'net_degree': len(in_transfers) - len(out_transfers),\n",
    "            'in_count': len(in_transfers),\n",
    "            'out_count': len(out_transfers),\n",
    "            'in_missing': in_missing,\n",
    "            'out_missing': out_missing,\n",
    "            'total_missing': in_missing + out_missing,\n",
    "            'uncertainty': uncertainty,\n",
    "            'best_case': best_case_npv,\n",
    "            'worst_case': worst_case_npv\n",
    "        }\n",
    "    \n",
    "    return school_stats\n",
    "\n",
    "# Calculate for most recent year\n",
    "most_recent_year = max([int(name.split('_')[-1]) for name in xferfiles.keys()])\n",
    "most_recent_graph_name = f\"transfer_portal_{most_recent_year}\"\n",
    "G_recent = xferfiles[most_recent_graph_name]\n",
    "\n",
    "stats = calculate_npv_with_bounds(G_recent, most_recent_year)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "results_df['school'] = results_df.index\n",
    "results_df = results_df.sort_values('npv', ascending=False)\n",
    "\n",
    "print(f\"Top 20 Schools by NPV ({most_recent_year}) with Uncertainty:\")\n",
    "print(\"=\"*70)\n",
    "top20 = results_df.head(20)[['school', 'npv', 'net_degree', 'in_count', 'out_count', \n",
    "                               'total_missing', 'uncertainty', 'best_case', 'worst_case']]\n",
    "print(top20.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Average uncertainty across all schools: ±{results_df['uncertainty'].mean():.2f}\")\n",
    "print(f\"2. Max uncertainty: ±{results_df['uncertainty'].max():.2f} ({results_df.loc[results_df['uncertainty'].idxmax(), 'school']})\")\n",
    "print(f\"3. Schools with >5 missing transfers: {len(results_df[results_df['total_missing'] > 5])}\")\n",
    "\n",
    "# Check ranking stability\n",
    "print(\"\\n4. Ranking Stability Analysis:\")\n",
    "results_df['rank'] = range(1, len(results_df) + 1)\n",
    "results_df_best = results_df.copy()\n",
    "results_df_best = results_df_best.sort_values('best_case', ascending=False)\n",
    "results_df_best['rank_best'] = range(1, len(results_df_best) + 1)\n",
    "\n",
    "results_df = results_df.merge(results_df_best[['school', 'rank_best']], on='school')\n",
    "results_df['rank_change'] = abs(results_df['rank'] - results_df['rank_best'])\n",
    "\n",
    "print(f\"   Average rank change in best-case scenario: {results_df['rank_change'].mean():.1f} positions\")\n",
    "print(f\"   Max rank change: {results_df['rank_change'].max():.0f} positions\")\n",
    "print(f\"   Schools with rank change >5: {len(results_df[results_df['rank_change'] > 5])}\")\n",
    "\n",
    "print(\"\\n5. Most Affected Schools (highest uncertainty):\")\n",
    "most_affected = results_df.nlargest(5, 'uncertainty')[['school', 'npv', 'total_missing', 'uncertainty', 'rank_change']]\n",
    "print(most_affected.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
