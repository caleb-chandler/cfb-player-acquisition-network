{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f3e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 5 files from xfer and 27 files from rec.\n"
     ]
    }
   ],
   "source": [
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\raw\")\n",
    "recpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\recruiting\")\n",
    "xferfiles = {}\n",
    "recfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "for file_path in recpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_r = nx.read_graphml(file_path)\n",
    "    recfiles[name] = G_r\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(xferfiles)} files from xfer and {len(recfiles)} files from rec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffa2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 transfer portal files\n",
      "\n",
      "============================================================\n",
      "ANALYZING CURRENT DATA STATE\n",
      "============================================================\n",
      "\n",
      "transfer_portal_2021:\n",
      "  Edges: 958\n",
      "  Players: 1053\n",
      "  Multi-player edges: 77\n",
      "\n",
      "transfer_portal_2022:\n",
      "  Edges: 1225\n",
      "  Players: 1367\n",
      "  Multi-player edges: 113\n",
      "\n",
      "transfer_portal_2023:\n",
      "  Edges: 1413\n",
      "  Players: 1607\n",
      "  Multi-player edges: 140\n",
      "\n",
      "transfer_portal_2024:\n",
      "  Edges: 2340\n",
      "  Players: 2654\n",
      "  Multi-player edges: 224\n",
      "\n",
      "transfer_portal_2025:\n",
      "  Edges: 3296\n",
      "  Players: 3765\n",
      "  Multi-player edges: 337\n",
      "\n",
      "============================================================\n",
      "BUILDING STAR-TO-RATING MAPPING FROM EXISTING DATA\n",
      "============================================================\n",
      "\n",
      "Rating statistics by star level:\n",
      "------------------------------------------------------------\n",
      "1 Stars: No data available\n",
      "\n",
      "2 Stars:\n",
      "  Count: 108\n",
      "  Mean:   0.7850\n",
      "  Median: 0.7900\n",
      "  Std:    0.0109\n",
      "  Range:  0.7300 - 0.7900\n",
      "\n",
      "3 Stars:\n",
      "  Count: 5476\n",
      "  Mean:   0.8496\n",
      "  Median: 0.8500\n",
      "  Std:    0.0236\n",
      "  Range:  0.8000 - 0.8900\n",
      "\n",
      "4 Stars:\n",
      "  Count: 655\n",
      "  Mean:   0.9125\n",
      "  Median: 0.9100\n",
      "  Std:    0.0146\n",
      "  Range:  0.9000 - 0.9700\n",
      "\n",
      "5 Stars:\n",
      "  Count: 16\n",
      "  Mean:   0.9850\n",
      "  Median: 0.9800\n",
      "  Std:    0.0071\n",
      "  Range:  0.9800 - 1.0000\n",
      "\n",
      "============================================================\n",
      "SPLITTING MULTI-PLAYER EDGES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Edges: 958 → 1051 (+93)\n",
      "  Players processed: 1053\n",
      "  Duplicates merged: 2\n",
      "\n",
      "Processing transfer_portal_2022...\n",
      "  Edges: 1225 → 1364 (+139)\n",
      "  Players processed: 1367\n",
      "  Duplicates merged: 3\n",
      "\n",
      "Processing transfer_portal_2023...\n",
      "  Edges: 1413 → 1603 (+190)\n",
      "  Players processed: 1607\n",
      "  Duplicates merged: 4\n",
      "\n",
      "Processing transfer_portal_2024...\n",
      "  Edges: 2340 → 2646 (+306)\n",
      "  Players processed: 2654\n",
      "  Duplicates merged: 8\n",
      "\n",
      "Processing transfer_portal_2025...\n",
      "  Edges: 3296 → 3751 (+455)\n",
      "  Players processed: 3765\n",
      "  Duplicates merged: 14\n",
      "\n",
      "\n",
      "============================================================\n",
      "IMPUTING MISSING RATINGS WITH STAR-TO-RATING VALUES\n",
      "============================================================\n",
      "\n",
      "Processing transfer_portal_2021...\n",
      "  Imputed 639 out of 1051 player ratings\n",
      "Processing transfer_portal_2022...\n",
      "  Imputed 410 out of 1364 player ratings\n",
      "Processing transfer_portal_2023...\n",
      "  Imputed 698 out of 1603 player ratings\n",
      "Processing transfer_portal_2024...\n",
      "  Imputed 641 out of 2646 player ratings\n",
      "Processing transfer_portal_2025...\n",
      "  Imputed 834 out of 3751 player ratings\n",
      "\n",
      "============================================================\n",
      "SAVING CLEANED GRAPHS\n",
      "============================================================\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2021_cleaned.graphml\n",
      "  Nodes: 264\n",
      "  Edges: 1051\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2022_cleaned.graphml\n",
      "  Nodes: 282\n",
      "  Edges: 1364\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2023_cleaned.graphml\n",
      "  Nodes: 283\n",
      "  Edges: 1603\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2024_cleaned.graphml\n",
      "  Nodes: 352\n",
      "  Edges: 2646\n",
      "\n",
      "Saved: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\transfer_portal_2025_cleaned.graphml\n",
      "  Nodes: 410\n",
      "  Edges: 3751\n",
      "\n",
      "✓ All graphs cleaned and saved!\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "               Graph  Original Edges  Cleaned Edges  Change  Percent Increase\n",
      "transfer_portal_2021             958           1051      93          9.707724\n",
      "transfer_portal_2022            1225           1364     139         11.346939\n",
      "transfer_portal_2023            1413           1603     190         13.446568\n",
      "transfer_portal_2024            2340           2646     306         13.076923\n",
      "transfer_portal_2025            3296           3751     455         13.804612\n",
      "\n",
      "============================================================\n",
      "STAR-TO-RATING MAPPING TABLE\n",
      "============================================================\n",
      "\n",
      "           mean  median       std   min   max   count\n",
      "Stars                                                \n",
      "1           NaN     NaN       NaN   NaN   NaN     NaN\n",
      "2      0.785000    0.79  0.010929  0.73  0.79   108.0\n",
      "3      0.849648    0.85  0.023627  0.80  0.89  5476.0\n",
      "4      0.912504    0.91  0.014614  0.90  0.97   655.0\n",
      "5      0.985000    0.98  0.007071  0.98  1.00    16.0\n",
      "\n",
      "✓ Mapping table saved to: C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\\star_rating_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# xfer: converting to multi-graphs and imputing missing ratings\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import uuid\n",
    "\n",
    "# load transfer portal graphs\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\raw\")\n",
    "xferfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "print(f\"Loaded {len(xferfiles)} transfer portal files\\n\")\n",
    "\n",
    "# 1. ANALYZE CURRENT STATE\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYZING CURRENT DATA STATE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    total_edges = len(graph.edges())\n",
    "    total_players = 0\n",
    "    multi_player_edges = 0\n",
    "    \n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        players_str = data.get('players', '')\n",
    "        if players_str:\n",
    "            player_list = [p.strip() for p in players_str.split('|')]\n",
    "            total_players += len(player_list)\n",
    "            if len(player_list) > 1:\n",
    "                multi_player_edges += 1\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Edges: {total_edges}\")\n",
    "    print(f\"  Players: {total_players}\")\n",
    "    print(f\"  Multi-player edges: {multi_player_edges}\")\n",
    "    print()\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: BUILD STAR-TO-RATING MAPPING\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING STAR-TO-RATING MAPPING FROM EXISTING DATA\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "all_ratings_by_star = {1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        ratings_str = data.get('ratings', '')\n",
    "        stars_str = data.get('stars', '')\n",
    "        \n",
    "        if not ratings_str or not stars_str:\n",
    "            continue\n",
    "        \n",
    "        # Split by pipe and clean\n",
    "        ratings_list = [r.strip() for r in ratings_str.split('|')]\n",
    "        stars_list = [st.strip() for st in stars_str.split('|')]\n",
    "        \n",
    "        # Match up ratings with stars\n",
    "        for rating, star in zip(ratings_list, stars_list):\n",
    "            try:\n",
    "                rating_val = float(rating) if rating and rating != '' and rating != 'None' else None\n",
    "                star_val = int(float(star)) if star and star != '' and star != 'None' else None\n",
    "                \n",
    "                if rating_val is not None and star_val is not None and 1 <= star_val <= 5:\n",
    "                    all_ratings_by_star[star_val].append(rating_val)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "# Calculate statistics for each star level\n",
    "print(\"Rating statistics by star level:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "star_rating_map = {}\n",
    "for star in sorted(all_ratings_by_star.keys()):\n",
    "    ratings = all_ratings_by_star[star]\n",
    "    if ratings:\n",
    "        mean_rating = np.mean(ratings)\n",
    "        median_rating = np.median(ratings)\n",
    "        std_rating = np.std(ratings)\n",
    "        min_rating = np.min(ratings)\n",
    "        max_rating = np.max(ratings)\n",
    "        \n",
    "        star_rating_map[star] = {\n",
    "            'mean': mean_rating,\n",
    "            'median': median_rating,\n",
    "            'std': std_rating,\n",
    "            'min': min_rating,\n",
    "            'max': max_rating,\n",
    "            'count': len(ratings)\n",
    "        }\n",
    "        \n",
    "        print(f\"{star} Stars:\")\n",
    "        print(f\"  Count: {len(ratings)}\")\n",
    "        print(f\"  Mean:   {mean_rating:.4f}\")\n",
    "        print(f\"  Median: {median_rating:.4f}\")\n",
    "        print(f\"  Std:    {std_rating:.4f}\")\n",
    "        print(f\"  Range:  {min_rating:.4f} - {max_rating:.4f}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{star} Stars: No data available\\n\")\n",
    "        star_rating_map[star] = {'mean': None, 'median': None}\n",
    "\n",
    "# Define fallback function\n",
    "def get_fallback_rating(star_value, method='median'):\n",
    "    \"\"\"Returns a fallback rating based on star value.\"\"\"\n",
    "    try:\n",
    "        star = int(float(star_value))\n",
    "        if star in star_rating_map and star_rating_map[star][method] is not None:\n",
    "            return star_rating_map[star][method]\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    return 0.0\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: SPLIT EDGES BY PLAYER\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPLITTING MULTI-PLAYER EDGES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def are_same_person(name1, name2):\n",
    "    \"\"\"\n",
    "    Returns True if two players share the same last name, \n",
    "    ignoring suffixes like Jr, Sr, III.\n",
    "    \"\"\"\n",
    "    if not name1 or not name2:\n",
    "        return False\n",
    "\n",
    "    def get_cleaned_last_name(full_name):\n",
    "        parts = full_name.strip().lower().split()\n",
    "        \n",
    "        if not parts:\n",
    "            return \"\"\n",
    "\n",
    "        suffixes = {'jr', 'jr.', 'sr', 'sr.', 'ii', 'iii', 'iv', 'v'}\n",
    "\n",
    "        while len(parts) > 1 and parts[-1] in suffixes:\n",
    "            parts.pop()\n",
    "            \n",
    "        return parts[-1]\n",
    "\n",
    "    return get_cleaned_last_name(name1) == get_cleaned_last_name(name2)\n",
    "\n",
    "cleaned_graphs = {}\n",
    "\n",
    "for name, graph in xferfiles.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    # Create new MULTI-graph to support multiple edges between same nodes\n",
    "    G_new = nx.MultiDiGraph()\n",
    "    \n",
    "    # Copy node attributes\n",
    "    for node, attrs in graph.nodes(data=True):\n",
    "        G_new.add_node(node, **attrs)\n",
    "    \n",
    "    edges_before = len(graph.edges())\n",
    "    edges_after = 0\n",
    "    players_processed = 0\n",
    "    duplicates_merged = 0\n",
    "    \n",
    "    # Process each edge\n",
    "    for source, target, data in graph.edges(data=True):\n",
    "        # Extract all the pipe-separated attributes\n",
    "        players_str = data.get('players', '')\n",
    "        positions_str = data.get('positions', '')\n",
    "        dates_str = data.get('dates', '')\n",
    "        ratings_str = data.get('ratings', '')\n",
    "        stars_str = data.get('stars', '')\n",
    "        eligibility_str = data.get('eligibility', '')\n",
    "        \n",
    "        if not players_str:\n",
    "            continue\n",
    "        \n",
    "        # Split all attributes by pipe\n",
    "        players = [p.strip() for p in players_str.split('|')]\n",
    "        positions = [p.strip() for p in positions_str.split('|')] if positions_str else [''] * len(players)\n",
    "        dates = [d.strip() for d in dates_str.split('|')] if dates_str else [''] * len(players)\n",
    "        ratings = [r.strip() for r in ratings_str.split('|')] if ratings_str else [''] * len(players)\n",
    "        stars = [s.strip() for s in stars_str.split('|')] if stars_str else [''] * len(players)\n",
    "        eligibility = [e.strip() for e in eligibility_str.split('|')] if eligibility_str else [''] * len(players)\n",
    "        \n",
    "        # Pad shorter lists to match players list length\n",
    "        max_len = len(players)\n",
    "        positions += [''] * (max_len - len(positions))\n",
    "        dates += [''] * (max_len - len(dates))\n",
    "        ratings += [''] * (max_len - len(ratings))\n",
    "        stars += [''] * (max_len - len(stars))\n",
    "        eligibility += [''] * (max_len - len(eligibility))\n",
    "        \n",
    "        # Group players by unique identity\n",
    "        player_groups = defaultdict(list)\n",
    "        \n",
    "        for i, player in enumerate(players):\n",
    "            players_processed += 1\n",
    "            \n",
    "            # Check if this player is already in our groups\n",
    "            merged = False\n",
    "            for existing_player in list(player_groups.keys()):\n",
    "                if are_same_person(player, existing_player):\n",
    "                    # Merge with existing entry\n",
    "                    player_groups[existing_player].append({\n",
    "                        'player': player,\n",
    "                        'position': positions[i],\n",
    "                        'date': dates[i],\n",
    "                        'rating': ratings[i],\n",
    "                        'stars': stars[i],\n",
    "                        'eligibility': eligibility[i]\n",
    "                    })\n",
    "                    duplicates_merged += 1\n",
    "                    merged = True\n",
    "                    break\n",
    "            \n",
    "            if not merged:\n",
    "                # Create new entry\n",
    "                player_groups[player].append({\n",
    "                    'player': player,\n",
    "                    'position': positions[i],\n",
    "                    'date': dates[i],\n",
    "                    'rating': ratings[i],\n",
    "                    'stars': stars[i],\n",
    "                    'eligibility': eligibility[i]\n",
    "                })\n",
    "        \n",
    "        # Create one edge per unique player\n",
    "        for player_name, player_data_list in player_groups.items():\n",
    "            # For duplicate entries, take the first non-empty value for each attribute\n",
    "            def get_best_value(attr_name):\n",
    "                values = [pd[attr_name] for pd in player_data_list]\n",
    "                for v in values:\n",
    "                    if v and v != '' and v != 'None':\n",
    "                        return v\n",
    "                return ''\n",
    "            \n",
    "            edge_unique_id = str(uuid.uuid4())\n",
    "            final_data = {\n",
    "                'id': edge_unique_id,\n",
    "                'players': player_name,\n",
    "                'positions': get_best_value('position'),\n",
    "                'dates': get_best_value('date'),\n",
    "                'ratings': get_best_value('rating'),\n",
    "                'stars': get_best_value('stars'),\n",
    "                'eligibility': get_best_value('eligibility'),\n",
    "                'weight': 1\n",
    "            }\n",
    "            \n",
    "            # Add edge (MultiDiGraph automatically handles multiple edges)\n",
    "            G_new.add_edge(source, target, key=edge_unique_id, **final_data)\n",
    "            edges_after += 1\n",
    "    \n",
    "    print(f\"  Edges: {edges_before} → {edges_after} (+{edges_after - edges_before})\")\n",
    "    print(f\"  Players processed: {players_processed}\")\n",
    "    print(f\"  Duplicates merged: {duplicates_merged}\") \n",
    "    print()\n",
    "    \n",
    "    cleaned_graphs[name] = G_new\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: IMPUTE MISSING RATINGS WITH STAR VALUES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPUTING MISSING RATINGS WITH STAR-TO-RATING VALUES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in cleaned_graphs.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    imputed_count = 0\n",
    "    total_players = 0\n",
    "    \n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        rating_str = data.get('ratings', '')\n",
    "        star_str = data.get('stars', '')\n",
    "        \n",
    "        total_players += 1\n",
    "        \n",
    "        # If rating is missing but star exists, use fallback\n",
    "        if (not rating_str or rating_str == '' or rating_str == 'None') and star_str and star_str != '' and star_str != 'None':\n",
    "            fallback = get_fallback_rating(star_str, method='median')\n",
    "            data['ratings'] = str(fallback)\n",
    "            imputed_count += 1\n",
    "    \n",
    "    print(f\"  Imputed {imputed_count} out of {total_players} player ratings\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: SAVE CLEANED GRAPHS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING CLEANED GRAPHS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, graph in cleaned_graphs.items():\n",
    "    output_file = output_path / f\"{name}_cleaned.graphml\"\n",
    "    nx.write_graphml(graph, output_file)\n",
    "    print(f\"Saved: {output_file}\")\n",
    "    print(f\"  Nodes: {len(graph.nodes())}\")\n",
    "    print(f\"  Edges: {len(graph.edges())}\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ All graphs cleaned and saved!\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 6: SUMMARY STATISTICS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_data = []\n",
    "for name in xferfiles.keys():\n",
    "    original = xferfiles[name]\n",
    "    cleaned = cleaned_graphs[name]\n",
    "    \n",
    "    orig_edges = len(original.edges())\n",
    "    clean_edges = len(cleaned.edges())\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Graph': name,\n",
    "        'Original Edges': orig_edges,\n",
    "        'Cleaned Edges': clean_edges,\n",
    "        'Change': clean_edges - orig_edges,\n",
    "        'Percent Increase': ((clean_edges - orig_edges) / orig_edges * 100) if orig_edges > 0 else 0\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# STEP 7: EXPORT MAPPING TABLE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAR-TO-RATING MAPPING TABLE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "mapping_df = pd.DataFrame.from_dict(star_rating_map, orient='index')\n",
    "mapping_df.index.name = 'Stars'\n",
    "print(mapping_df.to_string())\n",
    "\n",
    "# Save mapping to CSV\n",
    "mapping_csv = output_path / \"star_rating_mapping.csv\"\n",
    "mapping_df.to_csv(mapping_csv)\n",
    "print(f\"\\n✓ Mapping table saved to: {mapping_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e380ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRANSFER PORTAL GRAPHS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2021_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 19/264 nodes (7.2%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.', 'Texas-Permian Basin']\n",
      "  conference:\n",
      "    Missing in 19/264 nodes (7.2%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.', 'Texas-Permian Basin']\n",
      "  latitude:\n",
      "    Missing in 23/264 nodes (8.7%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'Northwestern', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.']\n",
      "  longitude:\n",
      "    Missing in 23/264 nodes (8.7%)\n",
      "    Sample nodes: ['Missouri Western State', 'Winston-Salem State', 'Northwestern', 'City College of San Francisco', 'Mississippi Gulf Coast C.C.']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 104/1051 edges (9.9%)\n",
      "    Sample edges: [('Missouri Western State', 'Kansas'), ('Kansas', 'Butler C.C.'), ('Kansas', 'Kansas State'), ('Kansas', 'UTSA'), ('Florida State', 'Troy')]\n",
      "  stars:\n",
      "    Missing in 104/1051 edges (9.9%)\n",
      "    Sample edges: [('Missouri Western State', 'Kansas'), ('Kansas', 'Butler C.C.'), ('Kansas', 'Kansas State'), ('Kansas', 'UTSA'), ('Florida State', 'Troy')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2022_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 23/282 nodes (8.2%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Trinity Valley C.C.']\n",
      "  conference:\n",
      "    Missing in 23/282 nodes (8.2%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Trinity Valley C.C.']\n",
      "  latitude:\n",
      "    Missing in 27/282 nodes (9.6%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Florida International']\n",
      "  longitude:\n",
      "    Missing in 27/282 nodes (9.6%)\n",
      "    Sample nodes: ['Iowa Western C.C.', 'Hutchinson C.C.', 'Lindenwood University', 'College of the Canyons', 'Florida International']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 123/1364 edges (9.0%)\n",
      "    Sample edges: [('East Carolina', 'Winston-Salem State'), ('East Carolina', 'Alabama A&M'), ('Tennessee State', 'Troy'), ('Dartmouth', 'New Mexico State'), ('Simon Fraser', 'Washington State')]\n",
      "  stars:\n",
      "    Missing in 123/1364 edges (9.0%)\n",
      "    Sample edges: [('East Carolina', 'Winston-Salem State'), ('East Carolina', 'Alabama A&M'), ('Tennessee State', 'Troy'), ('Dartmouth', 'New Mexico State'), ('Simon Fraser', 'Washington State')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2023_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 23/283 nodes (8.1%)\n",
      "    Sample nodes: ['Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Coffeyville C.C.', 'Laney College']\n",
      "  conference:\n",
      "    Missing in 23/283 nodes (8.1%)\n",
      "    Sample nodes: ['Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Coffeyville C.C.', 'Laney College']\n",
      "  latitude:\n",
      "    Missing in 25/283 nodes (8.8%)\n",
      "    Sample nodes: ['Florida International', 'Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Northwestern']\n",
      "  longitude:\n",
      "    Missing in 25/283 nodes (8.8%)\n",
      "    Sample nodes: ['Florida International', 'Saint Francis (PA)', 'Lindenwood University', 'Blinn College', 'Northwestern']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 39/1603 edges (2.4%)\n",
      "    Sample edges: [('Air Force', 'Palomar College'), ('UNLV', 'Cerritos College'), ('California', 'Nevada'), ('California', 'Arizona State'), ('Houston', 'Southern Miss')]\n",
      "  stars:\n",
      "    Missing in 39/1603 edges (2.4%)\n",
      "    Sample edges: [('Air Force', 'Palomar College'), ('UNLV', 'Cerritos College'), ('California', 'Nevada'), ('California', 'Arizona State'), ('Houston', 'Southern Miss')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2024_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 47/352 nodes (13.4%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'CSU-Pueblo', 'Missouri Western State']\n",
      "  conference:\n",
      "    Missing in 47/352 nodes (13.4%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'CSU-Pueblo', 'Missouri Western State']\n",
      "  latitude:\n",
      "    Missing in 51/352 nodes (14.5%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'Florida International', 'West Florida']\n",
      "  longitude:\n",
      "    Missing in 51/352 nodes (14.5%)\n",
      "    Sample nodes: ['Shippensburg University', 'Garden City C.C.', 'Butler C.C.', 'Florida International', 'West Florida']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 213/2646 edges (8.0%)\n",
      "    Sample edges: [('Georgia', 'Jacksonville State'), ('Washington State', 'Nevada'), ('Arkansas', 'Missouri State'), ('Arkansas', 'North Texas'), ('Arkansas', 'McNeese')]\n",
      "  stars:\n",
      "    Missing in 213/2646 edges (8.0%)\n",
      "    Sample edges: [('Georgia', 'Jacksonville State'), ('Washington State', 'Nevada'), ('Arkansas', 'Missouri State'), ('Arkansas', 'North Texas'), ('Arkansas', 'McNeese')]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: transfer_portal_2025_cleaned\n",
      "============================================================\n",
      "\n",
      "NODE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique node attributes found: 4\n",
      "Attributes: ['classification', 'conference', 'latitude', 'longitude']\n",
      "\n",
      "Missing Node Attributes Summary:\n",
      "  classification:\n",
      "    Missing in 66/410 nodes (16.1%)\n",
      "    Sample nodes: [\"King's College\", 'Albany', 'American River C.C.', 'UNC-Pembroke', 'Hinds C.C.']\n",
      "  conference:\n",
      "    Missing in 66/410 nodes (16.1%)\n",
      "    Sample nodes: [\"King's College\", 'Albany', 'American River C.C.', 'UNC-Pembroke', 'Hinds C.C.']\n",
      "  latitude:\n",
      "    Missing in 71/410 nodes (17.3%)\n",
      "    Sample nodes: [\"King's College\", 'Florida International', 'Albany', 'American River C.C.', 'UNC-Pembroke']\n",
      "  longitude:\n",
      "    Missing in 71/410 nodes (17.3%)\n",
      "    Sample nodes: [\"King's College\", 'Florida International', 'Albany', 'American River C.C.', 'UNC-Pembroke']\n",
      "\n",
      "EDGE ATTRIBUTES:\n",
      "----------------------------------------\n",
      "Total unique edge attributes found: 7\n",
      "Attributes: ['dates', 'eligibility', 'players', 'positions', 'ratings', 'stars', 'weight']\n",
      "\n",
      "Missing Edge Attributes Summary:\n",
      "  ratings:\n",
      "    Missing in 480/3751 edges (12.8%)\n",
      "    Sample edges: [('Richmond', 'East Carolina'), ('Richmond', 'James Madison'), ('East Carolina', 'Chattanooga'), ('East Carolina', 'Harding University'), ('East Carolina', 'App State')]\n",
      "  stars:\n",
      "    Missing in 480/3751 edges (12.8%)\n",
      "    Sample edges: [('Richmond', 'East Carolina'), ('Richmond', 'James Madison'), ('East Carolina', 'Chattanooga'), ('East Carolina', 'Harding University'), ('East Carolina', 'App State')]\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "OVERALL SUMMARY\n",
      "============================================================\n",
      "\n",
      "                       Graph  Node Attrs  Edge Attrs  Missing Node Attrs  Missing Edge Attrs\n",
      "transfer_portal_2021_cleaned           4           7                   4                   2\n",
      "transfer_portal_2022_cleaned           4           7                   4                   2\n",
      "transfer_portal_2023_cleaned           4           7                   4                   2\n",
      "transfer_portal_2024_cleaned           4           7                   4                   2\n",
      "transfer_portal_2025_cleaned           4           7                   4                   2\n"
     ]
    }
   ],
   "source": [
    "# checking missing attributes\n",
    "\n",
    "xferpathclean = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "xferfilesclean = {}\n",
    "\n",
    "for file_path in xferpathclean.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfilesclean[name] = G_x\n",
    "\n",
    "# ============================================\n",
    "# FUNCTION TO ANALYZE MISSING ATTRIBUTES\n",
    "# ============================================\n",
    "\n",
    "def analyze_missing_attributes(graph, graph_name):\n",
    "    \"\"\"\n",
    "    Analyzes a graph for missing node and edge attributes\n",
    "    Returns dictionaries with missing attribute information\n",
    "    \"\"\"\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Analyzing: {graph_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # --- NODE ATTRIBUTES ---\n",
    "    print(\"NODE ATTRIBUTES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all possible node attributes\n",
    "    all_node_attrs = set()\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        all_node_attrs.update(data.keys())\n",
    "    \n",
    "    print(f\"Total unique node attributes found: {len(all_node_attrs)}\")\n",
    "    print(f\"Attributes: {sorted(all_node_attrs)}\\n\")\n",
    "    \n",
    "    # Check which nodes are missing which attributes\n",
    "    node_missing_summary = {}\n",
    "    for attr in all_node_attrs:\n",
    "        missing_nodes = []\n",
    "        for node, data in graph.nodes(data=True):\n",
    "            if attr not in data or data[attr] is None or data[attr] == '' or data[attr] == 0.0 or data[attr] == 'Unknown':\n",
    "                missing_nodes.append(node)\n",
    "        \n",
    "        if missing_nodes:\n",
    "            node_missing_summary[attr] = {\n",
    "                'count': len(missing_nodes),\n",
    "                'percentage': (len(missing_nodes) / len(graph.nodes())) * 100,\n",
    "                'sample_nodes': missing_nodes[:5]  # First 5 examples\n",
    "            }\n",
    "    \n",
    "    if node_missing_summary:\n",
    "        print(\"Missing Node Attributes Summary:\")\n",
    "        for attr, info in sorted(node_missing_summary.items()):\n",
    "            print(f\"  {attr}:\")\n",
    "            print(f\"    Missing in {info['count']}/{len(graph.nodes())} nodes ({info['percentage']:.1f}%)\")\n",
    "            print(f\"    Sample nodes: {info['sample_nodes']}\")\n",
    "    else:\n",
    "        print(\"✓ All nodes have all attributes!\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # --- EDGE ATTRIBUTES ---\n",
    "    print(\"EDGE ATTRIBUTES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all possible edge attributes\n",
    "    all_edge_attrs = set()\n",
    "    for s, t, data in graph.edges(data=True):\n",
    "        all_edge_attrs.update(data.keys())\n",
    "    \n",
    "    print(f\"Total unique edge attributes found: {len(all_edge_attrs)}\")\n",
    "    print(f\"Attributes: {sorted(all_edge_attrs)}\\n\")\n",
    "    \n",
    "    # Check which edges are missing which attributes\n",
    "    edge_missing_summary = {}\n",
    "    for attr in all_edge_attrs:\n",
    "        missing_edges = []\n",
    "        for s, t, data in graph.edges(data=True):\n",
    "            if attr not in data or data[attr] is None or data[attr] == '' or data[attr] == 0.0 or data[attr] == 'Unknown':\n",
    "                missing_edges.append((s, t))\n",
    "        \n",
    "        if missing_edges:\n",
    "            edge_missing_summary[attr] = {\n",
    "                'count': len(missing_edges),\n",
    "                'percentage': (len(missing_edges) / len(graph.edges())) * 100,\n",
    "                'sample_edges': missing_edges[:5]  # First 5 examples\n",
    "            }\n",
    "    \n",
    "    if edge_missing_summary:\n",
    "        print(\"Missing Edge Attributes Summary:\")\n",
    "        for attr, info in sorted(edge_missing_summary.items()):\n",
    "            print(f\"  {attr}:\")\n",
    "            print(f\"    Missing in {info['count']}/{len(graph.edges())} edges ({info['percentage']:.1f}%)\")\n",
    "            print(f\"    Sample edges: {info['sample_edges']}\")\n",
    "    else:\n",
    "        print(\"✓ All edges have all attributes!\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'node_attrs': all_node_attrs,\n",
    "        'edge_attrs': all_edge_attrs,\n",
    "        'node_missing': node_missing_summary,\n",
    "        'edge_missing': edge_missing_summary\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ANALYZE ALL GRAPHS\n",
    "# ============================================\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# Analyze transfer portal graphs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFER PORTAL GRAPHS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, graph in xferfilesclean.items():\n",
    "    results = analyze_missing_attributes(graph, name)\n",
    "    all_results[name] = results\n",
    "\n",
    "# Analyze recruiting graphs\n",
    "#print(\"\\n\" + \"=\"*60)\n",
    "#print(\"RECRUITING GRAPHS\")\n",
    "#print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "#for name, graph in recfiles.items():\n",
    " #   results = analyze_missing_attributes(graph, name)\n",
    "  #  all_results[name] = results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CREATE SUMMARY DATAFRAME\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_data = []\n",
    "for graph_name, results in all_results.items():\n",
    "    summary_data.append({\n",
    "        'Graph': graph_name,\n",
    "        'Node Attrs': len(results['node_attrs']),\n",
    "        'Edge Attrs': len(results['edge_attrs']),\n",
    "        'Missing Node Attrs': len(results['node_missing']),\n",
    "        'Missing Edge Attrs': len(results['edge_missing'])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
