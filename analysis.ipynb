{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c641ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "recpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\recruiting\\final\")\n",
    "xferfiles = {}\n",
    "recfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "for file_path in recpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_r = nx.read_graphml(file_path)\n",
    "    recfiles[name] = G_r\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(xferfiles)} files from xfer and {len(recfiles)} files from rec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e388de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net degree (xfer)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load cleaned transfer portal data\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "xferfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*_cleaned.graphml'):\n",
    "    name = file_path.stem.replace('_cleaned', '')\n",
    "    G = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G\n",
    "\n",
    "print(f\"Loaded {len(xferfiles)} transfer portal files\\n\")\n",
    "\n",
    "# Calculate net degree for each team in each season\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 transfer portal files\n",
      "\n",
      "======================================================================\n",
      "MISSING DATA ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "2021:\n",
      "  Total transfers: 1051\n",
      "  Missing ratings: 105 (10.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 104\n",
      "\n",
      "2022:\n",
      "  Total transfers: 1364\n",
      "  Missing ratings: 123 (9.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 123\n",
      "\n",
      "2023:\n",
      "  Total transfers: 1603\n",
      "  Missing ratings: 39 (2.4%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 39\n",
      "\n",
      "2024:\n",
      "  Total transfers: 2646\n",
      "  Missing ratings: 213 (8.0%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 213\n",
      "\n",
      "2025:\n",
      "  Total transfers: 3751\n",
      "  Missing ratings: 480 (12.8%)\n",
      "  Missing by star level:\n",
      "    2-star: 0\n",
      "    3-star: 0\n",
      "    4-star: 0\n",
      "    5-star: 0\n",
      "    Unknown: 480\n",
      "\n",
      "\n",
      "Summary Table:\n",
      " Year  Total Edges  Missing Ratings  Missing %  Missing 2-star  Missing 3-star  Missing 4-star  Missing 5-star  Missing Unknown  Present 2-star  Present 3-star  Present 4-star  Present 5-star\n",
      " 2021         1051              105   9.990485               0               0               0               0              104             109             748              88               1\n",
      " 2022         1364              123   9.017595               0               0               0               0              123              97             998             140               6\n",
      " 2023         1603               39   2.432938               0               0               0               0               39             168            1120             270               6\n",
      " 2024         2646              213   8.049887               0               0               0               0              213             136            2079             212               6\n",
      " 2025         3751              480  12.796588               0               0               0               0              480             174            2886             209               2\n",
      "\n",
      "======================================================================\n",
      "NPV CALCULATION WITH CONFIDENCE INTERVALS\n",
      "======================================================================\n",
      "\n",
      "Top 20 Schools by NPV (2025) with Uncertainty:\n",
      "======================================================================\n",
      "              school   npv  net_degree  in_count  out_count  total_missing  uncertainty  best_case  worst_case\n",
      "    Sacramento State 17.07          20        31         11             10          1.0      23.17       21.17\n",
      "       Southern Miss 15.95          19        48         29              3          0.3      18.80       18.20\n",
      "              Kansas 15.36          18        26          8              9          0.9      10.31        8.51\n",
      "            Virginia 13.91          16        30         14              4          0.4      12.61       11.81\n",
      "         Austin Peay 12.65          15        21          6              3          0.3      13.80       13.20\n",
      "    Prairie View A&M 12.58          15        18          3              3          0.3      15.43       14.83\n",
      "      Kennesaw State 11.39          14        24         10             10          1.0       8.99        6.99\n",
      "    Western Kentucky  9.89          12        37         25              8          0.8      10.69        9.09\n",
      "      Oklahoma State  9.72          11        36         25              7          0.7      11.27        9.87\n",
      "East Tennessee State  9.55          11        20          9              7          0.7      16.20       14.80\n",
      "                UNLV  9.34          11        37         26              6          0.6       9.94        8.74\n",
      "    Florida Atlantic  8.22          10        33         23              8          0.8       9.02        7.42\n",
      "          New Mexico  8.14          10        30         20             10          1.0       9.14        7.14\n",
      "      Arkansas State  8.11          10        28         18             10          1.0       7.41        5.41\n",
      "             Memphis  7.85           9        35         26              1          0.1       8.80        8.60\n",
      "         Florida A&M  7.83           9        13          4              5          0.5      10.88        9.88\n",
      "              Baylor  7.65           9        22         13              4          0.4       6.35        5.55\n",
      "               UConn  7.55           9        22         13              4          0.4       6.25        5.45\n",
      "              Toledo  7.39           9        19         10              3          0.3       6.84        6.24\n",
      "            Colorado  7.17           8        32         24              2          0.2       7.37        6.97\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "======================================================================\n",
      "\n",
      "1. Average uncertainty across all schools: ±0.23\n",
      "2. Max uncertainty: ±1.70 (Marshall)\n",
      "3. Schools with >5 missing transfers: 43\n",
      "\n",
      "4. Ranking Stability Analysis:\n",
      "   Average rank change in best-case scenario: 35.4 positions\n",
      "   Max rank change: 210 positions\n",
      "   Schools with rank change >5: 332\n",
      "\n",
      "5. Most Affected Schools (highest uncertainty):\n",
      "          school   npv  total_missing  uncertainty  rank_change\n",
      "        Marshall  2.11             17          1.7           37\n",
      "Coastal Carolina -0.09             16          1.6          158\n",
      "   James Madison  4.14             15          1.5           31\n",
      "   Massachusetts  2.92             15          1.5           58\n",
      "     North Texas -1.29             12          1.2           43\n"
     ]
    }
   ],
   "source": [
    "# npv calculation with uncertainty bounds (xfer)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load cleaned transfer portal data\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "xferfiles = {}\n",
    "\n",
    "for file_path in xferpath.glob('*_cleaned.graphml'):\n",
    "    name = file_path.stem.replace('_cleaned', '')\n",
    "    G = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G\n",
    "\n",
    "print(f\"Loaded {len(xferfiles)} transfer portal files\\n\")\n",
    "\n",
    "# ============================================\n",
    "# ANALYZE MISSING DATA PATTERNS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "missing_analysis = []\n",
    "\n",
    "for name, G in xferfiles.items():\n",
    "    year = int(name.split('_')[-1])\n",
    "    \n",
    "    total_edges = G.number_of_edges()\n",
    "    missing_rating = 0\n",
    "    missing_stars = 0\n",
    "    has_rating = 0\n",
    "    has_stars = 0\n",
    "    \n",
    "    # Track ratings by star level for missing data\n",
    "    missing_by_star = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 'unknown': 0}\n",
    "    present_by_star = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    \n",
    "    for u, v, data in G.edges(data=True):\n",
    "        rating = data.get('ratings', '')\n",
    "        stars = data.get('stars', '')\n",
    "        \n",
    "        # Check rating presence\n",
    "        if not rating or rating in ['', '0.0', 'None']:\n",
    "            missing_rating += 1\n",
    "            \n",
    "            # What star level is this missing rating?\n",
    "            if stars and stars not in ['', 'None']:\n",
    "                try:\n",
    "                    star_val = int(float(stars))\n",
    "                    if 1 <= star_val <= 5:\n",
    "                        missing_by_star[star_val] += 1\n",
    "                    else:\n",
    "                        missing_by_star['unknown'] += 1\n",
    "                except:\n",
    "                    missing_by_star['unknown'] += 1\n",
    "            else:\n",
    "                missing_by_star['unknown'] += 1\n",
    "        else:\n",
    "            has_rating += 1\n",
    "            \n",
    "            # Track star distribution of present ratings\n",
    "            if stars and stars not in ['', 'None']:\n",
    "                try:\n",
    "                    star_val = int(float(stars))\n",
    "                    if 1 <= star_val <= 5:\n",
    "                        present_by_star[star_val] += 1\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Check stars presence\n",
    "        if not stars or stars in ['', 'None']:\n",
    "            missing_stars += 1\n",
    "        else:\n",
    "            has_stars += 1\n",
    "    \n",
    "    missing_pct = (missing_rating / total_edges * 100) if total_edges > 0 else 0\n",
    "    \n",
    "    missing_analysis.append({\n",
    "        'Year': year,\n",
    "        'Total Edges': total_edges,\n",
    "        'Missing Ratings': missing_rating,\n",
    "        'Missing %': missing_pct,\n",
    "        'Missing 2-star': missing_by_star[2],\n",
    "        'Missing 3-star': missing_by_star[3],\n",
    "        'Missing 4-star': missing_by_star[4],\n",
    "        'Missing 5-star': missing_by_star[5],\n",
    "        'Missing Unknown': missing_by_star['unknown'],\n",
    "        'Present 2-star': present_by_star[2],\n",
    "        'Present 3-star': present_by_star[3],\n",
    "        'Present 4-star': present_by_star[4],\n",
    "        'Present 5-star': present_by_star[5]\n",
    "    })\n",
    "    \n",
    "    print(f\"{year}:\")\n",
    "    print(f\"  Total transfers: {total_edges}\")\n",
    "    print(f\"  Missing ratings: {missing_rating} ({missing_pct:.1f}%)\")\n",
    "    print(f\"  Missing by star level:\")\n",
    "    print(f\"    2-star: {missing_by_star[2]}\")\n",
    "    print(f\"    3-star: {missing_by_star[3]}\")\n",
    "    print(f\"    4-star: {missing_by_star[4]}\")\n",
    "    print(f\"    5-star: {missing_by_star[5]}\")\n",
    "    print(f\"    Unknown: {missing_by_star['unknown']}\")\n",
    "    print()\n",
    "\n",
    "missing_df = pd.DataFrame(missing_analysis)\n",
    "print(\"\\nSummary Table:\")\n",
    "print(missing_df.to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# CALCULATE NPV WITH UNCERTAINTY BOUNDS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NPV CALCULATION WITH CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def calculate_npv_with_bounds(G, year):\n",
    "    \"\"\"\n",
    "    Calculate NPV for each school with uncertainty bounds\n",
    "    based on missing data.\n",
    "    \"\"\"\n",
    "    school_stats = {}\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        in_transfers = []\n",
    "        out_transfers = []\n",
    "        in_missing = 0\n",
    "        out_missing = 0\n",
    "        \n",
    "        # Incoming transfers\n",
    "        for pred in G.predecessors(node):\n",
    "            for key, data in G[pred][node].items() if isinstance(G, nx.MultiDiGraph) else [(0, G[pred][node])]:\n",
    "                rating = data.get('ratings', '')\n",
    "                if rating and rating not in ['', '0.0', 'None']:\n",
    "                    in_transfers.append(float(rating))\n",
    "                else:\n",
    "                    in_missing += 1\n",
    "        \n",
    "        # Outgoing transfers\n",
    "        for succ in G.successors(node):\n",
    "            for key, data in G[node][succ].items() if isinstance(G, nx.MultiDiGraph) else [(0, G[node][succ])]:\n",
    "                rating = data.get('ratings', '')\n",
    "                if rating and rating not in ['', '0.0', 'None']:\n",
    "                    out_transfers.append(float(rating))\n",
    "                else:\n",
    "                    out_missing += 1\n",
    "        \n",
    "        # Calculate NPV components\n",
    "        in_sum = sum(in_transfers)\n",
    "        out_sum = sum(out_transfers)\n",
    "        npv = in_sum - out_sum\n",
    "        \n",
    "        # Calculate uncertainty bounds (assume missing values could be ±0.1)\n",
    "        # Best case: missing incoming are high (0.95), missing outgoing are low (0.75)\n",
    "        # Worst case: missing incoming are low (0.75), missing outgoing are high (0.95)\n",
    "        best_case_npv = (in_sum + in_missing * 0.95) - (out_sum + out_missing * 0.75)\n",
    "        worst_case_npv = (in_sum + in_missing * 0.75) - (out_sum + out_missing * 0.95)\n",
    "        \n",
    "        uncertainty = (best_case_npv - worst_case_npv) / 2\n",
    "        \n",
    "        school_stats[node] = {\n",
    "            'npv': npv,\n",
    "            'net_degree': len(in_transfers) - len(out_transfers),\n",
    "            'in_count': len(in_transfers),\n",
    "            'out_count': len(out_transfers),\n",
    "            'in_missing': in_missing,\n",
    "            'out_missing': out_missing,\n",
    "            'total_missing': in_missing + out_missing,\n",
    "            'uncertainty': uncertainty,\n",
    "            'best_case': best_case_npv,\n",
    "            'worst_case': worst_case_npv\n",
    "        }\n",
    "    \n",
    "    return school_stats\n",
    "\n",
    "# Calculate for most recent year\n",
    "most_recent_year = max([int(name.split('_')[-1]) for name in xferfiles.keys()])\n",
    "most_recent_graph_name = f\"transfer_portal_{most_recent_year}\"\n",
    "G_recent = xferfiles[most_recent_graph_name]\n",
    "\n",
    "stats = calculate_npv_with_bounds(G_recent, most_recent_year)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "results_df['school'] = results_df.index\n",
    "results_df = results_df.sort_values('npv', ascending=False)\n",
    "\n",
    "print(f\"Top 20 Schools by NPV ({most_recent_year}) with Uncertainty:\")\n",
    "print(\"=\"*70)\n",
    "top20 = results_df.head(20)[['school', 'npv', 'net_degree', 'in_count', 'out_count', \n",
    "                               'total_missing', 'uncertainty', 'best_case', 'worst_case']]\n",
    "print(top20.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Average uncertainty across all schools: ±{results_df['uncertainty'].mean():.2f}\")\n",
    "print(f\"2. Max uncertainty: ±{results_df['uncertainty'].max():.2f} ({results_df.loc[results_df['uncertainty'].idxmax(), 'school']})\")\n",
    "print(f\"3. Schools with >5 missing transfers: {len(results_df[results_df['total_missing'] > 5])}\")\n",
    "\n",
    "# Check ranking stability\n",
    "print(\"\\n4. Ranking Stability Analysis:\")\n",
    "results_df['rank'] = range(1, len(results_df) + 1)\n",
    "results_df_best = results_df.copy()\n",
    "results_df_best = results_df_best.sort_values('best_case', ascending=False)\n",
    "results_df_best['rank_best'] = range(1, len(results_df_best) + 1)\n",
    "\n",
    "results_df = results_df.merge(results_df_best[['school', 'rank_best']], on='school')\n",
    "results_df['rank_change'] = abs(results_df['rank'] - results_df['rank_best'])\n",
    "\n",
    "print(f\"   Average rank change in best-case scenario: {results_df['rank_change'].mean():.1f} positions\")\n",
    "print(f\"   Max rank change: {results_df['rank_change'].max():.0f} positions\")\n",
    "print(f\"   Schools with rank change >5: {len(results_df[results_df['rank_change'] > 5])}\")\n",
    "\n",
    "print(\"\\n5. Most Affected Schools (highest uncertainty):\")\n",
    "most_affected = results_df.nlargest(5, 'uncertainty')[['school', 'npv', 'total_missing', 'uncertainty', 'rank_change']]\n",
    "print(most_affected.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
