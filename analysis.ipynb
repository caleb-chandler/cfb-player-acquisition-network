{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c641ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress, zscore, poisson, norm, ks_2samp\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from plottable import Table\n",
    "from plottable import ColumnDefinition\n",
    "from plottable.plots import image\n",
    "import seaborn as sns\n",
    "from networkx.algorithms import bipartite\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import curve_fit\n",
    "from itertools import combinations\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2740eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 5 files from xfer, 27 files from rec, 27 files from projected, and supplemental data\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "\n",
    "xferpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\transferportal\\cleaned\")\n",
    "recpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\recruiting\\bip\")\n",
    "projectedpath = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\recruiting\\projections\\combined\")\n",
    "xferfiles = {}\n",
    "recfiles = {}\n",
    "recfilesproj = {}\n",
    "\n",
    "for file_path in xferpath.glob('*_cleaned.graphml'):\n",
    "    name = file_path.stem.replace('_cleaned', '')\n",
    "    G_x = nx.read_graphml(file_path)\n",
    "    xferfiles[name] = G_x\n",
    "\n",
    "for file_path in recpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_r = nx.read_graphml(file_path)\n",
    "    recfiles[name] = G_r\n",
    "\n",
    "for file_path in projectedpath.glob('*.graphml'):\n",
    "    name = file_path.stem\n",
    "    G_p = nx.read_graphml(file_path)\n",
    "    recfilesproj[name] = G_p\n",
    "\n",
    "nd_npv_ppa_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\analysis\\xfer\\nd_npv\\degree_analysis_ppa.csv')\n",
    "nd_npv_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\analysis\\xfer\\nd_npv\\degree_analysis_rating.csv')\n",
    "comprehensive_metrics_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\analysis\\metrics\\ctm_new_and_not_improved.csv')\n",
    "teamratings_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\supplemental\\team_performance.csv')\n",
    "playerratings_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\supplemental\\player_performance.csv', encoding='latin1')\n",
    "rosters_df = pd.read_csv(r'C:\\Users\\User\\Documents\\cfb project\\data\\supplemental\\rosters.csv', dtype={5: str})\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(xferfiles)} files from xfer, {len(recfiles)} files from rec, {len(recfilesproj)} files from projected, and supplemental data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ND/NPV\n",
    "\n",
    "# 1. DEFINE CALCULATION LOGIC\n",
    "\n",
    "def nd_npv_rating(G):\n",
    "    \"\"\"\n",
    "    Calculate NPV for each school based on summing individual player ratings.\n",
    "    Includes uncertainty bounds for missing data.\n",
    "    \"\"\"\n",
    "    school_stats = {}\n",
    "    \n",
    "    for node in G.nodes():\n",
    "\n",
    "        in_transfers = []\n",
    "        out_transfers = []\n",
    "        in_missing = 0\n",
    "        out_missing = 0\n",
    "        \n",
    "        # incoming\n",
    "        for pred in G.predecessors(node):\n",
    "            for key, data in G[pred][node].items():\n",
    "                rating = data.get('ratings', '')\n",
    "                try:\n",
    "                    # check if rating is a valid number\n",
    "                    if rating and str(rating) not in ['', '0.0', 'None', 'nan']:\n",
    "                        in_transfers.append(float(rating))\n",
    "                    else:\n",
    "                        in_missing += 1\n",
    "                except ValueError:\n",
    "                    in_missing += 1\n",
    "        \n",
    "        # outgoing\n",
    "        for succ in G.successors(node):\n",
    "            for key, data in G[node][succ].items():\n",
    "                rating = data.get('ratings', '')\n",
    "                try:\n",
    "                    if rating and str(rating) not in ['', '0.0', 'None', 'nan']:\n",
    "                        out_transfers.append(float(rating))\n",
    "                    else:\n",
    "                        out_missing += 1\n",
    "                except ValueError:\n",
    "                    out_missing += 1\n",
    "        \n",
    "        # calculate sums\n",
    "        in_sum = sum(in_transfers)\n",
    "        out_sum = sum(out_transfers)\n",
    "        npv = in_sum - out_sum\n",
    "        \n",
    "        # calculate uncertainty bounds\n",
    "        best_case_npv = (in_sum + in_missing * 0.95) - (out_sum + out_missing * 0.75)\n",
    "        worst_case_npv = (in_sum + in_missing * 0.75) - (out_sum + out_missing * 0.95)\n",
    "        \n",
    "        # assumed npv is the midpoint\n",
    "        assumed_npv = (best_case_npv + worst_case_npv) / 2\n",
    "        \n",
    "        # if no missing data, assumed is just raw npv\n",
    "        if (in_missing + out_missing) == 0:\n",
    "            assumed_npv = npv\n",
    "            \n",
    "        uncertainty = (best_case_npv - worst_case_npv) / 2\n",
    "        \n",
    "        conference = G.nodes[node].get('conference')\n",
    "        classification = G.nodes[node].get('classification')\n",
    "\n",
    "        school_stats[node] = {\n",
    "            'conference': conference,\n",
    "            'classification': classification,\n",
    "            'NPV_raw': round(npv, 2),\n",
    "            'NPV_assumed': round(assumed_npv, 2),\n",
    "            'in_wt': round(in_sum, 2),\n",
    "            'out_wt': round(out_sum, 2),\n",
    "            'net_degree': len(in_transfers) - len(out_transfers),\n",
    "            'in_count': len(in_transfers),\n",
    "            'out_count': len(out_transfers),\n",
    "            'in_missing': in_missing,\n",
    "            'out_missing': out_missing,\n",
    "            'missing': in_missing + out_missing,\n",
    "            'uncertainty': round(uncertainty, 2),\n",
    "            'NPV_high': round(best_case_npv, 2),\n",
    "            'NPV_low': round(worst_case_npv, 2)\n",
    "        }\n",
    "    \n",
    "    return school_stats\n",
    "\n",
    "# 2. EXECUTE AND BUILD DATAFRAME\n",
    "\n",
    "all_npv_records = []\n",
    "\n",
    "print(\"Processing files...\")\n",
    "\n",
    "for filename, G in xferfiles.items():\n",
    "    # extract year from filename\n",
    "    year_match = re.search(r'(\\d{4})', filename)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "        \n",
    "        # calculate stats for this year\n",
    "        stats = nd_npv_rating(G)\n",
    "        \n",
    "        # flatten into list of dicts\n",
    "        for school, data in stats.items():\n",
    "            record = data.copy()\n",
    "            record['school'] = school\n",
    "            record['year'] = year\n",
    "            all_npv_records.append(record)\n",
    "    else:\n",
    "        print(f\"  Warning: Could not extract year from {filename}\")\n",
    "\n",
    "# create df\n",
    "npv_df = pd.DataFrame(all_npv_records)\n",
    "\n",
    "# 3. CALCULATE STANDARDIZED METRICS\n",
    "\n",
    "if not npv_df.empty:\n",
    "    # standardize school names\n",
    "    npv_df['school'] = npv_df['school'].astype(str).str.strip()\n",
    "    \n",
    "    # calculate z scores of assumed npv by specific year\n",
    "    npv_df['NPV_zscore'] = npv_df.groupby('year')['NPV_assumed'].transform(\n",
    "        lambda x: zscore(x, nan_policy='omit')\n",
    "    )\n",
    "    \n",
    "    # calculate percentiles\n",
    "    npv_df['NPV_percentile'] = npv_df.groupby('year')['NPV_assumed'].rank(pct=True) * 100\n",
    "    \n",
    "    # round to 2 decimal places\n",
    "    npv_df['NPV_zscore'] = npv_df['NPV_zscore'].round(2)\n",
    "    npv_df['NPV_percentile'] = npv_df['NPV_percentile'].round(2)\n",
    "\n",
    "    # reorder columns\n",
    "    cols = ['year', 'school', 'classification', 'conference', 'NPV_zscore', \n",
    "            'NPV_percentile', 'NPV_raw', 'NPV_assumed', \n",
    "            'net_degree', 'in_count', 'out_count', \n",
    "            'in_wt', 'out_wt', 'uncertainty', 'NPV_high', 'NPV_low',\n",
    "            'missing', 'in_missing', 'out_missing']\n",
    "            \n",
    "    # keep only columns that exist (in case no missing data found)\n",
    "    cols = [c for c in cols if c in npv_df.columns]\n",
    "    npv_df = npv_df[cols]\n",
    "\n",
    "    print(f\"\\nSuccessfully created npv_df with {len(npv_df)} records.\")\n",
    "    print(f\"Years covered: {sorted(npv_df['year'].unique())}\")\n",
    "    print(\"\\nSample Data (first 5 rows):\")\n",
    "    print(npv_df[['year', 'school', 'NPV_zscore', 'NPV_raw', 'NPV_assumed']].head().to_string())\n",
    "else:\n",
    "    print(\"Error: No data records generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95445df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE TALENT METRICS CALCULATION\n",
    "# RVI, GVO, NPV, TD, PCR\n",
    "\n",
    "# TODO: Fix RVI z-scores not showing up\n",
    "# TODO: Rework roster churn formula for pre-portal years\n",
    "\n",
    "# STEP 1: EXTRACT RECRUITING DATA & METADATA\n",
    "\n",
    "print(\"\\nStep 1: Processing recruiting data & extracting fallback metadata...\")\n",
    "\n",
    "all_recruits = []\n",
    "school_metadata_fallback = {} # (year, school) -> {conf, class} for years/teams not in npv df\n",
    "\n",
    "for year in range(2000, 2026):\n",
    "    graph_name = f\"recruiting_network_{year}\"\n",
    "    \n",
    "    if graph_name not in recfiles:\n",
    "        # print(f\"  Warning: {graph_name} not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    G = recfiles[graph_name]\n",
    "    count_for_year = 0\n",
    "    \n",
    "    # 1. iterate edges to get recruits and metadata\n",
    "    for u, v, key, data in G.edges(data=True, keys=True):\n",
    "        school_node = None\n",
    "        \n",
    "        # identify school node\n",
    "        if G.nodes[v].get('type') == 'School':\n",
    "            school_node = v\n",
    "        elif G.nodes[u].get('type') == 'School':\n",
    "            school_node = u\n",
    "            \n",
    "        if school_node:\n",
    "            school_name = str(school_node).strip()\n",
    "            \n",
    "            # extract metadata (as fallback for non-NPV years)\n",
    "            if (year, school_name) not in school_metadata_fallback:\n",
    "                node_attrs = G.nodes[school_node]\n",
    "                school_metadata_fallback[(year, school_name)] = {\n",
    "                    'classification': node_attrs.get('classification', 'Unknown'),\n",
    "                    'conference': node_attrs.get('conference', 'Unknown')\n",
    "                }\n",
    "\n",
    "            # 3. extract recruit data\n",
    "            rating = data.get('rating', None)\n",
    "            stars = data.get('stars', None)\n",
    "            \n",
    "            if rating is not None:\n",
    "                try:\n",
    "                    rating_val = float(rating)\n",
    "                    if rating_val > 0:\n",
    "                        all_recruits.append({\n",
    "                            'year': year,\n",
    "                            'school': school_name,\n",
    "                            'player_name': data.get('player'),\n",
    "                            'recruit_id': data.get('id'),\n",
    "                            'athlete_id': data.get('athlete_id'),\n",
    "                            'rating': rating_val,\n",
    "                            'stars': int(stars) if stars else None,\n",
    "                            'position': data.get('position')\n",
    "                        })\n",
    "                        count_for_year += 1\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "\n",
    "    print(f\"  {year}: Found {count_for_year} recruits\")\n",
    "\n",
    "df_recruits = pd.DataFrame(all_recruits)\n",
    "\n",
    "# metrics for recruits\n",
    "if not df_recruits.empty:\n",
    "    df_recruits['school'] = df_recruits['school'].astype(str).str.strip()\n",
    "    print(\"  Calculating recruiting Z-scores (Player Level)...\")\n",
    "    df_recruits['rating_percentile'] = df_recruits.groupby('year')['rating'].rank(pct=True) * 100\n",
    "    df_recruits['rating_zscore'] = df_recruits.groupby('year')['rating'].transform(lambda x: zscore(x, nan_policy='omit'))\n",
    "else:\n",
    "    print(\"CRITICAL WARNING: No recruits found.\")\n",
    "\n",
    "# STEP 2: BUILD PLAYER TRACKING (For GVO)\n",
    "\n",
    "print(\"\\nStep 2: Building player tracking system...\")\n",
    "player_recruit_info = {}\n",
    "for _, row in df_recruits.iterrows():\n",
    "    aid = str(row['athlete_id']) if pd.notna(row['athlete_id']) else None\n",
    "    if aid and aid != 'Unknown':\n",
    "        player_recruit_info[aid] = {\n",
    "            'rating': row['rating'],\n",
    "            'rating_zscore': row['rating_zscore'],\n",
    "            'rating_percentile': row['rating_percentile']\n",
    "        }\n",
    "\n",
    "# STEP 3: IDENTIFY GRADUATING PLAYERS (GVO)\n",
    "\n",
    "print(\"\\nStep 3: Identifying graduating players...\")\n",
    "rosters_df['player_id'] = rosters_df['player_id'].astype(str)\n",
    "rosters_df['year'] = rosters_df['year'].astype(int)\n",
    "\n",
    "graduating_players = []\n",
    "for year in range(2000, 2025):\n",
    "    curr = rosters_df[rosters_df['year'] == year]\n",
    "    nxt = rosters_df[rosters_df['year'] == year + 1]\n",
    "    next_ids = set(nxt['player_id'].unique())\n",
    "    \n",
    "    for _, player in curr.iterrows():\n",
    "        if player['player_id'] not in next_ids:\n",
    "            rec_info = player_recruit_info.get(str(player['player_id']), None)\n",
    "            graduating_players.append({\n",
    "                'grad_year': year,\n",
    "                'school': str(player['team']).strip(),\n",
    "                'rating': rec_info['rating'] if rec_info else None,\n",
    "                'rating_zscore': rec_info['rating_zscore'] if rec_info else None,\n",
    "                'rating_percentile': rec_info['rating_percentile'] if rec_info else None\n",
    "            })\n",
    "\n",
    "df_graduating = pd.DataFrame(graduating_players)\n",
    "print(f\"  Identified {len(df_graduating)} graduating players\")\n",
    "\n",
    "# STEP 4: AGGREGATE RVI & GVO\n",
    "\n",
    "print(\"\\nStep 4: Aggregating RVI and GVO...\")\n",
    "\n",
    "# RVI\n",
    "rvi_agg = df_recruits.groupby(['year', 'school']).agg({\n",
    "    'rating_zscore': 'sum', 'rating_percentile': 'sum', 'rating': 'sum', 'recruit_id': 'count'\n",
    "}).rename(columns={\n",
    "    'rating_zscore': 'RVI_zscore', 'rating_percentile': 'RVI_percentile', \n",
    "    'rating': 'RVI_raw', 'recruit_id': 'RVI_count'\n",
    "}).reset_index()\n",
    "\n",
    "# GVO\n",
    "gvo_agg = df_graduating[df_graduating['rating'].notna()].groupby(['grad_year', 'school']).agg({\n",
    "    'rating_zscore': 'sum', 'rating_percentile': 'sum', 'rating': 'sum', 'rating': 'count' # count gives player count\n",
    "}).rename(columns={\n",
    "    'rating_zscore': 'GVO_zscore', 'rating_percentile': 'GVO_percentile', \n",
    "    'rating': 'GVO_count' # re-mapped below for raw vs count\n",
    "}).reset_index().rename(columns={'grad_year': 'year'})\n",
    "\n",
    "# Fix GVO Raw/Count (the agg above overwrote rating sum with count)\n",
    "gvo_agg = df_graduating[df_graduating['rating'].notna()].groupby(['grad_year', 'school']).agg({\n",
    "    'rating_zscore': 'sum', 'rating_percentile': 'sum', 'rating': 'sum'\n",
    "}).rename(columns={'rating_zscore': 'GVO_zscore', 'rating_percentile': 'GVO_percentile', 'rating': 'GVO_raw'}).reset_index().rename(columns={'grad_year': 'year'})\n",
    "\n",
    "gvo_counts = df_graduating.groupby(['grad_year', 'school']).size().reset_index(name='GVO_total_count').rename(columns={'grad_year': 'year'})\n",
    "# rated count\n",
    "gvo_rated_counts = df_graduating[df_graduating['rating'].notna()].groupby(['grad_year', 'school']).size().reset_index(name='GVO_count').rename(columns={'grad_year': 'year'})\n",
    "\n",
    "# STEP 5: PREPARE NPV\n",
    "\n",
    "print(\"\\nStep 5: Preparing NPV data from nd_npv_df...\")\n",
    "\n",
    "if 'nd_npv_df' in locals():\n",
    "    npv_data = nd_npv_df.copy()\n",
    "    \n",
    "    # 1. standardize school\n",
    "    if 'school' not in npv_data.columns and 'team' in npv_data.columns:\n",
    "        npv_data = npv_data.rename(columns={'team': 'school'})\n",
    "    npv_data['school'] = npv_data['school'].astype(str).str.strip()\n",
    "    \n",
    "    # 4. calculate z score if not present\n",
    "    if 'NPV_zscore' not in npv_data.columns and 'NPV_assumed' in npv_data.columns:\n",
    "        print(\"  Calculating NPV z-scores...\")\n",
    "        npv_data['NPV_zscore'] = npv_data.groupby('year')['NPV_assumed'].transform(lambda x: zscore(x, nan_policy='omit'))\n",
    "    \n",
    "    print(f\"  Loaded NPV data: {len(npv_data)} records\")\n",
    "else:\n",
    "    print(\"  CRITICAL ERROR: nd_npv_df not found.\")\n",
    "    npv_data = pd.DataFrame(columns=['year', 'school'])\n",
    "\n",
    "# STEP 6: MASTER MERGE\n",
    "\n",
    "print(\"\\nStep 6: Creating Master DataFrame...\")\n",
    "\n",
    "# 1. create spine from all sources\n",
    "sources = [rvi_agg[['year', 'school']], gvo_agg[['year', 'school']], npv_data[['year', 'school']]]\n",
    "# add fallback metadata keys to spine to ensure pre-2021 teams exist\n",
    "fb_keys = [{'year': k[0], 'school': k[1]} for k in school_metadata_fallback.keys()]\n",
    "if fb_keys: sources.append(pd.DataFrame(fb_keys))\n",
    "\n",
    "master = pd.concat([df for df in sources if not df.empty]).drop_duplicates().sort_values(['year', 'school'])\n",
    "\n",
    "# 2. merge data\n",
    "merged = master.merge(rvi_agg, on=['year', 'school'], how='left')\n",
    "merged = merged.merge(gvo_agg, on=['year', 'school'], how='left')\n",
    "merged = merged.merge(gvo_counts, on=['year', 'school'], how='left')\n",
    "merged = merged.merge(gvo_rated_counts, on=['year', 'school'], how='left')\n",
    "merged = merged.merge(npv_data, on=['year', 'school'], how='left')\n",
    "\n",
    "# 3. handle metadata (conference/classification)\n",
    "#    priority 1: use what's in npv_data\n",
    "#    priority 2: se fallback from recruiting graphs\n",
    "if 'conference' not in merged.columns:\n",
    "    # use fallback dict\n",
    "    def get_meta(row, col):\n",
    "        key = (row['year'], row['school'])\n",
    "        if key in school_metadata_fallback:\n",
    "            return school_metadata_fallback[key].get(col, 'Unknown')\n",
    "        return 'Unknown'\n",
    "        \n",
    "    merged['conference'] = merged.apply(lambda x: get_meta(x, 'conference'), axis=1)\n",
    "    merged['classification'] = merged.apply(lambda x: get_meta(x, 'classification'), axis=1)\n",
    "else:\n",
    "    # if merged from npv, fill gaps using fallback for non-npv years\n",
    "    # because npv data likely only exists for 2021\n",
    "    print(\"  Using existing metadata columns, filling gaps...\")\n",
    "    for idx, row in merged[merged['conference'].isna()].iterrows():\n",
    "        key = (row['year'], row['school'])\n",
    "        if key in school_metadata_fallback:\n",
    "            merged.at[idx, 'conference'] = school_metadata_fallback[key].get('conference', 'Unknown')\n",
    "            merged.at[idx, 'classification'] = school_metadata_fallback[key].get('classification', 'Unknown')\n",
    "\n",
    "# fill metric NaNs with 0 for calculation\n",
    "metric_cols = [c for c in merged.columns if any(x in c for x in ['RVI', 'GVO', 'NPV'])]\n",
    "merged[metric_cols] = merged[metric_cols].fillna(0)\n",
    "\n",
    "# STEP 7: CALCULATE COMPOSITE METRICS\n",
    "\n",
    "print(\"\\nStep 7: Calculating TD and PCR...\")\n",
    "\n",
    "# 1. calculate team-level z scores for rvi and gvo\n",
    "merged['RVI_team_zscore'] = merged.groupby('year')['RVI_raw'].transform(\n",
    "    lambda x: zscore(x, nan_policy='omit')\n",
    ")\n",
    "\n",
    "merged['GVO_team_zscore'] = merged.groupby('year')['GVO_raw'].transform(\n",
    "    lambda x: zscore(x, nan_policy='omit')\n",
    ")\n",
    "\n",
    "# 2. calculate talent delta\n",
    "merged['TD_zscore'] = (\n",
    "    merged['RVI_team_zscore'].fillna(0) + \n",
    "    merged['NPV_zscore'].fillna(0) - \n",
    "    merged['GVO_team_zscore'].fillna(0)\n",
    ")\n",
    "\n",
    "merged['TD_raw'] = merged['RVI_raw'] + merged['NPV_raw'] - merged['GVO_raw']\n",
    "merged['TD_count'] = merged['RVI_count'] + merged['net_degree'] - merged['GVO_count']\n",
    "\n",
    "# 3. calculate portal contribution ratio (pcr)\n",
    "\n",
    "# FIXED: Calculate ratio FIRST, then z-score it\n",
    "\n",
    "# Calculate raw ratio\n",
    "merged['PCR_raw_ratio'] = np.where(\n",
    "    merged['RVI_raw'] > 0, \n",
    "    merged['NPV_assumed'] / merged['RVI_raw'], \n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# THEN z-score the ratio within each year\n",
    "merged['PCR_zscore'] = merged.groupby('year')['PCR_raw_ratio'].transform(\n",
    "    lambda x: zscore(x, nan_policy='omit')\n",
    ")\n",
    "\n",
    "# Keep the raw ratio as PCR_raw (more interpretable than the ratio itself)\n",
    "merged['PCR_raw'] = merged['PCR_raw_ratio']\n",
    "\n",
    "# Count-based version (also useful)\n",
    "merged['PCR_count_ratio'] = np.where(\n",
    "    merged['RVI_count'] > 0,\n",
    "    merged['net_degree'] / merged['RVI_count'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "merged['PCR_count'] = merged.groupby('year')['PCR_count_ratio'].transform(\n",
    "    lambda x: zscore(x, nan_policy='omit')\n",
    ")\n",
    "\n",
    "print(f\"  PCR_zscore range: {merged['PCR_zscore'].min():.2f} to {merged['PCR_zscore'].max():.2f}\")\n",
    "\n",
    "# 4. roster churn\n",
    "roster_sizes = rosters_df.groupby(['year', 'team']).size().reset_index(name='roster_size')\n",
    "merged = merged.merge(roster_sizes, left_on=['year', 'school'], right_on=['year', 'team'], how='left')\n",
    "merged = merged.drop(columns=['team'])\n",
    "\n",
    "merged['new_players'] = merged['RVI_count'] + merged['in_count']\n",
    "merged['roster_churn_pct'] = np.where(\n",
    "    merged['roster_size'] > 0,\n",
    "    (merged['new_players'] / merged['roster_size']) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# 5. calculate team-level percentiles\n",
    "#    this replaces the \"sum of player percentiles\" with \"rank of team total\"\n",
    "merged['RVI_percentile'] = merged.groupby('year')['RVI_raw'].rank(pct=True) * 100\n",
    "merged['GVO_percentile'] = merged.groupby('year')['GVO_raw'].rank(pct=True) * 100\n",
    "\n",
    "# STEP 8: FINALIZE AND SAVE\n",
    "\n",
    "print(\"\\nStep 8: Finalizing output...\")\n",
    "\n",
    "# 1. Replace Player-Sum Z-Scores with Team-Level Z-Scores\n",
    "#    This effectively swaps the metric in the final output\n",
    "merged['RVI_zscore'] = merged['RVI_team_zscore'].fillna(0)\n",
    "merged['GVO_zscore'] = merged['GVO_team_zscore'].fillna(0)\n",
    "\n",
    "# 2. define strict column order\n",
    "column_order = [\n",
    "    # metadata\n",
    "    'year', 'school', 'classification', 'conference',\n",
    "    \n",
    "    # composite metrics\n",
    "    'TD_zscore', 'TD_raw', 'TD_count',\n",
    "    'PCR_zscore', 'PCR_raw', 'PCR_raw_ratio', 'PCR_count'\n",
    "    \n",
    "    # rvi\n",
    "    'RVI_zscore', 'RVI_percentile', 'RVI_raw', 'RVI_count',\n",
    "    \n",
    "    # gvo\n",
    "    'GVO_zscore', 'GVO_percentile', 'GVO_raw', 'GVO_count', 'GVO_total_count',\n",
    "    \n",
    "    # npv\n",
    "    'NPV_zscore', 'NPV_percentile', 'NPV_raw', 'NPV_assumed', 'NPV_net_count',\n",
    "    \n",
    "    # roster context\n",
    "    'roster_size', 'new_players', 'roster_churn_pct'\n",
    "]\n",
    "\n",
    "# 3. filter and round\n",
    "# keep only the columns defined above that exist in the dataframe\n",
    "final_columns = [col for col in column_order if col in merged.columns]\n",
    "final_df = merged[final_columns]\n",
    "\n",
    "# round numeric columns\n",
    "numeric_cols = final_df.select_dtypes(include=[np.number]).columns\n",
    "final_df[numeric_cols] = final_df[numeric_cols].round(2)\n",
    "\n",
    "# 4. save\n",
    "output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\analysis\") / \"comprehensive_talent_metrics.csv\"\n",
    "try:\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✓ Saved to: {output_path}\")\n",
    "    print(f\"  Final Data Shape: {final_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error saving file: {e}\")\n",
    "\n",
    "# sample output\n",
    "print(\"\\nTop 5 Schools by TD_raw in 2024:\")\n",
    "sample = final_df[final_df['year'] == 2024].nlargest(5, 'TD_raw')[\n",
    "    ['year', 'school', 'TD_raw', 'RVI_zscore', 'NPV_zscore', 'GVO_zscore']\n",
    "]\n",
    "print(sample.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS (1 FOR RATING, 2 FOR PPA, 0 FOR NEITHER)\n",
    "switch = 0\n",
    "if switch == 1: # prevent accidental overwrite\n",
    "    output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\analysis\\nd_npv\") / f\"degree_analysis_rating.csv\"\n",
    "    npv_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print('NPV by rating successful')\n",
    "\n",
    "if switch == 2:\n",
    "    output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\data\\analysis\\nd_npv\") / f\"degree_analysis_ppa.csv\"\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print('NPV by PPA successful')\n",
    "\n",
    "if switch == 0:\n",
    "    print(\"Switch is off; operation skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e741b",
   "metadata": {},
   "source": [
    "TALENT METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93c2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Transfer Portal Divergence visualization...\n",
      "  Years analyzed: 2000 - 2025\n",
      "✓ Portal Divergence visualization saved!\n",
      "\n",
      "======================================================================\n",
      "PORTAL DIVERGENCE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Talent Concentration (TD Standard Deviation):\n",
      "  Pre-Portal Average (2000-2020):  0.951\n",
      "  Post-Portal Average (2021-2024): 1.053\n",
      "  Change: +10.7%\n",
      "\n",
      "Roster Churn:\n",
      "  Pre-Portal Average: 0.00%\n",
      "  Post-Portal Average: 8.37%\n",
      "  Change: +8.37 percentage points\n",
      "\n",
      "Trend Analysis:\n",
      "  Pre-Portal TD trend slope: -0.0252 (p=0.0017)\n",
      "  Post-Portal TD trend slope: 0.0261 (p=0.5392)\n",
      "  → Talent stratification is ACCELERATING post-portal\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# THE TRANSFER PORTAL DIVERGENCE\n",
    "# Visualizing talent stratification and roster instability\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nGenerating Transfer Portal Divergence visualization...\")\n",
    "\n",
    "# Load the comprehensive metrics\n",
    "df = comprehensive_metrics_df.copy()\n",
    "\n",
    "# Calculate annual metrics\n",
    "annual_stats = df.groupby('year').agg({\n",
    "    'TD_zscore': ['std', 'mean'],  # Talent concentration\n",
    "    'roster_churn_pct': 'mean',     # Average roster turnover\n",
    "    'PCR_zscore': 'std'             # Portal reliance variation\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "annual_stats.columns = ['year', 'TD_std', 'TD_mean', 'churn_mean', 'PCR_std']\n",
    "\n",
    "# Filter to years with sufficient data\n",
    "annual_stats = annual_stats[annual_stats['year'] >= 2000]\n",
    "\n",
    "print(f\"  Years analyzed: {annual_stats['year'].min()} - {annual_stats['year'].max()}\")\n",
    "\n",
    "# ============================================\n",
    "# CREATE DUAL-AXIS PLOT\n",
    "# ============================================\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# PRIMARY AXIS: Talent Concentration (TD Standard Deviation)\n",
    "color1 = 'darkred'\n",
    "ax1.set_xlabel('Year', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Talent Concentration\\n(Std Dev of TD Z-score)', \n",
    "               fontsize=14, fontweight='bold', color=color1)\n",
    "line1 = ax1.plot(annual_stats['year'], annual_stats['TD_std'], \n",
    "                 color=color1, linewidth=3, marker='o', markersize=6, \n",
    "                 label='Talent Concentration', zorder=3)\n",
    "ax1.tick_params(axis='y', labelcolor=color1, labelsize=12)\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# SECONDARY AXIS: Roster Churn\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'darkblue'\n",
    "ax2.set_ylabel('Average Roster Churn (%)', \n",
    "               fontsize=14, fontweight='bold', color=color2)\n",
    "line2 = ax2.plot(annual_stats['year'], annual_stats['churn_mean'], \n",
    "                 color=color2, linewidth=3, marker='s', markersize=6, \n",
    "                 label='Roster Churn %', zorder=3)\n",
    "ax2.tick_params(axis='y', labelcolor=color2, labelsize=12)\n",
    "\n",
    "# ============================================\n",
    "# ADD PORTAL ERA DEMARCATION\n",
    "# ============================================\n",
    "\n",
    "# Vertical line at 2021 (portal era begins)\n",
    "ax1.axvline(x=2021, color='black', linestyle='--', linewidth=2, \n",
    "            alpha=0.7, label='Transfer Portal Era', zorder=2)\n",
    "\n",
    "# Shaded regions\n",
    "ax1.axvspan(annual_stats['year'].min(), 2021, alpha=0.1, color='gray', \n",
    "            label='Pre-Portal Era')\n",
    "ax1.axvspan(2021, annual_stats['year'].max(), alpha=0.1, color='orange', \n",
    "            label='Portal Era')\n",
    "\n",
    "# ============================================\n",
    "# CALCULATE TREND LINES\n",
    "# ============================================\n",
    "\n",
    "# Pre-portal trend (2000-2020)\n",
    "pre_portal = annual_stats[annual_stats['year'] <= 2020]\n",
    "if len(pre_portal) > 1:\n",
    "    slope_pre, intercept_pre, r_pre, p_pre, _ = stats.linregress(\n",
    "        pre_portal['year'], pre_portal['TD_std']\n",
    "    )\n",
    "    ax1.plot(pre_portal['year'], \n",
    "             slope_pre * pre_portal['year'] + intercept_pre,\n",
    "             color=color1, linestyle=':', linewidth=2, alpha=0.5, \n",
    "             label=f'Pre-Portal Trend (slope={slope_pre:.3f})')\n",
    "\n",
    "# Post-portal trend (2021+)\n",
    "post_portal = annual_stats[annual_stats['year'] >= 2021]\n",
    "if len(post_portal) > 1:\n",
    "    slope_post, intercept_post, r_post, p_post, _ = stats.linregress(\n",
    "        post_portal['year'], post_portal['TD_std']\n",
    "    )\n",
    "    ax1.plot(post_portal['year'], \n",
    "             slope_post * post_portal['year'] + intercept_post,\n",
    "             color=color1, linestyle=':', linewidth=2, alpha=0.8, \n",
    "             label=f'Post-Portal Trend (slope={slope_post:.3f})')\n",
    "\n",
    "# ============================================\n",
    "# FORMATTING\n",
    "# ============================================\n",
    "\n",
    "# Title\n",
    "plt.title('The Transfer Portal Divergence:\\nTalent Stratification and Roster Instability (2000-2024)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Combined legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, \n",
    "           loc='upper left', fontsize=11, framealpha=0.95)\n",
    "\n",
    "# Tight layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig('./imgs/xfer/graphs/portal_divergence.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Portal Divergence visualization saved!\")\n",
    "\n",
    "# ============================================\n",
    "# PRINT SUMMARY STATISTICS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PORTAL DIVERGENCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pre_avg_td = pre_portal['TD_std'].mean()\n",
    "post_avg_td = post_portal['TD_std'].mean()\n",
    "td_change = ((post_avg_td - pre_avg_td) / pre_avg_td) * 100\n",
    "\n",
    "pre_avg_churn = pre_portal['churn_mean'].mean()\n",
    "post_avg_churn = post_portal['churn_mean'].mean()\n",
    "churn_change = post_avg_churn - pre_avg_churn\n",
    "\n",
    "print(f\"\\nTalent Concentration (TD Standard Deviation):\")\n",
    "print(f\"  Pre-Portal Average (2000-2020):  {pre_avg_td:.3f}\")\n",
    "print(f\"  Post-Portal Average (2021-2024): {post_avg_td:.3f}\")\n",
    "print(f\"  Change: {td_change:+.1f}%\")\n",
    "\n",
    "print(f\"\\nRoster Churn:\")\n",
    "print(f\"  Pre-Portal Average: {pre_avg_churn:.2f}%\")\n",
    "print(f\"  Post-Portal Average: {post_avg_churn:.2f}%\")\n",
    "print(f\"  Change: {churn_change:+.2f} percentage points\")\n",
    "\n",
    "if len(pre_portal) > 1 and len(post_portal) > 1:\n",
    "    print(f\"\\nTrend Analysis:\")\n",
    "    print(f\"  Pre-Portal TD trend slope: {slope_pre:.4f} (p={p_pre:.4f})\")\n",
    "    print(f\"  Post-Portal TD trend slope: {slope_post:.4f} (p={p_post:.4f})\")\n",
    "    \n",
    "    if slope_post > slope_pre:\n",
    "        print(f\"  → Talent stratification is ACCELERATING post-portal\")\n",
    "    else:\n",
    "        print(f\"  → Talent stratification is DECELERATING post-portal\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TD/PCR/PERFORMANCE SCATTER PLOTS\n",
    "\n",
    "# Merge comprehensive metrics with team ratings\n",
    "merged_analysis = comprehensive_metrics_df.merge(\n",
    "    teamratings_df[['school', 'year', 'fpi', 'srs']], \n",
    "    on=['school', 'year'], \n",
    "    how='inner'  # Only keep rows where both datasets have data\n",
    ")\n",
    "\n",
    "# Drop rows with NaN in key columns\n",
    "merged_analysis = merged_analysis.dropna(subset=['TD_zscore', 'PCR_zscore', 'fpi', 'srs'])\n",
    "\n",
    "print(f\"Merged dataset size: {len(merged_analysis)} school-year combinations\")\n",
    "print(f\"Years covered: {sorted(merged_analysis['year'].unique())}\")\n",
    "\n",
    "TD = merged_analysis['TD_zscore']\n",
    "PCR = merged_analysis['PCR_zscore']\n",
    "FPI = merged_analysis['fpi']\n",
    "SRS = merged_analysis['srs']\n",
    "\n",
    "# TD/PERFORMANCE SCATTER (FPI AND SRS)\n",
    "\n",
    "# FPI\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(TD, FPI, color='mediumblue', alpha=0.6)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(TD, FPI)\n",
    "plt.plot(TD, slope*TD + intercept, color='red', linewidth=2)\n",
    "plt.xlabel('Talent Delta (Z-score)')\n",
    "plt.ylabel('Team Performance (FPI)')\n",
    "plt.title('Scatter Plot of TD vs FPI')\n",
    "leg = plt.legend(['Schools', 'Regression Line'], title=f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}\\np-value: {p_value:.4f}')\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'.\\\\imgs\\\\supp\\\\scatter_td_fpi.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# SRS\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(TD, SRS, color='darkolivegreen', alpha=0.6)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(TD, SRS)\n",
    "plt.plot(TD, slope*TD + intercept, color='red', linewidth=2)\n",
    "plt.xlabel('Talent Delta (Z-score)')\n",
    "plt.ylabel('Team Performance (SRS)')\n",
    "plt.title('Scatter Plot of TD vs SRS')\n",
    "leg = plt.legend(['Schools', 'Regression Line'], title=f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}\\np-value: {p_value:.4f}')\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'.\\\\imgs\\\\supp\\\\scatter_td_srs.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# PCR/PERFORMANCE SCATTER (FPI AND SRS)\n",
    "\n",
    "# FPI\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(PCR, FPI, color='mediumblue', alpha=0.6)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(PCR, FPI)\n",
    "plt.plot(PCR, slope*PCR + intercept, color='red', linewidth=2)\n",
    "plt.xlabel('Portal Contribution Ratio (Z-score)')\n",
    "plt.ylabel('Team Performance (FPI)')\n",
    "plt.title('Scatter Plot of PCR vs FPI')\n",
    "leg = plt.legend(['Schools', 'Regression Line'], title=f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}\\np-value: {p_value:.4f}')\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'.\\\\imgs\\\\supp\\\\scatter_pcr_fpi.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# SRS\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(PCR, SRS, color='darkolivegreen', alpha=0.6)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(PCR, SRS)\n",
    "plt.plot(PCR, slope*PCR + intercept, color='red', linewidth=2)\n",
    "plt.xlabel('Portal Contribution Ratio (Z-score)')\n",
    "plt.ylabel('Team Performance (SRS)')\n",
    "plt.title('Scatter Plot of PCR vs SRS')\n",
    "leg = plt.legend(['Schools', 'Regression Line'], title=f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}\\np-value: {p_value:.4f}')\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'.\\\\imgs\\\\supp\\\\scatter_pcr_srs.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✓ All scatter plots saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e3288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STRATIFICATION ANALYSIS\n",
      "======================================================================\n",
      "Merged dataset size: 3229 school-year combinations\n",
      "Years covered: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "Data distribution:\n",
      "  Total observations: 3229\n",
      "  Pre-Portal (<2021): 2345\n",
      "  Portal Era (2021+): 884\n",
      "\n",
      "✓ Stratification plot saved to: C:\\Users\\User\\Documents\\cfb project\\imgs\\supp\\stratification_td_srs.png\n",
      "\n",
      "Stratification Change Analysis:\n",
      "  Pre-Portal Correlation: r = -0.107\n",
      "  Portal Era Correlation: r = -0.169\n",
      "  RESULT: Correlation has STRENGTHENED by 0.062\n",
      "  INTERPRETATION: Talent advantages are translating MORE directly to wins in the portal era.\n",
      "\n",
      "======================================================================\n",
      "PORTAL STRATEGY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Elite Tier: r=0.116, p=0.1141\n",
      "\n",
      "Mid Tier: r=0.183, p=0.0221\n",
      "\n",
      "Low Tier: r=0.179, p=0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4324\\2089288359.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  portal_strategy['performance_tier'] = pd.cut(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Portal strategy payoff plot saved!\n",
      "\n",
      "Quadrant Distribution (Portal Era):\n",
      "  Portal-Focused + Improvement: 90 (17.2%)\n",
      "  Recruiting-Focused + Improvement: 168 (32.1%)\n",
      "  Recruiting-Focused + Decline: 181 (34.5%)\n",
      "  Portal-Focused + Decline: 75 (14.3%)\n",
      "\n",
      "======================================================================\n",
      "✓ ALL ANALYSES COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# MODIFIED TD/PCR/PERFORMANCE\n",
    "\n",
    "# ============================================\n",
    "# STRATIFICATION ANALYSIS: TD vs Performance Over Time\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATIFICATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "analysis_df = comprehensive_metrics_df.copy()\n",
    "\n",
    "# CRITICAL FIX: Fill missing Portal metrics with 0 for pre-2021 years\n",
    "# This prevents them from being dropped as \"incomplete data\"\n",
    "portal_cols = ['NPV_zscore', 'NPV_raw', 'PCR_zscore', 'PCR_raw']\n",
    "for col in portal_cols:\n",
    "    if col in analysis_df.columns:\n",
    "        analysis_df[col] = analysis_df[col].fillna(0)\n",
    "\n",
    "# 2. Merge with Performance Data\n",
    "# Using 'inner' is fine as long as school names match\n",
    "merged_analysis = analysis_df.merge(\n",
    "    teamratings_df[['school', 'year', 'fpi', 'srs']], \n",
    "    on=['school', 'year'], \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 3. Filter Data\n",
    "# FIX: Only drop rows missing the specific variables we are PLOTTING (TD and SRS)\n",
    "# We remove 'fpi' and 'PCR_zscore' from this check to allow pre-2005 (no FPI) and pre-2021 (no PCR) years.\n",
    "merged_analysis = merged_analysis.dropna(subset=['TD_zscore', 'srs'])\n",
    "\n",
    "# Add conference tier classification\n",
    "def classify_conference(conf):\n",
    "    \"\"\"Classify conferences as P5/P4 or G5/G6\"\"\"\n",
    "    # Adjust list for historical accuracy if needed\n",
    "    power_conferences = ['SEC', 'Big Ten', 'Big 12', 'ACC', 'Pac-12', 'Pac-10']\n",
    "    if any(p in str(conf) for p in power_conferences):\n",
    "        return 'P5'\n",
    "    else:\n",
    "        return 'G5'\n",
    "\n",
    "merged_analysis['tier'] = merged_analysis['conference'].apply(classify_conference)\n",
    "\n",
    "print(f\"Merged dataset size: {len(merged_analysis)} school-year combinations\")\n",
    "print(f\"Years covered: {sorted(merged_analysis['year'].unique())}\")\n",
    "\n",
    "# ============================================\n",
    "# FIGURE 1: STRATIFICATION OVER TIME (TD vs SRS)\n",
    "# ============================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Color by year (gradient)\n",
    "years = merged_analysis['year']\n",
    "normalize = plt.Normalize(vmin=years.min(), vmax=years.max())\n",
    "colors = cm.viridis(normalize(years))\n",
    "\n",
    "# Size by tier\n",
    "sizes = merged_analysis['tier'].map({'P5': 100, 'G5': 50})\n",
    "\n",
    "# Scatter plot\n",
    "scatter = ax.scatter(merged_analysis['TD_zscore'], \n",
    "                     merged_analysis['srs'],\n",
    "                     c=colors, \n",
    "                     s=sizes,\n",
    "                     alpha=0.6,\n",
    "                     edgecolors='black',\n",
    "                     linewidth=0.5)\n",
    "\n",
    "# Add colorbar for year\n",
    "cbar = plt.colorbar(cm.ScalarMappable(norm=normalize, cmap='viridis'), ax=ax)\n",
    "cbar.set_label('Year', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Overall regression line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "    merged_analysis['TD_zscore'], \n",
    "    merged_analysis['srs']\n",
    ")\n",
    "x_line = np.linspace(merged_analysis['TD_zscore'].min(), \n",
    "                     merged_analysis['TD_zscore'].max(), 100)\n",
    "ax.plot(x_line, slope*x_line + intercept, \n",
    "        color='red', linewidth=2, linestyle='--', \n",
    "        label=f'Overall: r={r_value:.3f}')\n",
    "\n",
    "# ============================================\n",
    "# ERA COMPARISON\n",
    "# ============================================\n",
    "\n",
    "portal_era = merged_analysis[merged_analysis['year'] >= 2021]\n",
    "pre_portal = merged_analysis[merged_analysis['year'] < 2021]\n",
    "\n",
    "print(f\"\\nData distribution:\")\n",
    "print(f\"  Total observations: {len(merged_analysis)}\")\n",
    "print(f\"  Pre-Portal (<2021): {len(pre_portal)}\")\n",
    "print(f\"  Portal Era (2021+): {len(portal_era)}\")\n",
    "\n",
    "# Pre-portal regression line\n",
    "if len(pre_portal) > 10:\n",
    "    slope_pre, int_pre, r_pre, p_pre, _ = stats.linregress(\n",
    "        pre_portal['TD_zscore'], pre_portal['srs']\n",
    "    )\n",
    "    ax.plot(x_line, slope_pre*x_line + int_pre,\n",
    "            color='gray', linewidth=2.5, linestyle='-',\n",
    "            label=f'Pre-Portal (<2021): r={r_pre:.3f}')\n",
    "else:\n",
    "    print(\"  ⚠ Insufficient pre-portal data for regression\")\n",
    "\n",
    "# Portal era regression line\n",
    "if len(portal_era) > 10:\n",
    "    slope_post, int_post, r_post, p_post, _ = stats.linregress(\n",
    "        portal_era['TD_zscore'], portal_era['srs']\n",
    "    )\n",
    "    ax.plot(x_line, slope_post*x_line + int_post,\n",
    "            color='orange', linewidth=2.5, linestyle='-',\n",
    "            label=f'Portal Era (2021+): r={r_post:.3f}')\n",
    "else:\n",
    "    print(\"  ⚠ Insufficient portal era data for regression\")\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Talent Delta (Z-score)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Team Performance (SRS)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Stratification Analysis: TD vs SRS Over Time\\n(Comparison of Pre-Portal vs Portal Eras)', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper left', fontsize=11, framealpha=0.95)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Save\n",
    "output_path = Path(r\"C:\\Users\\User\\Documents\\cfb project\\imgs\\supp\") / \"stratification_td_srs.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✓ Stratification plot saved to: {output_path}\")\n",
    "\n",
    "# Print Analysis Results\n",
    "if len(pre_portal) > 10 and len(portal_era) > 10:\n",
    "    print(\"\\nStratification Change Analysis:\")\n",
    "    print(f\"  Pre-Portal Correlation: r = {r_pre:.3f}\")\n",
    "    print(f\"  Portal Era Correlation: r = {r_post:.3f}\")\n",
    "    \n",
    "    delta = abs(r_post) - abs(r_pre)\n",
    "    if delta > 0:\n",
    "        print(f\"  RESULT: Correlation has STRENGTHENED by {delta:.3f}\")\n",
    "        print(\"  INTERPRETATION: Talent advantages are translating MORE directly to wins in the portal era.\")\n",
    "    else:\n",
    "        print(f\"  RESULT: Correlation has WEAKENED by {abs(delta):.3f}\")\n",
    "# ============================================\n",
    "# FIGURE 2: PORTAL STRATEGY PAYOFF (PCR vs Performance Change)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PORTAL STRATEGY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate year-over-year performance change\n",
    "merged_analysis = merged_analysis.sort_values(['school', 'year'])\n",
    "merged_analysis['fpi_change'] = merged_analysis.groupby('school')['fpi'].diff()\n",
    "merged_analysis['srs_change'] = merged_analysis.groupby('school')['srs'].diff()\n",
    "\n",
    "# Only use portal era (2021+) and rows with performance change data\n",
    "portal_strategy = merged_analysis[\n",
    "    (merged_analysis['year'] >= 2021) & \n",
    "    (merged_analysis['fpi_change'].notna())\n",
    "]\n",
    "\n",
    "# Classify initial performance tier\n",
    "portal_strategy['performance_tier'] = pd.cut(\n",
    "    portal_strategy['fpi'], \n",
    "    bins=[-np.inf, -5, 5, np.inf],\n",
    "    labels=['Low', 'Mid', 'Elite']\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Color by performance tier\n",
    "tier_colors = {'Elite': 'darkred', 'Mid': 'orange', 'Low': 'lightblue'}\n",
    "for tier in ['Elite', 'Mid', 'Low']:\n",
    "    tier_data = portal_strategy[portal_strategy['performance_tier'] == tier]\n",
    "    if len(tier_data) > 0:\n",
    "        ax.scatter(tier_data['PCR_zscore'], \n",
    "                   tier_data['fpi_change'],\n",
    "                   c=tier_colors[tier],\n",
    "                   s=80,\n",
    "                   alpha=0.6,\n",
    "                   edgecolors='black',\n",
    "                   linewidth=0.5,\n",
    "                   label=f'{tier} (baseline FPI)')\n",
    "\n",
    "# Add regression lines by tier\n",
    "for tier in ['Elite', 'Mid', 'Low']:\n",
    "    tier_data = portal_strategy[portal_strategy['performance_tier'] == tier]\n",
    "    if len(tier_data) > 5:\n",
    "        slope, intercept, r, p, _ = stats.linregress(\n",
    "            tier_data['PCR_zscore'].dropna(), \n",
    "            tier_data['fpi_change'].dropna()\n",
    "        )\n",
    "        x_line = np.linspace(tier_data['PCR_zscore'].min(), \n",
    "                             tier_data['PCR_zscore'].max(), 50)\n",
    "        ax.plot(x_line, slope*x_line + intercept,\n",
    "                color=tier_colors[tier], linewidth=2, linestyle='--',\n",
    "                alpha=0.7)\n",
    "        print(f\"\\n{tier} Tier: r={r:.3f}, p={p:.4f}\")\n",
    "\n",
    "# Add quadrant lines\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Label quadrants\n",
    "ax.text(-2, 8, 'Recruiting-Focused\\n+ Improvement', \n",
    "        fontsize=10, ha='center', va='center', \n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "ax.text(2, 8, 'Portal-Focused\\n+ Improvement', \n",
    "        fontsize=10, ha='center', va='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "ax.text(-2, -8, 'Recruiting-Focused\\n+ Decline', \n",
    "        fontsize=10, ha='center', va='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.3))\n",
    "ax.text(2, -8, 'Portal-Focused\\n+ Decline', \n",
    "        fontsize=10, ha='center', va='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.3))\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Portal Contribution Ratio (Z-score)\\n← Recruiting-Focused | Portal-Focused →', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Year-Over-Year FPI Change', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Portal Strategy Payoff: Does It Work? (2021-2024)', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=11, framealpha=0.95, title='Performance Tier')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./imgs/supp/portal_strategy_payoff.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✓ Portal strategy payoff plot saved!\")\n",
    "\n",
    "# Count schools in each quadrant\n",
    "q1 = portal_strategy[(portal_strategy['PCR_zscore'] > 0) & (portal_strategy['fpi_change'] > 0)]\n",
    "q2 = portal_strategy[(portal_strategy['PCR_zscore'] < 0) & (portal_strategy['fpi_change'] > 0)]\n",
    "q3 = portal_strategy[(portal_strategy['PCR_zscore'] < 0) & (portal_strategy['fpi_change'] < 0)]\n",
    "q4 = portal_strategy[(portal_strategy['PCR_zscore'] > 0) & (portal_strategy['fpi_change'] < 0)]\n",
    "\n",
    "print(\"\\nQuadrant Distribution (Portal Era):\")\n",
    "print(f\"  Portal-Focused + Improvement: {len(q1)} ({len(q1)/len(portal_strategy)*100:.1f}%)\")\n",
    "print(f\"  Recruiting-Focused + Improvement: {len(q2)} ({len(q2)/len(portal_strategy)*100:.1f}%)\")\n",
    "print(f\"  Recruiting-Focused + Decline: {len(q3)} ({len(q3)/len(portal_strategy)*100:.1f}%)\")\n",
    "print(f\"  Portal-Focused + Decline: {len(q4)} ({len(q4)/len(portal_strategy)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ ALL ANALYSES COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ND/NPV\n",
    "\n",
    "# ND distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(nd_npv_df['net_degree'], discrete=True, color='cyan')\n",
    "plt.title('Distribution of Net Portal Gain', fontsize=14)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "nd_std_dev = statistics.stdev(nd_npv_df['net_degree'])\n",
    "q1 = np.percentile(nd_npv_df['net_degree'], 25)\n",
    "q3 = np.percentile(nd_npv_df['net_degree'], 75)\n",
    "iqr = q3 - q1\n",
    "plt.axvline(q1, color='green', linestyle='dashed', linewidth=1, label=f'IQR: ± {iqr/2}')\n",
    "plt.axvline(q3, color='green', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(nd_std_dev, color='red', linestyle='dashed', linewidth=1, label=f'Std Dev: {nd_std_dev:.2f}')\n",
    "plt.axvline(-nd_std_dev, color='red', linestyle='dashed', linewidth=1)\n",
    "leg = plt.legend(title=f\"Skewness: {nd_npv_df['net_degree'].skew():.2f}\\nKurtosis: {nd_npv_df['net_degree'].kurt():.2f}\", )\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'.\\\\imgs\\\\xfer\\\\graphs\\\\distribution_net_degree.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ND/NPV SCATTER (with regression line)\n",
    "plt.scatter(nd_npv_df['net_degree'], nd_npv_df['NPV_assumed'])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(nd_npv_df['net_degree'], nd_npv_df['NPV_assumed'])\n",
    "plt.plot(nd_npv_df['net_degree'], slope*nd_npv_df['net_degree'] + intercept, color='red')\n",
    "plt.xlabel('Net Portal Gain')\n",
    "plt.ylabel('Net Portal Value')\n",
    "plt.title('Scatter Plot of NPG vs NPV')\n",
    "plt.legend(['Schools', 'Regression Line'], title= f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}')\n",
    "plt.savefig(f'.\\\\imgs\\\\xfer\\\\graphs\\\\scatter_net_degree_vs_npv.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# IN/OUT SCATTER (with regression line)\n",
    "plt.scatter(nd_npv_df['in_count'], nd_npv_df['out_count'], color='purple')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(nd_npv_df['in_count'], nd_npv_df['out_count'])\n",
    "plt.plot(nd_npv_df['in_count'], slope*nd_npv_df['in_count'] + intercept, color='red')\n",
    "plt.xlabel('In-Count')\n",
    "plt.ylabel('Out-Count')\n",
    "plt.title('Scatter Plot of In-Count vs Out-Count')\n",
    "leg = plt.legend(['Schools', 'Regression Line'], title= f'Slope: {slope:.2f}\\nCorrelation: {r_value:.2f}')\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.savefig(f'.\\\\imgs\\\\xfer\\\\graphs\\\\scatter_in_vs_out_degree.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# AGG METRICS BY SCHOOL\n",
    "\n",
    "# 1. Prepare your data\n",
    "school_summary_npv = nd_npv_df.groupby('school')['net_degree'].sum().reset_index().sort_values('net_degree', ascending=False)\n",
    "\n",
    "# 2. Create explicit copies for Top and Bottom to avoid SettingWithCopy warnings\n",
    "#    and manipulate their indices independently.\n",
    "\n",
    "# --- Top 15 (Highest Net Degree) ---\n",
    "df_top = school_summary_npv.head(15).copy()\n",
    "df_top.reset_index(drop=True, inplace=True)  # Reset to 0, 1, 2...\n",
    "df_top.index = df_top.index + 1             # Shift to 1, 2, 3...\n",
    "df_top.index.name = 'Rank'                  # Set the header label\n",
    "\n",
    "# --- Bottom 15 (Lowest Net Degree) ---\n",
    "# Your logic was correct: tail(15) gets the bottom, sort_values(asc=True) puts the lowest first.\n",
    "df_bottom = school_summary_npv.tail(15).sort_values('net_degree', ascending=True).copy()\n",
    "df_bottom.reset_index(drop=True, inplace=True) # Reset to 0, 1, 2...\n",
    "df_bottom.index = df_bottom.index + 1          # Shift to 1, 2, 3...\n",
    "df_bottom.index.name = 'Rank'                  # Set the header label\n",
    "\n",
    "# 3. Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6)) # Increased width slightly for readability\n",
    "plt.suptitle('Aggregate Net Portal Gain by School', fontsize=16)\n",
    "\n",
    "column_definitions = [ColumnDefinition(name='school', # name of the column to change\n",
    "                                       title='School', # new title for the column\n",
    "                                       textprops={\"ha\": \"left\"}),\n",
    "                      ColumnDefinition(name='net_degree',\n",
    "                                       title='Value',\n",
    "                                       textprops={\"ha\": \"right\"}),\n",
    "                      ColumnDefinition(name='Rank',\n",
    "                                       textprops={'ha': 'right'})\n",
    "                                      ]\n",
    "\n",
    "# Create the tables\n",
    "tab1 = Table(df_top, ax=axes[0], column_definitions=column_definitions)\n",
    "tab2 = Table(df_bottom, ax=axes[1], column_definitions=column_definitions)\n",
    "axes[0].set_title(\"Top\", fontstyle='italic')\n",
    "axes[1].set_title(\"Bottom\", fontstyle='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# AGG TEAM RATINGS BY SCHOOL FOR SAME YEARS\n",
    "\n",
    "#teamratings_df['year'] = teamratings_df['season'].apply(lambda x: int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6660e0",
   "metadata": {},
   "source": [
    "COURSE-REQUIRED ANALYSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECTING BIPARTITE RECRUITING NETWORK(S)\n",
    "\n",
    "# function to calculate shared recruit volume for weights\n",
    "def shared_recruit_volume(G, u, v):\n",
    "    weight = 0\n",
    "    # Find all hometowns (neighbors) that both schools share\n",
    "    shared_hometowns = set(G[u]) & set(G[v])\n",
    "    \n",
    "    for h in shared_hometowns:\n",
    "        # Get the weight for School U -> Hometown\n",
    "        w_u = G[u][h].get('weight', 1)\n",
    "        # Get the weight for School V -> Hometown\n",
    "        w_v = G[v][h].get('weight', 1)\n",
    "        \n",
    "        # chosen operation\n",
    "        weight += w_u + w_v\n",
    "        \n",
    "    return weight\n",
    "\n",
    "for file, B in recfiles.items():\n",
    "    year = int(re.search(r'\\d{4}', file).group())\n",
    "    schools = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    hometowns = set(B) - schools\n",
    "    G_bip_simple = nx.Graph()\n",
    "    # copy nodes\n",
    "    for n, d in B.nodes(data=True):\n",
    "        G_bip_simple.add_node(n, **d)\n",
    "\n",
    "    # accumulate weights (default: count parallel edges)\n",
    "    edge_weights = {}\n",
    "    for u, v, key, data in B.edges(keys=True, data=True):\n",
    "        # determine which end is the school\n",
    "        if u in schools and v not in schools:\n",
    "            s, h = u, v\n",
    "        elif v in schools and u not in schools:\n",
    "            s, h = v, u\n",
    "        else:\n",
    "            # skip same-type edges (just in case)\n",
    "            continue\n",
    "        w = 1    \n",
    "        edge_weights[(s, h)] = edge_weights.get((s, h), 0) + w\n",
    "\n",
    "    # add aggregated edges to the simple bipartite graph\n",
    "    for (s, h), w in edge_weights.items():\n",
    "        G_bip_simple.add_edge(s, h, weight=w)\n",
    "\n",
    "    # Now create a weighted projection of the school nodes\n",
    "    projected = bipartite.generic_weighted_projected_graph(G_bip_simple, schools, weight_function=shared_recruit_volume)\n",
    "    #nx.write_graphml(projected, f'.\\\\data\\\\recruiting\\\\projections\\\\total\\\\projected_{year}_total.graphml')\n",
    "\n",
    "# -------------------------------\n",
    "# COMBINING PROJECTIONS INTO SINGLE GRAPH\n",
    "# -------------------------------\n",
    "\n",
    "# Load all projection files from subfolders\n",
    "for file_path in projectedpath.rglob(\"*.graphml\"):\n",
    "    name = file_path.stem\n",
    "    \n",
    "    year_match = re.search(r\"20\\d{2}\", name)\n",
    "    if not year_match:\n",
    "        print(\"SKIPPING (no year found):\", name)\n",
    "        continue\n",
    "\n",
    "    year = int(year_match.group(0))\n",
    "\n",
    "    \n",
    "    # Determine projection type based on folder location + filename\n",
    "    parent = file_path.parent.name.lower()\n",
    "    name_lower = name.lower()\n",
    "\n",
    "    if parent == \"total\":\n",
    "        projection_type = \"total\"\n",
    "    elif parent == \"min\":\n",
    "        projection_type = \"min\"\n",
    "    else:\n",
    "        projection_type = \"places\"\n",
    "    \n",
    "    # Load graph\n",
    "    G = nx.read_graphml(file_path)\n",
    "    \n",
    "    # Store by year + type\n",
    "    recfilesproj.setdefault(year, {})\n",
    "    recfilesproj[year][projection_type] = G\n",
    "\n",
    "# Combine graphs year by year  \n",
    "outdir = Path(\"data/recruiting/projections/combined\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for year, proj_dict in recfilesproj.items():\n",
    "\n",
    "    # Safety check  \n",
    "    if not all(k in proj_dict for k in [\"total\", \"places\", \"min\"]):\n",
    "        print(f\"WARNING: Year {year} missing one or more projections — skipping\")\n",
    "        continue\n",
    "    \n",
    "    G_total = proj_dict[\"total\"]\n",
    "    G_places = proj_dict[\"places\"]\n",
    "    G_min = proj_dict[\"min\"]\n",
    "\n",
    "    # Create combined graph\n",
    "    G_combined = nx.Graph()\n",
    "    G_combined.add_nodes_from(G_total.nodes(data=True))\n",
    "\n",
    "    # Union of all edges across the three graphs\n",
    "    all_edges = (\n",
    "        set(G_total.edges()) |\n",
    "        set(G_places.edges()) |\n",
    "        set(G_min.edges())\n",
    "    )\n",
    "\n",
    "    for u, v in all_edges:\n",
    "        G_combined.add_edge(u, v)\n",
    "\n",
    "        # Assign three weight attributes\n",
    "        G_combined[u][v][\"total_volume\"] = (\n",
    "            G_total[u][v].get(\"weight\", 0) if G_total.has_edge(u, v) else 0\n",
    "        )\n",
    "        G_combined[u][v][\"shared_places\"] = (\n",
    "            G_places[u][v].get(\"weight\", 0) if G_places.has_edge(u, v) else 0\n",
    "        )\n",
    "        G_combined[u][v][\"min_shared\"] = (\n",
    "            G_min[u][v].get(\"weight\", 0) if G_min.has_edge(u, v) else 0\n",
    "        )\n",
    "\n",
    "    # Save combined file\n",
    "    outfile = outdir / f\"projected_combined_{year}.graphml\"\n",
    "    #nx.write_graphml(G_combined, outfile)\n",
    "\n",
    "    print(f\"✔ Saved {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1389582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING FUNCTIONS\n",
    "\n",
    "def fit_and_plot_best_distribution(data, title=\"Degree Distribution\", xlabel=\"Value\", ylabel=\"Probability\", color='skyblue', log=False, savepath=None, select=None):\n",
    "    \"\"\"\n",
    "    Fits Power Law, Exponential, Log-Normal, and Gaussian distributions to provided data,\n",
    "    determines the best fit via R-squared, and plots the result.\n",
    "    \"\"\"\n",
    "    # Process Data: Calculate statistics and create histogram/probabilities\n",
    "    avg_val = np.mean(data)\n",
    "    std_val = np.std(data) # Needed for Gaussian initial guess\n",
    "    \n",
    "    # Create histogram\n",
    "    if np.issubdtype(np.array(data).dtype, np.integer) and max(data) < 500:\n",
    "        bins = np.arange(min(data), max(data) + 2) - 0.5\n",
    "    else:\n",
    "        bins = 100 \n",
    "        \n",
    "    counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "    \n",
    "    # Calculate bin centers\n",
    "    x = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    y = counts\n",
    "\n",
    "    # Filter zeros for fitting\n",
    "    mask = (y > 0) & (x > 0)\n",
    "    x_fit = x[mask]\n",
    "    y_fit = y[mask]\n",
    "\n",
    "    # Define candidate models\n",
    "    \n",
    "    # Power Law:\n",
    "    def power_law(x, a, b):\n",
    "        return a * np.power(x, -b)\n",
    "\n",
    "    # Exponential:\n",
    "    def exponential(x, a, b):\n",
    "        return a * np.exp(-b * x)\n",
    "    \n",
    "    # Log-Normal:\n",
    "    def log_normal(x, mu, sigma):\n",
    "        return (1 / (x * sigma * np.sqrt(2 * np.pi))) * np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "    # Gaussian (Normal):\n",
    "    def gaussian(x, amp, mu, sigma):\n",
    "            return amp * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    \n",
    "    models = {\n",
    "        \"Power Law\": {\n",
    "            \"func\": power_law, \n",
    "            \"p0\": [1, 2], \n",
    "            \"eqn\": r\"$P(x) \\propto x^{{-{:.2f}}}$\",\n",
    "            \"params\": [\"amplitude\", \"alpha\"]\n",
    "        },\n",
    "        \"Exponential\": {\n",
    "            \"func\": exponential, \n",
    "            \"p0\": [1, 0.1], \n",
    "            \"eqn\": r\"$P(x) \\propto e^{{-{:.2f}x}}$\",\n",
    "            \"params\": [\"amplitude\", \"lambda\"]\n",
    "        },\n",
    "        \"Log-Normal\": {\n",
    "            \"func\": log_normal,\n",
    "            \"p0\": [np.log(avg_val), 1.0],\n",
    "            \"eqn\": r\"LogNorm($\\mu={:.2f}, \\sigma={:.2f}$)\",\n",
    "            \"params\": [\"mu\", \"sigma\"]\n",
    "        },\n",
    "        \"Gaussian\": {\n",
    "            \"func\": gaussian,\n",
    "            # GUESSES: Amplitude = max height of data, Mu = average, Sigma = std dev\n",
    "            \"p0\": [max(y_fit), avg_val, std_val], \n",
    "            \"eqn\": r\"Gauss($\\mu={:.2f}, \\sigma={:.2f}$)\",\n",
    "            \"params\": [\"amp\", \"mu\", \"sigma\"] \n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Fit models and compare\n",
    "    best_r2 = -np.inf\n",
    "    best_model_name = \"\"\n",
    "    best_params = []\n",
    "    best_y_pred = []\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model_info in models.items():\n",
    "        try:\n",
    "            # Perform curve fit\n",
    "            popt, pcov = curve_fit(model_info[\"func\"], x_fit, y_fit, p0=model_info[\"p0\"], maxfev=10000)\n",
    "            \n",
    "            # Generate predictions\n",
    "            y_pred = model_info[\"func\"](x_fit, *popt)\n",
    "            \n",
    "            # Calculate R-squared\n",
    "            residuals = y_fit - y_pred\n",
    "            ss_res = np.sum(residuals**2)\n",
    "            ss_tot = np.sum((y_fit - np.mean(y_fit))**2)\n",
    "            r2 = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            # Keep track\n",
    "            results[name] = {\"r2\": r2, \"params\": popt}\n",
    "            \n",
    "            should_update = False\n",
    "            \n",
    "            if select:\n",
    "                # Force specific fit if specified\n",
    "                if name == select:\n",
    "                    should_update = True\n",
    "            else:\n",
    "                # Standard auto-selection: strictly better R2\n",
    "                if r2 > best_r2:\n",
    "                    should_update = True\n",
    "\n",
    "            if should_update:\n",
    "                best_r2 = r2\n",
    "                best_model_name = name\n",
    "                best_params = popt\n",
    "                best_y_pred = y_pred\n",
    "                 \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fit {name}: {e}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot data\n",
    "    plt.bar(x, y, width=np.diff(bin_edges), color=color, alpha=0.7, label='Observed Data', align='center')\n",
    "\n",
    "    # Plot best fit curve\n",
    "    if best_model_name:\n",
    "        x_smooth = np.linspace(min(x_fit), max(x_fit), 200)\n",
    "        y_smooth = models[best_model_name][\"func\"](x_smooth, *best_params)\n",
    "        plt.plot(x_smooth, y_smooth, 'r--', linewidth=2.5, label=f'Best Fit: {best_model_name}')\n",
    "\n",
    "        # Construct legend text\n",
    "        correlation, _ = stats.pearsonr(y_fit, best_y_pred)\n",
    "        \n",
    "        # Format specific equation string\n",
    "        if best_model_name == \"Power Law\":\n",
    "            model_str = models[\"Power Law\"][\"eqn\"].format(best_params[1]) \n",
    "        elif best_model_name == \"Exponential\":\n",
    "            model_str = models[\"Exponential\"][\"eqn\"].format(best_params[1])\n",
    "        elif best_model_name == \"Log-Normal\":\n",
    "            model_str = models[\"Log-Normal\"][\"eqn\"].format(best_params[0], best_params[1])\n",
    "        elif best_model_name == \"Gaussian\":\n",
    "            model_str = models[\"Gaussian\"][\"eqn\"].format(best_params[1], best_params[2])\n",
    "        \n",
    "        legend_text = (\n",
    "            f\"Mean Value: {avg_val:.2f}\\n\"\n",
    "            f\"Model: {best_model_name}\\n\"\n",
    "            f\"Fit: {model_str}\\n\"\n",
    "            f\"$R^2$: {best_r2:.4f}\\n\"\n",
    "            f\"Correlation ($r$): {correlation:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Add legend with the stats block\n",
    "        leg = plt.legend(title=legend_text, title_fontsize=10, loc='upper right')\n",
    "        leg.set_alignment(\"left\")\n",
    "\n",
    "    else:\n",
    "        plt.legend([\"Data (No fit converged)\"])\n",
    "\n",
    "    # Final formatting\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.xlim(left=min(x))\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Optional: Log-Log scale\n",
    "    if log:\n",
    "        plt.xscale('log'); plt.yscale('log')\n",
    "\n",
    "    # Optional: Save\n",
    "    if savepath:\n",
    "        plt.savefig(savepath)\n",
    "    return plt\n",
    "\n",
    "# REC\n",
    "all_degrees_r = []\n",
    "for name, G in recfilesproj.items():\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    all_degrees_r.extend(degrees)\n",
    "\n",
    "# 2. Call the function\n",
    "fit_and_plot_best_distribution(all_degrees_r, \n",
    "                               title=\"Average Projected Recruiting Network Degree Distribution\", \n",
    "                               color=\"lightcoral\", \n",
    "                               #savepath=f\".\\\\imgs\\\\rec\\\\graphs\\\\degdist\\\\recruiting_degree_distribution.png\"\n",
    "                            )\n",
    "\n",
    "# XFER\n",
    "\n",
    "specify = True\n",
    "if specify:\n",
    "    all_degrees_x = []\n",
    "    target_classes = {'fbs'}\n",
    "\n",
    "    for name, G in xferfiles.items():\n",
    "        degrees = []\n",
    "        for n, d in G.degree():\n",
    "            # Retrieve the classification directly from the node attribute\n",
    "            # Safely returns None if the attribute is missing\n",
    "            school_class = G.nodes[n].get('classification')\n",
    "            \n",
    "            # Check if it exists and is in our target list (case-insensitive)\n",
    "            if school_class and str(school_class).lower() in target_classes:\n",
    "                degrees.append(d)\n",
    "                \n",
    "        all_degrees_x.extend(degrees)\n",
    "\n",
    "    # Safety check\n",
    "    if not all_degrees_x:\n",
    "        raise RuntimeError(\"No D1 (FBS/FCS) schools found. Check your node attributes.\")\n",
    "\n",
    "    # 2. Call the function\n",
    "    fit_and_plot_best_distribution(\n",
    "        all_degrees_x, \n",
    "        title=\"Average Transfer Network Degree Distribution (FBS Only)\", \n",
    "        color=\"skyblue\",\n",
    "        #savepath=f\".\\\\imgs\\\\xfer\\\\graphs\\\\degdist\\\\transfer_degree_distribution_fbs.png\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    all_degrees_x = []\n",
    "    for name, G in xferfiles.items():\n",
    "        degrees = [d for n, d in G.degree()]\n",
    "        all_degrees_x.extend(degrees)\n",
    "\n",
    "    # 2. Call the function\n",
    "    fit_and_plot_best_distribution(all_degrees_x, \n",
    "                                title=\"Average Transfer Network Degree Distribution\", \n",
    "                                #savepath=f\".\\\\imgs\\\\xfer\\\\graphs\\\\degdist\\\\transfer_degree_distribution.png\"\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAGERANK\n",
    "# ========\n",
    "\n",
    "# --- GRAPH\n",
    "\n",
    "pr_accumulator = {}\n",
    "\n",
    "# Collect PR scores from each graph\n",
    "for name, G in xferfiles.items():\n",
    "    avg_pr_values = nx.pagerank(G)\n",
    "    for node, pr in avg_pr_values.items():\n",
    "        pr_accumulator.setdefault(node, []).append(pr)\n",
    "\n",
    "# Compute average PR per school\n",
    "avg_pr_values = np.array([np.mean(values) for values in pr_accumulator.values()])\n",
    "\n",
    "# Call plotting function\n",
    "fit_and_plot_best_distribution(avg_pr_values, title='Distribution of Average PageRank (Transfer Portal)', \n",
    "                               ylabel=\"Probability Density\", color='turquoise', \n",
    "                               savepath=f\".\\\\imgs\\\\xfer\\\\graphs\\\\pagerank_distribution.png\")\n",
    "\n",
    "# --- TABLE\n",
    "\n",
    "pr_df = pd.DataFrame({\n",
    "    'school': list(pr_accumulator.keys()),\n",
    "    'avg_pagerank': avg_pr_values  # keep numeric\n",
    "})\n",
    "pr_df = pr_df.sort_values('avg_pagerank', ascending=False)\n",
    "pr_df_display = pr_df.copy()\n",
    "pr_df_display['avg_pagerank'] = pr_df_display['avg_pagerank'].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "df_top = pr_df_display.head(15).copy()\n",
    "df_top.reset_index(drop=True, inplace=True)  \n",
    "df_top.index = df_top.index + 1             \n",
    "df_top.index.name = 'Rank'                  \n",
    "\n",
    "df_bottom = pr_df_display.tail(15).sort_values('avg_pagerank', ascending=True).copy()\n",
    "df_bottom.reset_index(drop=True, inplace=True) \n",
    "df_bottom.index = df_bottom.index + 1          \n",
    "df_bottom.index.name = 'Rank'                  \n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.suptitle('Average PageRank by School (D1 Only)', fontsize=16)\n",
    "\n",
    "column_definitions = [ColumnDefinition(name='school',\n",
    "                                       title='School',\n",
    "                                       textprops={\"ha\": \"left\"}),\n",
    "                      ColumnDefinition(name='avg_pagerank',\n",
    "                                       title='Value',\n",
    "                                       textprops={\"ha\": \"right\"}),\n",
    "                      ColumnDefinition(name='Rank',\n",
    "                                       textprops={'ha': 'right'})\n",
    "                                      ]\n",
    "\n",
    "# Create the tables\n",
    "tab1 = Table(df_top, ax=axes[0], column_definitions=column_definitions)\n",
    "tab2 = Table(df_bottom, ax=axes[1], column_definitions=column_definitions)\n",
    "axes[0].set_title(\"Top\", fontstyle='italic')\n",
    "axes[1].set_title(\"Bottom\", fontstyle='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'.\\\\imgs\\\\xfer\\\\graphs\\\\pagerank_top_bottom.png', dpi=250, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSORTATIVITY\n",
    "\n",
    "# Accumulate (k, knn) pairs from all graphs\n",
    "k_knn_map = {}  \n",
    "\n",
    "for name, G in xferfiles.items():\n",
    "    # Calculate metrics for this specific graph snapshot\n",
    "    knn_dict = nx.average_neighbor_degree(G) \n",
    "    degree_dict = dict(G.degree())\n",
    "    \n",
    "    for node, k in degree_dict.items():\n",
    "        if k > 0 and node in knn_dict:\n",
    "            knn = knn_dict[node]\n",
    "            k_knn_map.setdefault(k, []).append(knn)\n",
    "\n",
    "# Binning: calculate the mean knn for each degree k\n",
    "x_k = []\n",
    "y_knn = []\n",
    "\n",
    "# Sort by degree so the line connects properly\n",
    "for k in sorted(k_knn_map.keys()):\n",
    "    if k > 0: # Log-log plots dislike 0\n",
    "        vals = k_knn_map[k]\n",
    "        x_k.append(k)\n",
    "        y_knn.append(np.mean(vals))\n",
    "\n",
    "# Fitting\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(x_k), np.log(y_knn))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter of the binned means\n",
    "plt.scatter(x_k, y_knn, color='navy', alpha=0.8, s=50, label='Observed Data (Binned)')\n",
    "\n",
    "# Trend line\n",
    "x_fit = np.linspace(min(x_k), max(x_k), 100)\n",
    "y_fit = np.exp(intercept + slope * np.log(x_fit)) # Transform back from log space\n",
    "plt.plot(x_fit, y_fit, 'r--', linewidth=2, label=f'Trend (Slope: {slope:.2f})')\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Degree Correlation: $k_{nn}$ vs $k$ (Transfer Portal)\", fontsize=14)\n",
    "plt.xlabel(\"Node Degree ($k$)\", fontsize=12)\n",
    "plt.ylabel(\"Avg. Neighbor Degree ($k_{nn}$)\", fontsize=12)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Legend\n",
    "legend_text = (\n",
    "    f\"Slope: {slope:.2f}\\n\"\n",
    "    f\"Correlation: {r_value:.2f}\"\n",
    ")\n",
    "leg = plt.legend(title=legend_text)\n",
    "leg.set_alignment('left')\n",
    "\n",
    "# Save\n",
    "plt.savefig(r\"imgs\\xfer\\graphs\\assortativity_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ab6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETWEENNESS\n",
    "\n",
    "# ========\n",
    "# GRAPH\n",
    "# ========\n",
    "\n",
    "# build D1 set from latest classification info\n",
    "latest_year = comprehensive_metrics_df['year'].max()\n",
    "class_map = comprehensive_metrics_df.loc[comprehensive_metrics_df['year'] == latest_year, ['school', 'classification']].drop_duplicates()\n",
    "class_map['school_lower'] = class_map['school'].str.lower().str.strip()\n",
    "class_map['classification'] = class_map['classification'].astype(str).str.lower().str.strip()\n",
    "fbs_set = set(class_map.loc[class_map['classification'].isin(['fbs']), 'school_lower'])\n",
    "\n",
    "bc_accumulator_fbs = {}\n",
    "bc_accumulator = {}\n",
    "\n",
    "# Compute\n",
    "for name, G in recfilesproj.items():\n",
    "    bc_values = nx.betweenness_centrality(G, normalized=True)\n",
    "    for node, bc in bc_values.items():\n",
    "        node_norm = str(node).lower().strip()\n",
    "        bc_accumulator.setdefault(node, []).append(bc)\n",
    "        if node_norm in fbs_set:\n",
    "            bc_accumulator_fbs.setdefault(node, []).append(bc)\n",
    "\n",
    "# Average BC per school\n",
    "avg_bc_values = np.array([np.mean(values) for values in bc_accumulator.values()])\n",
    "avg_bc_values_d1 = np.array([np.mean(values) for values in bc_accumulator_fbs.values()])\n",
    "\n",
    "# All\n",
    "fit_and_plot_best_distribution(avg_bc_values, title='Distribution of Average Betweenness (Recruiting)', \n",
    "                               ylabel=\"Probability Density\", color='fuchsia', \n",
    "                               savepath=f\".\\\\imgs\\\\rec\\\\graphs\\\\betweenness_distribution.png\")\n",
    "\n",
    "# D1-only\n",
    "fit_and_plot_best_distribution(avg_bc_values_d1, \n",
    "                               title='Distribution of Average Betweenness (Recruiting) -- FBS Only', \n",
    "                               ylabel=\"Probability Density\", color='fuchsia', \n",
    "                               savepath=f\".\\\\imgs\\\\rec\\\\graphs\\\\betweenness_distribution_fbs.png\")\n",
    "\n",
    "# =========================\n",
    "# TABLE\n",
    "# =========================\n",
    "\n",
    "# build dataframe from bc_accumulator but include only FBS schools\n",
    "fbs_items = [\n",
    "    (node, np.mean(values))\n",
    "    for node, values in bc_accumulator.items()\n",
    "    if str(node).lower().strip() in fbs_set\n",
    "]\n",
    "\n",
    "if len(fbs_items) == 0:\n",
    "    raise RuntimeError(\"No betweenness centrality scores available for FBS schools.\")\n",
    "\n",
    "bc_df = pd.DataFrame(fbs_items, columns=['school', 'avg_bc'])\n",
    "\n",
    "# sort and format for display\n",
    "bc_df = bc_df.sort_values('avg_bc', ascending=False)\n",
    "\n",
    "bc_df_disp = bc_df.copy()\n",
    "bc_df_disp['avg_bc'] = bc_df_disp['avg_bc'].map(lambda x: f\"{x:.5f}\")\n",
    "\n",
    "n_top = min(15, len(bc_df_disp))\n",
    "n_bottom = min(15, len(bc_df_disp))\n",
    "\n",
    "df_top = bc_df_disp.head(n_top).copy()\n",
    "df_top.index = np.arange(1, n_top + 1)\n",
    "df_top.index.name = 'Rank'\n",
    "\n",
    "df_bottom = bc_df_disp.tail(n_bottom).sort_values('avg_bc').copy()\n",
    "df_bottom.index = np.arange(1, n_bottom + 1)\n",
    "df_bottom.index.name = 'Rank'\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.suptitle(\"Average Betweenness Centrality (FBS only)\", fontsize=16)\n",
    "\n",
    "col_defs = [\n",
    "    ColumnDefinition(name='school', title='School', textprops={'ha': 'left'}),\n",
    "    ColumnDefinition(name='avg_bc', title='Value', textprops={'ha': 'right'}),\n",
    "    ColumnDefinition(name='Rank', textprops={'ha': 'right'})\n",
    "]\n",
    "\n",
    "tab1 = Table(df_top, ax=axes[0], column_definitions=col_defs)\n",
    "tab2 = Table(df_bottom, ax=axes[1], column_definitions=col_defs)\n",
    "\n",
    "axes[0].set_title(\"Top\", fontstyle='italic')\n",
    "axes[1].set_title(\"Bottom\", fontstyle='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'.\\\\imgs\\\\rec\\\\tables\\\\betweenness_top_bottom_fbs.png', dpi=250, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTERING\n",
    "\n",
    "cc_accumulator = {}\n",
    "\n",
    "# Collect scores from each graph\n",
    "for name, G in recfilesproj.items():\n",
    "    avg_cc_values = nx.clustering(G)\n",
    "    for node, cc in avg_cc_values.items():\n",
    "        cc_accumulator.setdefault(node, []).append(cc)\n",
    "\n",
    "# Compute average per school\n",
    "avg_cc_values = np.array([np.mean(values) for values in cc_accumulator.values()])\n",
    "avg_cc_values = avg_cc_values[avg_cc_values > 0] # cutting off 0 values so that the function works\n",
    "\n",
    "# Call plotting function\n",
    "fit_and_plot_best_distribution(avg_cc_values, title='Distribution of Average Clustering Coefficient (Recruiting', \n",
    "                               ylabel=\"Probability\", color='gold', \n",
    "                               savepath=f\".\\\\imgs\\\\rec\\\\graphs\\\\clustering_distribution.png\",\n",
    "                               select=\"Gaussian\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL COMPARISON\n",
    "\n",
    "# ======================================================\n",
    "# SETUP & HELPER FUNCTION\n",
    "# ======================================================\n",
    "\n",
    "# Select target graphs (Most recent year)\n",
    "G_rec_target = list(recfilesproj.values())[-1] \n",
    "G_xfer_target = list(xferfiles.values())[-1]\n",
    "\n",
    "def plot_ecdf_with_ci(null_datasets, type_label, save_path, color='gray'):\n",
    "    \"\"\"\n",
    "    Calculates the Mean ECDF and 95% Confidence Intervals for null models.\n",
    "    Plots the Null area and prepares the figure for the real line to be added.\n",
    "    \"\"\"\n",
    "    # 1. Standardize x axis and combine all data\n",
    "    all_data = np.concatenate(null_datasets)\n",
    "    x_values = np.sort(np.unique(all_data))\n",
    "\n",
    "    # Compute ECDF for every null model on this standardized axis\n",
    "    ecdf_matrix = []\n",
    "    \n",
    "    for data in null_datasets:\n",
    "        # Using searchsorted because it's faster than list comprehension for large arrays\n",
    "        data_sorted = np.sort(data)\n",
    "        y_vals = np.searchsorted(data_sorted, x_values, side='right') / len(data)\n",
    "        ecdf_matrix.append(y_vals)\n",
    "    \n",
    "    ecdf_matrix = np.array(ecdf_matrix)\n",
    "\n",
    "    # 3. Calculate statistics\n",
    "    avg_ecdf = np.mean(ecdf_matrix, axis=0)\n",
    "    lower_ci = np.percentile(ecdf_matrix, 2.5, axis=0) # Bottom 2.5%\n",
    "    upper_ci = np.percentile(ecdf_matrix, 97.5, axis=0) # Top 2.5%\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Mean null line\n",
    "    plt.step(x_values, avg_ecdf, where='post', color=color, linewidth=2, label='Null Mean', alpha=0.8)\n",
    "    \n",
    "    # 95% CI\n",
    "    plt.fill_between(x_values, lower_ci, upper_ci, step='post', color=color, alpha=0.3, label='Null 95% CI')\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title(f\"Real vs. Null Distribution: {type_label}\", fontsize=14)\n",
    "    plt.xlabel(\"Metric Value\", fontsize=12)\n",
    "    plt.ylabel(\"Cumulative Probability)\", fontsize=12)\n",
    "    plt.xlim(left=min(x_values))\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.grid(axis='x', linestyle=':', alpha=0.3)\n",
    "    \n",
    "    return plt, x_values\n",
    "\n",
    "# ======================================================\n",
    "# GENERATE NULL MODELS\n",
    "# ======================================================\n",
    "\n",
    "NUM_NULLS = 100\n",
    "SWAP_MULTIPLIER = 10 \n",
    "\n",
    "# --- Storage for recruiting\n",
    "null_rec_bc = []\n",
    "null_rec_clust = []\n",
    "\n",
    "# --- Storage for transfer\n",
    "null_xfer_pr = []\n",
    "null_xfer_assort = []\n",
    "\n",
    "print(f\"\\nGenerating {NUM_NULLS} Null Models...\")\n",
    "\n",
    "# Recruiting Nulls (Undirected)\n",
    "n_swaps_rec = len(G_rec_target.edges()) * SWAP_MULTIPLIER\n",
    "for i in range(NUM_NULLS):\n",
    "    if i % 10 == 0: print(f\"  Recruiting Null {i}...\")\n",
    "    G_null = G_rec_target.copy()\n",
    "    nx.double_edge_swap(G_null, nswap=n_swaps_rec, max_tries=n_swaps_rec*50)\n",
    "    \n",
    "    # Betweenness\n",
    "    null_rec_bc.append(list(nx.betweenness_centrality(G_null, normalized=True).values()))\n",
    "    \n",
    "    # Clustering\n",
    "    null_rec_clust.append(list(nx.clustering(G_null).values()))\n",
    "\n",
    "# Transfer Nulls (Directed)\n",
    "n_swaps_xfer = len(G_xfer_target.edges()) * SWAP_MULTIPLIER\n",
    "for i in range(NUM_NULLS):\n",
    "    if i % 10 == 0: print(f\"  Transfer Null {i}...\")\n",
    "    G_null = G_xfer_target.copy()\n",
    "    nx.directed_edge_swap(G_null, nswap=n_swaps_xfer, max_tries=n_swaps_xfer*100)\n",
    "\n",
    "    # 1. PageRank\n",
    "    null_xfer_pr.append(list(nx.pagerank(G_null, alpha=0.85).values()))\n",
    "    \n",
    "    # 2. Avg Neighbor Degree (proxy for assortativity distribution)\n",
    "    assort_dict = nx.average_neighbor_degree(G_null, source='in', target='out') \n",
    "    null_xfer_assort.append(list(assort_dict.values()))\n",
    "\n",
    "# ======================================================\n",
    "# PLOTTING RECRUITING\n",
    "# ======================================================\n",
    "\n",
    "# --- Betweenness ---\n",
    "plt_bc, _ = plot_ecdf_with_ci(null_rec_bc, \"Recruiting Betweenness\", r\"imgs\\nullcomp\\betweenness.png\", color='silver')\n",
    "\n",
    "# Add real line\n",
    "real_bc = list(nx.betweenness_centrality(G_rec_target, normalized=True).values())\n",
    "x_real = np.sort(real_bc)\n",
    "y_real = np.arange(1, len(x_real)+1) / len(x_real)\n",
    "plt_bc.step(x_real, y_real, where='post', color='darkred', linewidth=2.5, label='Real Network')\n",
    "plt_bc.legend(loc='lower right')\n",
    "#plt_bc.savefig(r\"imgs\\nullcomp\\betweenness_ci.png\")\n",
    "plt_bc.show()\n",
    "\n",
    "# --- Clustering Coefficient ---\n",
    "plt_clust, _ = plot_ecdf_with_ci(null_rec_clust, \"Recruiting Clustering Coeff\", r\"imgs\\nullcomp\\clustering.png\", color='silver')\n",
    "\n",
    "real_clust = list(nx.clustering(G_rec_target).values())\n",
    "x_clust = np.sort(real_clust)\n",
    "y_clust = np.arange(1, len(x_clust)+1) / len(x_clust)\n",
    "plt_clust.step(x_clust, y_clust, where='post', color='teal', linewidth=2.5, label='Real Network')\n",
    "plt_clust.legend(loc='lower right')\n",
    "#plt_clust.savefig(r\"imgs\\nullcomp\\clustering_ci.png\")\n",
    "plt_clust.show()\n",
    "\n",
    "# ======================================================\n",
    "# PLOTTING TRANSFER\n",
    "# ======================================================\n",
    "\n",
    "# --- PageRank ---\n",
    "plt_pr, _ = plot_ecdf_with_ci(null_xfer_pr, \"Transfer PageRank\", r\"imgs\\nullcomp\\pagerank.png\", color='silver')\n",
    "\n",
    "real_pr = list(nx.pagerank(G_xfer_target, alpha=0.85).values())\n",
    "x_pr = np.sort(real_pr)\n",
    "y_pr = np.arange(1, len(x_pr)+1) / len(x_pr)\n",
    "plt_pr.step(x_pr, y_pr, where='post', color='mediumorchid', linewidth=2.5, label='Real Network')\n",
    "plt_pr.legend(loc='lower right')\n",
    "#plt_pr.savefig(r\"imgs\\nullcomp\\pagerank_ci.png\")\n",
    "plt_pr.show()\n",
    "\n",
    "# --- Assortativity (Avg Neighbor Degree) ---\n",
    "plt_assort, _ = plot_ecdf_with_ci(null_xfer_assort, \"Transfer Assortativity\", r\"imgs\\nullcomp\\assort.png\", color='silver')\n",
    "\n",
    "real_assort = list(nx.average_neighbor_degree(G_xfer_target, source='in', target='out').values())\n",
    "x_assort = np.sort(real_assort)\n",
    "y_assort = np.arange(1, len(x_assort)+1) / len(x_assort)\n",
    "\n",
    "plt_assort.step(x_assort, y_assort, where='post', color='darkorange', linewidth=2.5, label='Real Network')\n",
    "plt_assort.legend(loc='lower right')\n",
    "plt_assort.xlim()\n",
    "#plt_assort.savefig(r\"imgs\\nullcomp\\assort_ci.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365e45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOLMOGOROV-SMIRNOV STATISTICAL VALIDATION:\n",
      "\n",
      "--- Recruiting: Betweenness Centrality ---\n",
      "  KS Statistic: 0.1050\n",
      "  P-Value:      1.0079e-01\n",
      "  >> RESULT: FAIL TO REJECT Null Hypothesis.\n",
      "     The real distribution is statistically similar to the nulls.\n",
      "     Conclusion: Metric is purely a byproduct of degree.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Recruiting: Clustering Coefficient ---\n",
      "  KS Statistic: 0.5950\n",
      "  P-Value:      8.0932e-45\n",
      "  >> RESULT: REJECT Null Hypothesis.\n",
      "     The real distribution is STATISTICALLY DIFFERENT from the nulls.\n",
      "     Conclusion: Structure cannot be explained by degree alone.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Transfer: PageRank ---\n",
      "  KS Statistic: 0.0995\n",
      "  P-Value:      2.1850e-03\n",
      "  >> RESULT: REJECT Null Hypothesis.\n",
      "     The real distribution is STATISTICALLY DIFFERENT from the nulls.\n",
      "     Conclusion: Structure cannot be explained by degree alone.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Transfer: Avg Neighbor Degree (Assortativity) ---\n",
      "  KS Statistic: 0.1844\n",
      "  P-Value:      1.3049e-10\n",
      "  >> RESULT: REJECT Null Hypothesis.\n",
      "     The real distribution is STATISTICALLY DIFFERENT from the nulls.\n",
      "     Conclusion: Structure cannot be explained by degree alone.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KS 2-SAMPLE TEST\n",
    "\n",
    "def run_ks_test(real_data, null_datasets, label):\n",
    "    \"\"\"\n",
    "    Runs the Kolmogorov-Smirnov 2-Sample Test comparing real data \n",
    "    against an aggregate null population.\n",
    "    \"\"\"\n",
    "    # Flatten the list of lists into one massive \"Null Population\" sample\n",
    "    null_population = np.concatenate(null_datasets)\n",
    "\n",
    "    # 2. Run test\n",
    "    statistic, p_value = ks_2samp(real_data, null_population)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"  KS Statistic: {statistic:.4f}\")\n",
    "    print(f\"  P-Value:      {p_value:.4e}\") \n",
    "\n",
    "    # 4. Interpretation logic\n",
    "    alpha = 0.01 # Significance level 1%\n",
    "    if p_value < alpha:\n",
    "        print(\"  >> RESULT: REJECT Null Hypothesis.\")\n",
    "        print(\"     The real distribution is STATISTICALLY DIFFERENT from the nulls.\")\n",
    "        print(\"     Conclusion: Structure cannot be explained by degree alone.\")\n",
    "    else:\n",
    "        print(\"  >> RESULT: FAIL TO REJECT Null Hypothesis.\")\n",
    "        print(\"     The real distribution is statistically similar to the nulls.\")\n",
    "        print(\"     Conclusion: Metric is purely a byproduct of degree.\")\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ======================================================\n",
    "# RUN TESTS FOR ALL 4 METRICS\n",
    "# ======================================================\n",
    "\n",
    "print(\"KOLMOGOROV-SMIRNOV STATISTICAL VALIDATION:\\n\")\n",
    "\n",
    "# 1. Recruiting Betweenness\n",
    "run_ks_test(real_bc, null_rec_bc, \"Recruiting: Betweenness Centrality\")\n",
    "\n",
    "# 2. Recruiting Clustering\n",
    "run_ks_test(real_clust, null_rec_clust, \"Recruiting: Clustering Coefficient\")\n",
    "\n",
    "# 3. Transfer PageRank\n",
    "run_ks_test(real_pr, null_xfer_pr, \"Transfer: PageRank\")\n",
    "\n",
    "# 4. Transfer Assortativity\n",
    "run_ks_test(real_assort, null_xfer_assort, \"Transfer: Avg Neighbor Degree (Assortativity)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91d9c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Null Hierarchy...\n",
      "  Iteration 0...\n",
      "  Iteration 5...\n",
      "  Iteration 10...\n",
      "  Iteration 15...\n",
      "  Iteration 20...\n",
      "  Iteration 25...\n",
      "  Iteration 30...\n",
      "  Iteration 35...\n",
      "  Iteration 40...\n",
      "  Iteration 45...\n",
      "  Iteration 50...\n",
      "  Iteration 55...\n",
      "  Iteration 60...\n",
      "  Iteration 65...\n",
      "  Iteration 70...\n",
      "  Iteration 75...\n",
      "  Iteration 80...\n",
      "  Iteration 85...\n",
      "  Iteration 90...\n",
      "  Iteration 95...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MORE CAREFUL NULL MODELING\n",
    "\n",
    "# ======================================================\n",
    "# RECRUITING\n",
    "# ======================================================\n",
    "\n",
    "# Detecting communities for 3rd null model\n",
    "partition = community_louvain.best_partition(G_rec_target)\n",
    "nx.set_node_attributes(G_rec_target, partition, 'community')\n",
    "\n",
    "# Helper to group edges by community\n",
    "def get_edge_types(G):\n",
    "    internal_edges = []\n",
    "    external_edges = []\n",
    "    for u, v in G.edges():\n",
    "        if G.nodes[u]['community'] == G.nodes[v]['community']:\n",
    "            internal_edges.append((u, v))\n",
    "        else:\n",
    "            external_edges.append((u, v))\n",
    "    return internal_edges, external_edges\n",
    "\n",
    "# MODEL GENERATION\n",
    "# ======================================================\n",
    "\n",
    "NUM_NULLS = 100\n",
    "null_cluster_er = []\n",
    "null_cluster_cfg = []\n",
    "null_cluster_comm = []\n",
    "\n",
    "print(\"Generating Null Hierarchy...\")\n",
    "\n",
    "for i in range(NUM_NULLS):\n",
    "    if i % 5 == 0: print(f\"  Iteration {i}...\")\n",
    "\n",
    "    # --- MODEL 1: ERDOS-RENYI (Random) ---\n",
    "    G_er = nx.gnm_random_graph(len(G_rec_target), len(G_rec_target.edges()))\n",
    "    null_cluster_er.append(nx.average_clustering(G_er))\n",
    "\n",
    "    # --- MODEL 2: CONFIGURATION (Degree Preserved) ---\n",
    "    G_cfg = G_rec_target.copy()\n",
    "    nx.double_edge_swap(G_cfg, nswap=len(G_cfg.edges())*5, max_tries=len(G_cfg.edges())*50)\n",
    "    null_cluster_cfg.append(nx.average_clustering(G_cfg))\n",
    "\n",
    "    # --- MODEL 3: COMMUNITY CONFIGURATION (Community Preserved) ---\n",
    "    # Swaps edges only if they preserve the community structure\n",
    "    \n",
    "    G_comm = G_rec_target.copy()\n",
    "    \n",
    "    # Identify edges internal to community\n",
    "    edges_by_comm = {}\n",
    "    for u, v in G_comm.edges():\n",
    "        comm_u = G_comm.nodes[u]['community']\n",
    "        comm_v = G_comm.nodes[v]['community']\n",
    "        \n",
    "        if comm_u == comm_v: # Internal Edge\n",
    "            edges_by_comm.setdefault(comm_u, []).append((u, v))\n",
    "    \n",
    "    for comm_id, edges in edges_by_comm.items():\n",
    "        # Temp subgraph of just this community's edges\n",
    "        sub_nodes = {u for u,v in edges} | {v for u,v in edges}\n",
    "        G_sub = nx.Graph()\n",
    "        G_sub.add_edges_from(edges)\n",
    "        \n",
    "        # Swap edges within this subgraph and skip if too small\n",
    "        try:\n",
    "            nx.double_edge_swap(G_sub, nswap=len(edges)*5, max_tries=len(edges)*50)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Update the main graph with the swapped edges\n",
    "        G_comm.remove_edges_from(edges)\n",
    "        G_comm.add_edges_from(G_sub.edges())\n",
    "\n",
    "    null_cluster_comm.append(nx.average_clustering(G_comm))\n",
    "\n",
    "# VISUALIZATION\n",
    "# ======================================================\n",
    "\n",
    "real_clust = nx.average_clustering(G_rec_target)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histograms\n",
    "plt.hist(null_cluster_er, color='gray', alpha=0.5, label='Null 1: Random')\n",
    "plt.hist(null_cluster_cfg, color='orange', alpha=0.5, label='Null 2: Degree Preserved')\n",
    "plt.hist(null_cluster_comm, color='green', alpha=0.5, label='Null 3: Community Preserved')\n",
    "\n",
    "# Real value\n",
    "plt.axvline(real_clust, color='red', linestyle='--', linewidth=3, label=f'Real Network ({real_clust:.3f})')\n",
    "\n",
    "plt.title(\"Clustering Coefficient of Real Network vs. Null Models\")\n",
    "plt.xlabel(\"Average Clustering Coefficient\")\n",
    "plt.legend()\n",
    "plt.savefig(r\"imgs\\nullcomp\\recruiting_comprehensive_nulls\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034b35c",
   "metadata": {},
   "source": [
    "RECRUITING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7560d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMUNITIES\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "years = range(2002, 2027)\n",
    "stability_threshold = 0.35  # Schools must be in same community _% of the time to keep link\n",
    "label_threshold_percentile = 0  # Only label top _% of nodes by degree to reduce clutter\n",
    "\n",
    "# Initialize Consensus Graph\n",
    "consensus_G = nx.Graph()\n",
    "graphs_processed = 0\n",
    "\n",
    "print(f\"Starting Volume-Weighted Consensus Clustering for {len(years)} years...\")\n",
    "\n",
    "# --- 2. ITERATE AND PROCESS ---\n",
    "for year in years:\n",
    "    # Find the graph in the dictionary\n",
    "    target_key = next((k for k in recfilesproj.keys() if str(year) in str(k)), None)\n",
    "    \n",
    "    if target_key is None:\n",
    "        continue\n",
    "        \n",
    "    G = recfilesproj[target_key]\n",
    "    \n",
    "    # [CHANGE 1] Use 'total_volume' for community detection\n",
    "    # This ensures heavy recruiting pipelines dictate the communities\n",
    "    try:\n",
    "        partition = community_louvain.best_partition(G, weight='total_volume')\n",
    "    except Exception as e:\n",
    "        print(f\"  Skipping {year} (Error: {e})\")\n",
    "        continue\n",
    "\n",
    "    # Group nodes by community\n",
    "    comm_sets = {}\n",
    "    for node, comm_id in partition.items():\n",
    "        comm_sets.setdefault(comm_id, []).append(node)\n",
    "    \n",
    "    # Update Consensus Graph (Edge Weight = Frequency of Co-occurrence)\n",
    "    for comm_nodes in comm_sets.values():\n",
    "        for u, v in combinations(comm_nodes, 2):\n",
    "            if consensus_G.has_edge(u, v):\n",
    "                consensus_G[u][v]['weight'] += 1\n",
    "            else:\n",
    "                consensus_G.add_edge(u, v, weight=1)\n",
    "                \n",
    "    graphs_processed += 1\n",
    "\n",
    "print(f\"Processed {graphs_processed} years. Filtering for stability...\")\n",
    "\n",
    "# --- 3. FILTER CONSENSUS GRAPH ---\n",
    "cutoff_weight = graphs_processed * stability_threshold\n",
    "\n",
    "edges_to_remove = [\n",
    "    (u, v) for u, v, data in consensus_G.edges(data=True) \n",
    "    if data['weight'] < cutoff_weight\n",
    "]\n",
    "consensus_G.remove_edges_from(edges_to_remove)\n",
    "consensus_G.remove_nodes_from(list(nx.isolates(consensus_G)))\n",
    "\n",
    "# --- 4. FINAL PARTITION ---\n",
    "final_partition = community_louvain.best_partition(consensus_G, weight='weight')\n",
    "\n",
    "# --- 5. VISUALIZATION WITH SMART LABELS ---\n",
    "plt.figure(figsize=(20, 20))\n",
    "pos = nx.spring_layout(consensus_G, k=0.15, iterations=100, seed=42)\n",
    "\n",
    "# Colors\n",
    "cmap = plt.get_cmap('tab20', max(final_partition.values()) + 1)\n",
    "node_colors = [final_partition[n] for n in consensus_G.nodes()]\n",
    "\n",
    "# Draw Graph\n",
    "nx.draw_networkx_edges(consensus_G, pos, alpha=0.1, edge_color='gray')\n",
    "nx.draw_networkx_nodes(consensus_G, pos, node_size=120, cmap=cmap, node_color=node_colors)\n",
    "\n",
    "# [CHANGE 2] Smart Labeling\n",
    "# Calculate node degrees to identify \"important\" schools\n",
    "degrees = dict(consensus_G.degree())\n",
    "import numpy as np\n",
    "deg_values = list(degrees.values())\n",
    "if deg_values:\n",
    "    threshold_deg = np.percentile(deg_values, label_threshold_percentile)\n",
    "else:\n",
    "    threshold_deg = 0\n",
    "\n",
    "texts = []\n",
    "for node, (x, y) in pos.items():\n",
    "    # Only label important nodes to reduce initial clutter\n",
    "    if degrees[node] >= threshold_deg:\n",
    "        texts.append(plt.text(x, y, node, fontsize=9, fontweight='bold', \n",
    "                              ha='center', va='center'))\n",
    "\n",
    "# use adjustText for non-overlapping labels\n",
    "from adjustText import adjust_text\n",
    "print(\"Applying smart label placement (this may take a moment)...\")\n",
    "adjust_text(texts, \n",
    "            arrowprops=dict(arrowstyle='-', color='gray', alpha=0.5),\n",
    "            force_text=(0.5, 1.0)) # Increase force to push labels apart\n",
    "\n",
    "plt.title(f\"Average Recruiting Communities ({years[0]}-{years[-1]})\\nWeighted by Total Volume\", fontsize=20)\n",
    "plt.axis('off')\n",
    "#plt.savefig(r\"imgs\\rec\\netviz\\average_communities_totalvolume_allnames\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1cf77c",
   "metadata": {},
   "source": [
    "PORTAL ANALYSIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
